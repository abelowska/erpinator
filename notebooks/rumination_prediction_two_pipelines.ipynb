{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40a73099-38c1-4bf0-afd3-5481df7c3d19",
   "metadata": {},
   "source": [
    "# Rumination prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ff9f56-5483-44c7-b9cc-486a31838279",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e84d26-b32c-41ae-b3f4-81e0ee55156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import ast\n",
    "import os.path as op\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "\n",
    "import pickle\n",
    "from time import time\n",
    "import pywt\n",
    "import mne\n",
    "import scipy\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import cesium.featurize\n",
    "from plotly.subplots import make_subplots\n",
    "from ipywidgets import Dropdown, FloatRangeSlider, IntSlider, FloatSlider, interact\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "# sys.path.append(\"..\")\n",
    "# from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c69899-6a32-4418-9079-8bd66aed497f",
   "metadata": {},
   "source": [
    "---\n",
    "## Loading data\n",
    "\n",
    "Loading EEG data and data from rumination questionnaire. By default create_df_data loads all info from given file but one can specify it by passing a list of desired labels from csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc483a7-410f-4b65-9955-9df42c783bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths TODO\n",
    "dir_path = os.path.dirname(os.path.abspath(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a25389-d030-415b-982d-b68df981b758",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin, tmax = -0.1, 0.6  # Start and end of the segments\n",
    "signal_frequency = 256\n",
    "ERROR = 0\n",
    "CORRECT = 1\n",
    "random_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6c08f3-3aad-4793-9656-98458799aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = [4, 38, 39, 11, 47, 46, 12, 48, 49, 19, 32, 56, 20, 31, 57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b514a320-9641-45b3-a78c-a0c65b63a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in sig:\n",
    "    print(channels_order_list[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1ef4f5-f711-4f8e-8ba5-163dc50bd2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_order_list = [\n",
    "    \"Fp1\",\n",
    "    \"AF7\",\n",
    "    \"AF3\",\n",
    "    \"F1\",\n",
    "    \"F3\",\n",
    "    \"F5\",\n",
    "    \"F7\",\n",
    "    \"FT7\",\n",
    "    \"FC5\",\n",
    "    \"FC3\",\n",
    "    \"FC1\",\n",
    "    \"C1\",\n",
    "    \"C3\",\n",
    "    \"C5\",\n",
    "    \"T7\",\n",
    "    \"TP7\",\n",
    "    \"CP5\",\n",
    "    \"CP3\",\n",
    "    \"CP1\",\n",
    "    \"P1\",\n",
    "    \"P3\",\n",
    "    \"P5\",\n",
    "    \"P7\",\n",
    "    \"P9\",\n",
    "    \"PO7\",\n",
    "    \"PO3\",\n",
    "    \"O1\",\n",
    "    \"Iz\",\n",
    "    \"Oz\",\n",
    "    \"POz\",\n",
    "    \"Pz\",\n",
    "    \"CPz\",\n",
    "    \"Fpz\",\n",
    "    \"Fp2\",\n",
    "    \"AF8\",\n",
    "    \"AF4\",\n",
    "    \"AFz\",\n",
    "    \"Fz\",\n",
    "    \"F2\",\n",
    "    \"F4\",\n",
    "    \"F6\",\n",
    "    \"F8\",\n",
    "    \"FT8\",\n",
    "    \"FC6\",\n",
    "    \"FC4\",\n",
    "    \"FC2\",\n",
    "    \"FCz\",\n",
    "    \"Cz\",\n",
    "    \"C2\",\n",
    "    \"C4\",\n",
    "    \"C6\",\n",
    "    \"T8\",\n",
    "    \"TP8\",\n",
    "    \"CP6\",\n",
    "    \"CP4\",\n",
    "    \"CP2\",\n",
    "    \"P2\",\n",
    "    \"P4\",\n",
    "    \"P6\",\n",
    "    \"P8\",\n",
    "    \"P10\",\n",
    "    \"PO8\",\n",
    "    \"PO4\",\n",
    "    \"O2\",\n",
    "]\n",
    "\n",
    "channels_dict = dict(zip(channels_order_list, np.arange(0, 64, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c412f36-66a2-4fd8-bfa7-caa98c4a315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_data(\n",
    "    test_participants=False,\n",
    "    test_epochs=False,\n",
    "    info_filename=None,\n",
    "    info=\"all\",\n",
    "    personal=True,\n",
    "):\n",
    "    \"\"\"Loads data for all participants and create DataFrame with optional additional info from given .csv file.\n",
    "\n",
    "    On default, loads a train set: chooses only 80% of participants\n",
    "    and for each of them chooses 80% of epochs.\n",
    "    It will choose them deterministically.\n",
    "\n",
    "    Participants with less than 10 epochs per condition are rejected.\n",
    "\n",
    "    If test_participants is set to True, it will load remaining 20% of participants.\n",
    "    If test_epochs is set to True, it will load remaining 20% of epochs.\n",
    "    Test epochs are chronologically after train epochs,\n",
    "    because it reflects real usage (first callibration and then classification).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_participants: bool\n",
    "        whether load data for training or final testing.\n",
    "        If true load participants data for testing.\n",
    "    test_epochs: bool\n",
    "        whether load data for training or final testing.\n",
    "        If true load epochs of each participants data for testing.\n",
    "    info_filename: String | None\n",
    "        path to .csv file with additional data.\n",
    "    info: array\n",
    "        listed parameters from the info file to be loaded.\n",
    "        if 'all', load all parameters\n",
    "    personal: bool\n",
    "        whether a model will be both trained and tested on epochs from one person\n",
    "        if false, person's epochs aren't split into test and train\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    go_nogo_data_df : pandas.DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "    print(os.path.abspath(\"\"))\n",
    "    dir_path = os.path.dirname(os.path.abspath(\"\"))\n",
    "    print(dir_path)\n",
    "    header_files_glob = os.path.join(dir_path, \"data/responses_400_600/*.vhdr\")\n",
    "    header_files = glob.glob(header_files_glob)\n",
    "\n",
    "    header_files = sorted(header_files)\n",
    "    go_nogo_data_df = pd.DataFrame()\n",
    "\n",
    "    # cut 20% of data for testing\n",
    "    h_train, h_test = train_test_split(header_files, test_size=0.2, random_state=0)\n",
    "\n",
    "    if test_participants:\n",
    "        header_files = h_test\n",
    "    else:\n",
    "        header_files = h_train\n",
    "\n",
    "    for file in header_files:\n",
    "        #  load eeg data for given participant\n",
    "        participant_epochs = load_epochs_from_file(file)\n",
    "\n",
    "        # and compute participant's id from file_name\n",
    "        participant_id = re.match(r\".*_(\\w+).*\", file).group(1)\n",
    "\n",
    "        error = participant_epochs[\"error_response\"]._data\n",
    "        correct = participant_epochs[\"correct_response\"]._data\n",
    "\n",
    "        # exclude those participants who have too few samples\n",
    "        if len(error) < 5 or len(correct) < 5:\n",
    "            # not enough data for this participant\n",
    "            continue\n",
    "\n",
    "        if personal:\n",
    "            # cut 20% of each participant's epochs for testing\n",
    "            # shuffling is disabled to make sure test epochs are after train epochs\n",
    "            # TODO: not sure if this step is necessary\n",
    "            err_train, err_test = train_test_split(error, test_size=0.2, shuffle=False)\n",
    "            cor_train, cor_test = train_test_split(\n",
    "                correct, test_size=0.2, shuffle=False\n",
    "            )\n",
    "            if test_epochs:\n",
    "                error = err_test\n",
    "                correct = cor_test\n",
    "            else:\n",
    "                error = err_train\n",
    "                correct = cor_train\n",
    "\n",
    "        # construct dataframe for participant with: id|epoch_data|response_type|additional info...\n",
    "        participant_df = create_df_from_epochs(\n",
    "            participant_id, correct, error, info_filename, info\n",
    "        )\n",
    "        print(participant_id)\n",
    "        go_nogo_data_df = go_nogo_data_df.append(participant_df, ignore_index=True)\n",
    "\n",
    "    return go_nogo_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0991419b-7acd-42bc-b048-e5e9fa3cb3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_from_epochs(id, correct, error, info_filename, info):\n",
    "    \"\"\"Create df for each participant. DF structure is like: {id: String ; epoch: epoch_data ; marker: 1.0|0.0}\n",
    "    1.0 means correct and 0.0 means error response.\n",
    "    Default info extracted form .csv file is 'Rumination Full Scale' and participants' ids.\n",
    "    With this info df structure is like:\n",
    "    {id: String ; epoch: epoch_data ; marker: 1.0|0.0 ; File: id ; 'Rumination Full Scale': int}\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    id: String\n",
    "        participant's id extracted from filename\n",
    "    correct: array\n",
    "        correct responses' data\n",
    "    error: array\n",
    "        error responses' data\n",
    "    info_filename: String\n",
    "        path to .csv file with additional data.\n",
    "    info: array\n",
    "        listed parameters from the info file to be loaded.\n",
    "        if 'all', load all parameters\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    participant_df : pandas.DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "    participant_df = pd.DataFrame()\n",
    "    info_df = pd.DataFrame()\n",
    "\n",
    "    # get additional info from file\n",
    "    if info_filename is not None:\n",
    "        if info == \"all\":\n",
    "            rumination_df = pd.read_csv(info_filename)\n",
    "        else:\n",
    "            rumination_df = pd.read_csv(info_filename, usecols=[\"File\"] + info)\n",
    "        info_df = (\n",
    "            rumination_df.loc[rumination_df[\"File\"] == id]\n",
    "            .reset_index()\n",
    "            .drop(\"index\", axis=1)\n",
    "        )\n",
    "\n",
    "    for epoch in correct:\n",
    "        epoch_df = pd.DataFrame(\n",
    "            {\"id\": [id], \"epoch\": [epoch], \"marker\": [CORRECT]}\n",
    "        ).join(info_df)\n",
    "        participant_df = participant_df.append(epoch_df, ignore_index=True)\n",
    "\n",
    "    for epoch in error:\n",
    "        epoch_df = pd.DataFrame({\"id\": [id], \"epoch\": [epoch], \"marker\": [ERROR]}).join(\n",
    "            info_df\n",
    "        )\n",
    "        participant_df = participant_df.append(epoch_df, ignore_index=True)\n",
    "\n",
    "    return participant_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa88517e-884a-4b5b-9652-1bf2e7787aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_epochs_from_file(file, reject_bad_segments=\"auto\", mask=None):\n",
    "    \"\"\"Load epochs from a header file.\n",
    "\n",
    "    Args:\n",
    "        file: path to a header file (.vhdr)\n",
    "        reject_bad_segments: 'auto' means that bad segments are rejected automatically.\n",
    "\n",
    "    Returns:\n",
    "        mne Epochs\n",
    "\n",
    "    \"\"\"\n",
    "    # Import the BrainVision data into an MNE Raw object\n",
    "    raw = mne.io.read_raw_brainvision(file)\n",
    "\n",
    "    # Construct annotation filename\n",
    "    annot_file = file[:-4] + \"vmrk\"\n",
    "\n",
    "    # Read in the event information as MNE annotations\n",
    "    annotations = mne.read_annotations(annot_file)\n",
    "\n",
    "    # Add the annotations to our raw object so we can use them with the data\n",
    "    raw.set_annotations(annotations)\n",
    "\n",
    "    # Map with response markers only\n",
    "    event_dict = {\n",
    "        \"Stimulus/RE*ex*1_n*1_c_1*R*FB\": 10004,\n",
    "        \"Stimulus/RE*ex*1_n*1_c_1*R*FG\": 10005,\n",
    "        \"Stimulus/RE*ex*1_n*1_c_2*R\": 10006,\n",
    "        \"Stimulus/RE*ex*1_n*2_c_1*R\": 10007,\n",
    "        \"Stimulus/RE*ex*2_n*1_c_1*R\": 10008,\n",
    "        \"Stimulus/RE*ex*2_n*2_c_1*R*FB\": 10009,\n",
    "        \"Stimulus/RE*ex*2_n*2_c_1*R*FG\": 10010,\n",
    "        \"Stimulus/RE*ex*2_n*2_c_2*R\": 10011,\n",
    "    }\n",
    "\n",
    "    # Map for merged correct/error response markers\n",
    "    merged_event_dict = {\"correct_response\": 0, \"error_response\": 1}\n",
    "\n",
    "    # Reconstruct the original events from Raw object\n",
    "    events, event_ids = mne.events_from_annotations(raw, event_id=event_dict)\n",
    "\n",
    "    # Merge correct/error response events\n",
    "    merged_events = mne.merge_events(\n",
    "        events,\n",
    "        [10004, 10005, 10009, 10010],\n",
    "        merged_event_dict[\"correct_response\"],\n",
    "        replace_events=True,\n",
    "    )\n",
    "    merged_events = mne.merge_events(\n",
    "        merged_events,\n",
    "        [10006, 10007, 10008, 10011],\n",
    "        merged_event_dict[\"error_response\"],\n",
    "        replace_events=True,\n",
    "    )\n",
    "\n",
    "    epochs = []\n",
    "    bads = []\n",
    "    this_reject_by_annotation = True\n",
    "\n",
    "    # Read epochs\n",
    "    epochs = mne.Epochs(\n",
    "        raw=raw,\n",
    "        events=merged_events,\n",
    "        event_id=merged_event_dict,\n",
    "        tmin=tmin,\n",
    "        tmax=tmax,\n",
    "        baseline=None,\n",
    "        reject_by_annotation=this_reject_by_annotation,\n",
    "        preload=True,\n",
    "    )\n",
    "\n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db5e07d-9618-47de-a706-687a529fb2fe",
   "metadata": {},
   "source": [
    "#### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db8c673-5477-4126-b09d-870a8fcd9477",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = \"go_nogo_100_600_df_3-5\"\n",
    "pickled_data_filename = \"../data/\" + df_name + \".pkl\"\n",
    "info_filename = \"../data/Demographic_Questionnaires_Behavioral_Results_N=163.csv\"\n",
    "\n",
    "# Check if data is already loaded\n",
    "if os.path.isfile(pickled_data_filename):\n",
    "    print(\"Pickled file found. Loading pickled data...\")\n",
    "    epochs_df = pd.read_pickle(pickled_data_filename)\n",
    "    print(\"Done\")\n",
    "else:\n",
    "    print(\"Pickled file not found. Loading data...\")\n",
    "    epochs_df = create_df_data(\n",
    "        test_participants=False, info=\"all\", personal=False, info_filename=info_filename\n",
    "    )\n",
    "    epochs_df.name = df_name\n",
    "    # save loaded data into a pickle file\n",
    "    epochs_df.to_pickle(\"../data/\" + epochs_df.name + \".pkl\")\n",
    "    print(\"Done. Pickle file created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055815fa-0d47-4bdd-9caf-51d60ced5d91",
   "metadata": {},
   "source": [
    "#### Read data for external testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c990ac1-14fc-4d0c-bf5d-d96f076e1e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = \"go_nogo_100_600_test_df_3-5\"\n",
    "pickled_data_filename = \"../data/\" + df_name + \".pkl\"\n",
    "info_filename = \"../data/Demographic_Questionnaires_Behavioral_Results_N=163.csv\"\n",
    "\n",
    "# Check if data is already loaded\n",
    "if os.path.isfile(pickled_data_filename):\n",
    "    print(\"Pickled file found. Loading pickled data...\")\n",
    "    epochs_test_df = pd.read_pickle(pickled_data_filename)\n",
    "    print(\"Done\")\n",
    "else:\n",
    "    print(\"Pickled file not found. Loading data...\")\n",
    "    epochs_test_df = create_df_data(\n",
    "        test_participants=True, info=\"all\", personal=False, info_filename=info_filename\n",
    "    )\n",
    "    epochs_test_df.name = df_name\n",
    "    # save loaded data into a pickle file\n",
    "    epochs_test_df.to_pickle(\"../data/\" + epochs_test_df.name + \".pkl\")\n",
    "    print(\"Done. Pickle file created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb16019e-062f-453d-a30e-363fff670393",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Rearrange data:  from: *one row - one epoch* to *one row - one participant* \n",
    "\n",
    "epochs column contain list of epochs from given condition (marker = error or correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8df7179-4753-45e0-96f9-6a9e62336f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = (\n",
    "    epochs_df.groupby(\n",
    "        [\"id\", \"marker\"],\n",
    "        sort=False,\n",
    "    )\n",
    "    .apply(\n",
    "        lambda group_df: pd.Series(\n",
    "            {\n",
    "                \"epochs\": np.array(group_df[\"epoch\"].to_list(), dtype=\"float64\"),\n",
    "                # \"ern\": np.array(group_df[\"ern\"].to_list(), dtype=\"float64\"),\n",
    "                # \"pe\": np.array(group_df[\"pe\"].to_list(), dtype=\"float64\"),\n",
    "                \"Rumination\": np.mean(group_df[\"Rumination Full Scale\"]),\n",
    "                \"Anxiety\": np.mean(group_df[\"DASS-21 Anxiety scale\"]),\n",
    "                \"Stress\": np.mean(group_df[\"DASS-21 Stress scale\"]),\n",
    "                \"Depression\": np.mean(group_df[\"DASS-21 Depression scale\"]),\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "X_df = data_df[data_df['marker'] == ERROR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659a96a5-d46b-4f75-a4ea-8ce81d04a6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449269ab-f50c-425a-b624-c6e9c1d10ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_df = (\n",
    "    epochs_test_df.groupby(\n",
    "        [\"id\", \"marker\"],\n",
    "        sort=False,\n",
    "    )\n",
    "    .apply(\n",
    "        lambda group_test_df: pd.Series(\n",
    "            {\n",
    "                \"epochs\": np.array(group_test_df[\"epoch\"].to_list(), dtype=\"float64\"),\n",
    "                # \"ern\": np.array(group_df[\"ern\"].to_list(), dtype=\"float64\"),\n",
    "                # \"pe\": np.array(group_df[\"pe\"].to_list(), dtype=\"float64\"),\n",
    "                \"Rumination\": np.mean(group_test_df[\"Rumination Full Scale\"]),\n",
    "                \"Anxiety\": np.mean(group_test_df[\"DASS-21 Anxiety scale\"]),\n",
    "                \"Stress\": np.mean(group_test_df[\"DASS-21 Stress scale\"]),\n",
    "                \"Depression\": np.mean(group_test_df[\"DASS-21 Depression scale\"]),\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "X_test_df = data_test_df[data_test_df['marker'] == ERROR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7098ac4c-bd40-4ea9-a136-b3877f17efbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7308d796-9764-4562-9377-4f30473a6d68",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a1985f-accc-498e-a33f-17bc26d6304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = (\n",
    "    epochs_df.groupby(\n",
    "        [\"id\", \"marker\"],\n",
    "        sort=False,\n",
    "    )\n",
    "    .size()\n",
    "    .reset_index(name=\"counts\")\n",
    ")\n",
    "\n",
    "participants_data_len = np.array(\n",
    "    summary_df[summary_df[\"marker\"] == 0][\"counts\"].tolist()\n",
    ")\n",
    "\n",
    "# participant data indices for identifying participants data after spatial filtering\n",
    "\n",
    "participants_data_indices = []\n",
    "index = 0\n",
    "\n",
    "for participant_len in participants_data_len:\n",
    "    participant_indices = (index, index + participant_len - 1)\n",
    "    participants_data_indices.append(participant_indices)\n",
    "    index = index + participant_len\n",
    "\n",
    "participants_data_indices = np.array(participants_data_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fea2478-01a2-499e-b6bb-b20e580c0676",
   "metadata": {},
   "source": [
    "---\n",
    "## Training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dff3a8-14a7-445c-8940-aba32c28ef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import permutation_test_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from tempfile import mkdtemp\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a593d8-7928-410c-88b9-0b4b25f1c493",
   "metadata": {},
   "source": [
    "#### Create X train and y train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7afda6e-cc8b-492f-bb80-ac3a0b0cde44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection of the analysed condition: erroneous responses or correct responses\n",
    "\n",
    "dataset = ERROR\n",
    "dataset_name = \"correct\" if dataset == CORRECT else \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6f1ac9-2bd1-46c6-b404-a394ac24603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape 4-D: participant x epoch x channel x timepoints\n",
    "# X_train = np.array(data_df[data_df[\"marker\"] == dataset][\"epochs\"].tolist())\n",
    "\n",
    "# dataframe where 1 row = one participant and 'epochs' column consists of 4-array: participant x epoch x channel x timepoints\n",
    "X_train = X_df\n",
    "\n",
    "# shape 1-D: rumination score\n",
    "rumination = np.array(\n",
    "    data_df[data_df[\"marker\"] == dataset][\"Rumination\"].to_list()\n",
    ")\n",
    "\n",
    "anxiety = np.array(data_df[data_df[\"marker\"] == dataset][\"Anxiety\"].to_list())\n",
    "stress = np.array(data_df[data_df[\"marker\"] == dataset][\"Stress\"].to_list())\n",
    "depression = np.array(data_df[data_df[\"marker\"] == dataset][\"Depression\"].to_list())\n",
    "\n",
    "y_train = rumination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889f04e5-5e91-42df-a5a2-1a5e28a92e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rum = np.array(\n",
    "    data_test_df[data_test_df[\"marker\"] == dataset][\"Rumination\"].to_list()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b37add-c98f-4625-8049-6a2bd087b013",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd66b12-5ea1-42ab-985d-575ab9f81191",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a366c3c6-dd06-4837-9bd8-a286d9c530f6",
   "metadata": {},
   "source": [
    "---\n",
    "### Experiments \n",
    "\n",
    "Parameters of experiments:\n",
    "- regressors\n",
    "- hyperparameters\n",
    "- preprocessing pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d962b4be-4bc7-4e61-9bb7-4151a2f59008",
   "metadata": {},
   "source": [
    "#### Prepare experiment estimating \n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75fe861-b8ef-4c53-a68c-5241ba5348ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating model with grid search\n",
    "\n",
    "\n",
    "def rate_regressor(\n",
    "    X_train, y_train, X_test, y_test, regressor, regressor_params, base_steps, cv=3\n",
    "):\n",
    "    # define cross-validation method\n",
    "    cv_kf = KFold(n_splits=3)\n",
    "\n",
    "    pipeline = Pipeline([base_steps, regressor])\n",
    "    param_grid = regressor_params\n",
    "    # print(f\"Param grid {param_grid}\")\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid,\n",
    "        cv=cv_kf,\n",
    "        scoring={\"r2\", \"neg_mean_absolute_error\", \"neg_mean_squared_error\"},\n",
    "        refit=\"r2\",\n",
    "        return_train_score=True,\n",
    "        n_jobs=10,\n",
    "        verbose=1,\n",
    "        error_score=\"raise\",\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ce1e5-4ec9-4ab1-b3d7-28a80d119ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conducting experiment and saving selected info do result df\n",
    "\n",
    "\n",
    "def run_experiment(\n",
    "    tested_regressors,\n",
    "    regressor_params,\n",
    "    pipeline_name,\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test,\n",
    "    dataset_name,\n",
    "    base_steps,\n",
    "    preprocessed_pipeline,\n",
    "    X_test_df,\n",
    "    y_rum,\n",
    "    results_df,\n",
    "):\n",
    "\n",
    "    for (regressor, params) in tested_regressors:\n",
    "        print(f\"Rating {regressor} \\n\")\n",
    "        tested_params = {**regressor_params, **params}\n",
    "\n",
    "        # enter to grid search\n",
    "        grid_result = rate_regressor(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            X_test,\n",
    "            y_test,\n",
    "            regressor,\n",
    "            tested_params,\n",
    "            base_steps,\n",
    "            cv=3,\n",
    "        )\n",
    "\n",
    "        #     predictions = grid_result.predict(X_test)\n",
    "        #     r2 = grid_result.score(X_test, y_test)\n",
    "        #     mae = mean_absolute_error(y_test, predictions)\n",
    "        #     r2_adj = r2_adjusted_scorer(y_test, predictions, len(X_test[0]), len(X_test))\n",
    "\n",
    "        best_estimator_index = grid_result.best_index_\n",
    "        mean_cv_r2 = grid_result.cv_results_[\"mean_test_r2\"][best_estimator_index]\n",
    "        std_cv_r2 = grid_result.cv_results_[\"std_test_r2\"][best_estimator_index]\n",
    "        mean_cv_neg_mean_absolute_error = grid_result.cv_results_[\n",
    "            \"mean_test_neg_mean_absolute_error\"\n",
    "        ][best_estimator_index]\n",
    "        std_cv_neg_mean_absolute_error = grid_result.cv_results_[\n",
    "            \"std_test_neg_mean_absolute_error\"\n",
    "        ][best_estimator_index]\n",
    "        mean_cv_neg_mean_squared_error = grid_result.cv_results_[\n",
    "            \"mean_test_neg_mean_squared_error\"\n",
    "        ][best_estimator_index]\n",
    "        std_cv_neg_mean_squared_error = grid_result.cv_results_[\n",
    "            \"std_test_neg_mean_squared_error\"\n",
    "        ][best_estimator_index]\n",
    "        \n",
    "        mean_train_r2 = grid_result.cv_results_[\"mean_train_r2\"][best_estimator_index]\n",
    "        mean_train_mae = grid_result.cv_results_[\"mean_train_neg_mean_absolute_error\"][best_estimator_index]\n",
    "        mean_train_mse = grid_result.cv_results_[\"mean_train_neg_mean_squared_error\"][best_estimator_index]\n",
    "\n",
    "\n",
    "        print(f\"     Best parameters: {grid_result.best_params_}\")\n",
    "        print(f\"     mean r2: {mean_cv_r2}           Â± {round(std_cv_r2,3)}\")\n",
    "        print(f\"     mean r2 train: {mean_train_r2}\")\n",
    "\n",
    "        cv_results = grid_result.cv_results_\n",
    "\n",
    "        # calculate p-value\n",
    "        scores_, pvalue_ = calculate_p_permutations(\n",
    "            grid_result.best_estimator_, X_train, y_train\n",
    "        )\n",
    "        \n",
    "        pre_processed_test_X = preprocessed_pipeline.transform(X_test_df)\n",
    "        estimator = grid_result.best_estimator_\n",
    "        score = estimator.score(pre_processed_test_X, y_rum)\n",
    "        \n",
    "        print(print(f\"     external validation r2: {score}\"))\n",
    "        \n",
    "\n",
    "        # insert selected info to df\n",
    "        data = {\n",
    "            \"data_set\": dataset_name,\n",
    "            \"pipeline_name\": pipeline_name,\n",
    "            \"model\": regressor[0],\n",
    "            \"parameters\": grid_result.best_params_,\n",
    "            \"mean_cv_r2\": mean_cv_r2,\n",
    "            \"std_cv_r2\": std_cv_r2,\n",
    "            \"mean_cv_mae\": mean_cv_neg_mean_absolute_error,\n",
    "            \"std_cv_mae\": std_cv_neg_mean_absolute_error,\n",
    "            \"mean_cv_mse\":mean_cv_neg_mean_squared_error,\n",
    "            \"std_cv_mse\": std_cv_neg_mean_squared_error,\n",
    "            \"cv_results\": cv_results,\n",
    "            \"mean_train_r2\": mean_train_r2,\n",
    "            \"mean_train_mae\":mean_train_mae,\n",
    "            \"mean_train_mse\":mean_train_mse,\n",
    "            \"p-value\": pvalue_,\n",
    "            \"best_estimator\": grid_result.best_estimator_,\n",
    "            \"pre_processed_pipeline\": preprocessed_pipeline,\n",
    "            \"external_score\":score\n",
    "        }\n",
    "\n",
    "        results_df = results_df.append(data, ignore_index=True)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bfa7df-bda2-4249-97c5-999e73d1abbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating p-value with permutation test\n",
    "\n",
    "\n",
    "def calculate_p_permutations(estimator, X, y, cv=3, n_permutations=100, n_jobs=10):\n",
    "\n",
    "    score_, perm_scores_, pvalue_ = permutation_test_score(\n",
    "        estimator, X, y, cv=cv, n_permutations=n_permutations, n_jobs=n_jobs\n",
    "    )\n",
    "\n",
    "    # summarize\n",
    "    print(f\"     The permutation P-value is = {pvalue_:.3f}\")\n",
    "    print(f\"     The permutation score is = {score_:.3f}\\n\")\n",
    "\n",
    "    return score_, pvalue_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0386ed08-cb1a-4cf4-ac0a-9ffa8e324f05",
   "metadata": {},
   "source": [
    "#### Define pipelines\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad7ad2a-3ed6-41dd-acdd-e03b8a0aab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rumination_experiment_transformers_averaged import *\n",
    "\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae44fab-a74f-4e47-acce-a324c9b79899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPATIAL FILTER - BINS\n",
    "\n",
    "\n",
    "def spatial_filter_bins_steps(spatial_filter_n_components, timepoints_count):\n",
    "\n",
    "    steps = [\n",
    "               (\"extract_epochs\", EEGdata(dataset=dataset)),\n",
    "        # (\"narrow_indices\", NarrowIndices(start=101, stop=257)),\n",
    "        (\n",
    "            \"channels_filtering\",\n",
    "            ChannelExtraction(significant_channels)\n",
    "        ),\n",
    "        (\n",
    "            \"average_epochs\",\n",
    "            AveragePerParticipant(),\n",
    "        ),\n",
    "        (\"spatial_filter_preprocessing\", SpatialFilterPreprocessing()),\n",
    "        (\n",
    "            \"spatial_filter\",\n",
    "            PCA(n_components=spatial_filter_n_components, random_state=random_state),\n",
    "        ),\n",
    "        (\n",
    "            \"spatial_filter_postprocessing\",\n",
    "            SpatialFilterPostprocessing(\n",
    "                timepoints_count=timepoints_count,\n",
    "            ),\n",
    "        ),\n",
    "        (\"lowpass_filter\", LowpassFilter()),\n",
    "        (\"binning\", BinTransformer(step=step_tp)),\n",
    "        (\"data_channel_swap\", ChannelDataSwap()),\n",
    "        (\"postprocessing\", PostprocessingTransformer()),\n",
    "    ]\n",
    "\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00333aa-c223-4ea5-a67f-d4b920e59241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPATIAL FILTER - BINS - UNION\n",
    "\n",
    "\n",
    "def spatial_filter_bins_union_features(spatial_filter_n_components, timepoints_count):\n",
    "\n",
    "    ern_features = Pipeline(steps=[\n",
    "                    (\"ern_data_extraction\", ErnTransformer()),\n",
    "                    # (\"ern_min_max_features\", ErnMinMaxFeatures()),\n",
    "                    (\"ern_amplitude\", ErnAmplitude2()),\n",
    "                    (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                    (\"postprocessing\", PostprocessingTransformer()),\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    (\"feature_selection\", FastICA(random_state=random_state))\n",
    "    ])\n",
    "\n",
    "    pe_features = Pipeline(steps = [\n",
    "                    (\"pe_data_extraction\", PeTransformer()),\n",
    "                    # (\"pe_min_max_features\", PeMinMaxFeatures()),\n",
    "                    (\"pe_amplitude\", PeAmplitude2()),\n",
    "                    (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                    (\"postprocessing\", PostprocessingTransformer()),\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    (\"feature_selection\", FastICA(random_state=random_state))\n",
    "    ])\n",
    "    \n",
    "    ern_pe_features = FeatureUnion([(\"ern_features\", ern_features), (\"pe_features\", pe_features)], n_jobs = 10)\n",
    "\n",
    "    features = Pipeline([\n",
    "        # (\"extract_epochs\", EEGdata(dataset=dataset)),\n",
    "        # (\n",
    "        #     \"channels_filtering\",\n",
    "        #     ChannelExtraction(significant_channels)\n",
    "        # ),\n",
    "        # (\n",
    "        #     \"average_epochs\",\n",
    "        #     AveragePerParticipant(),\n",
    "        # ),\n",
    "        # (\"spatial_filter_preprocessing\", SpatialFilterPreprocessing()),\n",
    "        # (\n",
    "        #     \"spatial_filter\",\n",
    "        #     PCA(n_components=spatial_filter_n_components, random_state=random_state),\n",
    "        # ),\n",
    "        # (\n",
    "        #     \"spatial_filter_postprocessing\",\n",
    "        #     SpatialFilterPostprocessing(\n",
    "        #         timepoints_count=timepoints_count,\n",
    "        #     ),\n",
    "        # ),\n",
    "        # (\"lowpass_filter\", LowpassFilter()),\n",
    "        # (\"binning\", BinTransformer(step=step_tp)),\n",
    "        ('ern_pe_features', ern_pe_features)\n",
    "    \n",
    "    ])\n",
    "        \n",
    "    steps = ('features', features)\n",
    "\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09edcc05-9539-4c74-9a81-531c9ee91373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPATIAL FILTER - BINS - UNION\n",
    "\n",
    "\n",
    "def spatial_filter_bins_union_amplitude(spatial_filter_n_components, timepoints_count):\n",
    "\n",
    "    ern_features = Pipeline(steps=[\n",
    "                    (\"ern_amplitude\", ErnAmplitude()),\n",
    "                    (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                    (\"postprocessing\", PostprocessingTransformer()),\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    (\"feature_selection\", FastICA(random_state=random_state))\n",
    "    ])\n",
    "\n",
    "    pe_features = Pipeline(steps = [\n",
    "                    (\"pe_amplitude\", PeAmplitude()),\n",
    "                    (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                    (\"postprocessing\", PostprocessingTransformer()),\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    (\"feature_selection\", FastICA(random_state=random_state))\n",
    "    ])\n",
    "    \n",
    "    ern_pe_features = FeatureUnion([(\"ern_features\", ern_features), (\"pe_features\", pe_features)], n_jobs = 10)\n",
    "\n",
    "    features = Pipeline([\n",
    "        # (\"extract_epochs\", EEGdata(dataset=dataset)),\n",
    "        # (\n",
    "        #     \"channels_filtering\",\n",
    "        #     ChannelExtraction(significant_channels)\n",
    "        # ),\n",
    "        # (\n",
    "        #     \"average_epochs\",\n",
    "        #     AveragePerParticipant(),\n",
    "        # ),\n",
    "        # (\"spatial_filter_preprocessing\", SpatialFilterPreprocessing()),\n",
    "        # (\n",
    "        #     \"spatial_filter\",\n",
    "        #     PCA(n_components=spatial_filter_n_components, random_state=random_state),\n",
    "        # ),\n",
    "        # (\n",
    "        #     \"spatial_filter_postprocessing\",\n",
    "        #     SpatialFilterPostprocessing(\n",
    "        #         timepoints_count=timepoints_count,\n",
    "        #     ),\n",
    "        # ),\n",
    "        # (\"lowpass_filter\", LowpassFilter()),\n",
    "        # (\"binning\", BinTransformer(step=step_tp)),\n",
    "        ('ern_pe_features', ern_pe_features)\n",
    "    \n",
    "    ])\n",
    "        \n",
    "    steps = ('features', features)\n",
    "\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9813d9-0940-4d13-9b67-bb6c95b128a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPATIAL FILTER - BINS - UNION\n",
    "\n",
    "\n",
    "def spatial_filter_bins_union_min_max_features(spatial_filter_n_components, timepoints_count):\n",
    "\n",
    "    ern_features = Pipeline(steps=[\n",
    "                    (\"ern_data_extraction\", ErnTransformer()),\n",
    "                    (\"ern_min_max_features\", ErnMinMaxFeatures()),\n",
    "                    # (\"ern_amplitude\", ErnAmplitude()),\n",
    "                    (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                    (\"postprocessing\", PostprocessingTransformer()),\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    (\"feature_selection\", FastICA(random_state=random_state))\n",
    "    ])\n",
    "\n",
    "    pe_features = Pipeline(steps = [\n",
    "                    (\"pe_data_extraction\", PeTransformer()),\n",
    "                    (\"pe_min_max_features\", ErnMinMaxFeatures()),\n",
    "                    # (\"pe_amplitude\", PeAmplitude()),\n",
    "                    (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                    (\"postprocessing\", PostprocessingTransformer()),\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    (\"feature_selection\", FastICA(random_state=random_state))\n",
    "    ])\n",
    "    \n",
    "    ern_pe_features = FeatureUnion([(\"ern_features\", ern_features), (\"pe_features\", pe_features)], n_jobs = 10)\n",
    "\n",
    "    features = Pipeline([\n",
    "        # (\"extract_epochs\", EEGdata(dataset=dataset)),\n",
    "        # (\n",
    "        #     \"channels_filtering\",\n",
    "        #     ChannelExtraction(significant_channels)\n",
    "        # ),\n",
    "        # (\n",
    "        #     \"average_epochs\",\n",
    "        #     AveragePerParticipant(),\n",
    "        # ),\n",
    "        # (\"spatial_filter_preprocessing\", SpatialFilterPreprocessing()),\n",
    "        # (\n",
    "        #     \"spatial_filter\",\n",
    "        #     PCA(n_components=spatial_filter_n_components, random_state=random_state),\n",
    "        # ),\n",
    "        # (\n",
    "        #     \"spatial_filter_postprocessing\",\n",
    "        #     SpatialFilterPostprocessing(\n",
    "        #         timepoints_count=timepoints_count,\n",
    "        #     ),\n",
    "        # ),\n",
    "        # (\"lowpass_filter\", LowpassFilter()),\n",
    "        # (\"binning\", BinTransformer(step=step_tp)),\n",
    "        ('ern_pe_features', ern_pe_features)\n",
    "    \n",
    "    ])\n",
    "        \n",
    "    steps = ('features', features)\n",
    "\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714e8757-c5b6-43b8-ae1a-bb279c5b5083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPATIAL FILTER - BINS - UNION\n",
    "\n",
    "\n",
    "def spatial_filter_bins_union_plain_features(spatial_filter_n_components, timepoints_count):\n",
    "\n",
    "    ern_features = Pipeline(steps=[\n",
    "                    (\"ern_data_extraction\", ErnTransformer()),\n",
    "                    # (\"ern_min_max_features\", ErnMinMaxFeatures()),\n",
    "                    # (\"ern_amplitude\", ErnAmplitude()),\n",
    "                    (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                    (\"postprocessing\", PostprocessingTransformer()),\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    (\"feature_selection\", FastICA(random_state=random_state))\n",
    "    ])\n",
    "\n",
    "    pe_features = Pipeline(steps = [\n",
    "                    (\"pe_data_extraction\", PeTransformer()),\n",
    "                    # (\"pe_min_max_features\", ErnMinMaxFeatures()),\n",
    "                    # (\"pe_amplitude\", PeAmplitude()),\n",
    "                    (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                    (\"postprocessing\", PostprocessingTransformer()),\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    (\"feature_selection\", FastICA(random_state=random_state))\n",
    "    ])\n",
    "    \n",
    "    ern_pe_features = FeatureUnion([(\"ern_features\", ern_features), (\"pe_features\", pe_features)], n_jobs = 10)\n",
    "\n",
    "    features = Pipeline([\n",
    "        # (\"extract_epochs\", EEGdata(dataset=dataset)),\n",
    "        # (\n",
    "        #     \"channels_filtering\",\n",
    "        #     ChannelExtraction(significant_channels)\n",
    "        # ),\n",
    "        # (\n",
    "        #     \"average_epochs\",\n",
    "        #     AveragePerParticipant(),\n",
    "        # ),\n",
    "        # (\"spatial_filter_preprocessing\", SpatialFilterPreprocessing()),\n",
    "        # (\n",
    "        #     \"spatial_filter\",\n",
    "        #     PCA(n_components=spatial_filter_n_components, random_state=random_state),\n",
    "        # ),\n",
    "        # (\n",
    "        #     \"spatial_filter_postprocessing\",\n",
    "        #     SpatialFilterPostprocessing(\n",
    "        #         timepoints_count=timepoints_count,\n",
    "        #     ),\n",
    "        # ),\n",
    "        # (\"lowpass_filter\", LowpassFilter()),\n",
    "        # (\"binning\", BinTransformer(step=step_tp)),\n",
    "        ('ern_pe_features', ern_pe_features)\n",
    "    \n",
    "    ])\n",
    "        \n",
    "    steps = ('features', features)\n",
    "\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1f6b5a-ebe8-4605-956d-8344538ebe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_filter_union_bins_features(spatial_filter_n_components, timepoints_count):\n",
    "\n",
    "    ern_features = Pipeline(steps=[\n",
    "                    (\"ern_data_extraction\", ErnTransformerTP()),\n",
    "                    (\"binning\", BinTransformer(step=step_tp)),\n",
    "                    (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                    (\"postprocessing\", PostprocessingTransformer()),\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    (\"feature_selection\", FastICA(random_state=random_state))])\n",
    "\n",
    "    pe_features = Pipeline(steps = [\n",
    "                    (\"pe_data_extraction\", PeTransformerTP()),\n",
    "                    (\"binning\", BinTransformer(step=step_tp)),\n",
    "                    (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                    (\"postprocessing\", PostprocessingTransformer()),\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    (\"feature_selection\", FastICA(random_state=random_state))])\n",
    "    \n",
    "    ern_pe_features = FeatureUnion([(\"ern_features\", ern_features), (\"pe_features\", pe_features)], n_jobs = 10)\n",
    "\n",
    "    features = Pipeline([\n",
    "        # (\"extract_epochs\", EEGdata(dataset=dataset)),\n",
    "        # (\n",
    "        #     \"channels_filtering\",\n",
    "        #     ChannelExtraction(significant_channels)\n",
    "        # ),\n",
    "        # (\n",
    "        #     \"average_epochs\",\n",
    "        #     AveragePerParticipant(),\n",
    "        # ),\n",
    "        # (\"spatial_filter_preprocessing\", SpatialFilterPreprocessing()),\n",
    "        # (\n",
    "        #     \"spatial_filter\",\n",
    "        #     PCA(n_components=spatial_filter_n_components, random_state=random_state),\n",
    "        # ),\n",
    "        # (\n",
    "        #     \"spatial_filter_postprocessing\",\n",
    "        #     SpatialFilterPostprocessing(\n",
    "        #         timepoints_count=timepoints_count,\n",
    "        #     ),\n",
    "        # ),\n",
    "        # (\"lowpass_filter\", LowpassFilter()),\n",
    "        # (\"binning\", BinTransformer(step=step_tp)),\n",
    "        ('ern_pe_features', ern_pe_features)\n",
    "    \n",
    "    ])\n",
    "        \n",
    "    steps = ('features', features)\n",
    "\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83ee71c-c8eb-4d8d-a266-d9f1d8060964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_filter_centered_components(spatial_filter_n_components, timepoints_count):\n",
    "\n",
    "    ern_features = Pipeline(steps=[\n",
    "                    (\"ern_extraction\", CenteredERN(step=12)),\n",
    "                    (\"binning\", BinTransformer(step=12)),\n",
    "                    (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                    (\"postprocessing\", PostprocessingTransformer()),\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    (\"feature_selection\", FastICA(random_state=random_state))])\n",
    "\n",
    "    pe_features = Pipeline(steps = [\n",
    "                    (\"pe_extraction\", CenteredPe(step=12)),\n",
    "                    (\"binning\", BinTransformer(step=12)),\n",
    "                    (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                    (\"postprocessing\", PostprocessingTransformer()),\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    (\"feature_selection\", FastICA(random_state=random_state))])\n",
    "    \n",
    "    ern_pe_features = FeatureUnion([(\"ern_features\", ern_features), (\"pe_features\", pe_features)], n_jobs = 10)\n",
    "\n",
    "    features = Pipeline([\n",
    "        ('ern_pe_features', ern_pe_features)\n",
    "    \n",
    "    ])\n",
    "        \n",
    "    steps = ('features', features)\n",
    "\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79fddff-8c71-491b-89fd-b5fb702f5915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPATIAL FILTER - BINS - UNION - METRICS\n",
    "\n",
    "\n",
    "def spatial_filter_bins_union_metrics_features(spatial_filter_n_components, timepoints_count, feature_name):\n",
    "\n",
    "    ern_features = Pipeline(steps=[\n",
    "                    (\"ern_data_extraction\", ErnTransformer()),\n",
    "                    (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                    (\"postprocessing\", PostprocessingTransformer()),\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    (\"feature_selection\", FastICA(random_state=random_state))])\n",
    "\n",
    "    pe_features = Pipeline(steps = [\n",
    "                    (\"pe_data_extraction\", PeTransformer()),\n",
    "                    (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                    (\"postprocessing\", PostprocessingTransformer()),\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    (\"feature_selection\", FastICA(random_state=random_state))])\n",
    "    \n",
    "    eeg_features = FeatureUnion([(\"ern_features\", ern_features), (\"pe_features\", pe_features)])\n",
    "\n",
    "    eeg_pipeline = Pipeline([\n",
    "        (\"extract_epochs\", EEGdata(dataset=dataset)),\n",
    "        (\n",
    "            \"channels_filtering\",\n",
    "            ChannelExtraction(significant_channels)\n",
    "        ),\n",
    "        (\n",
    "            \"average_epochs\",\n",
    "            AveragePerParticipant(),\n",
    "        ),\n",
    "        (\"spatial_filter_preprocessing\", SpatialFilterPreprocessing()),\n",
    "        (\n",
    "            \"spatial_filter\",\n",
    "            PCA(n_components=spatial_filter_n_components, random_state=random_state),\n",
    "        ),\n",
    "        (\n",
    "            \"spatial_filter_postprocessing\",\n",
    "            SpatialFilterPostprocessing(\n",
    "                timepoints_count=timepoints_count,\n",
    "            ),\n",
    "        ),\n",
    "        (\"lowpass_filter\", LowpassFilter()),\n",
    "        (\"binning\", BinTransformer(step=step_tp)),\n",
    "        ('ern_pe_features', eeg_features)\n",
    "    \n",
    "    ])\n",
    "        \n",
    "    \n",
    "    metric = Pipeline(steps = [\n",
    "            (\"anxiety\", GetFeature(feature_name=feature_name, dataset=dataset)),\n",
    "            (\"scaler\", StandardScaler())\n",
    "        ])\n",
    "    \n",
    "    features = FeatureUnion([(\"eeg_features\", eeg_pipeline),(\"metric_features\", metric)])\n",
    "    steps = ('features', features)\n",
    "\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14be436-829d-4819-bb18-b6cce5c7b4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BINS\n",
    "def erp_bins_steps():\n",
    "    steps = [\n",
    "        (\n",
    "            \"channels_filtering\",\n",
    "            ChannelExtraction(significant_channels),\n",
    "        ),\n",
    "        (\"lowpass_filter\", LowpassFilter()),\n",
    "        (\n",
    "            \"average_epochs\",\n",
    "            AveragePerParticipant(),\n",
    "        ),\n",
    "        (\"binning\", BinTransformer(step=step_tp)),\n",
    "        (\"data_channel_swap\", ChannelDataSwap()),\n",
    "        (\"postprocessing\", PostprocessingTransformer()),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        # (\"feature_selection\", PCA(random_state=random_state)),\n",
    "    ]\n",
    "\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05322ac1-c31d-412b-828a-e39e78305751",
   "metadata": {},
   "source": [
    "Generate estimator HTML representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b556630-2263-4a3b-b4e9-be6d4f29a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import estimator_html_repr\n",
    "\n",
    "# with open(\"my_estimator.html\", \"w\") as f:\n",
    "#     f.write(estimator_html_repr(Pipeline(this_steps)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fea081-c0ff-47c9-ba47-6323d0fa33bd",
   "metadata": {},
   "source": [
    "### Perform Experiments\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d385045e-557e-44ab-a650-439c38ff8ab6",
   "metadata": {},
   "source": [
    "#### Global parameters common for each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d8dc3b-60fb-4bb0-848a-876ea8c1bf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels that will be included in the experiment\n",
    "\n",
    "# red_box = [\n",
    "#     \"F1\",\n",
    "#     \"Fz\",\n",
    "#     \"F2\",\n",
    "#     \"FC1\",\n",
    "#     \"FCz\",\n",
    "#     \"FC2\",\n",
    "#     \"C1\",\n",
    "#     \"Cz\",\n",
    "#     \"C2\",\n",
    "#     \"CP1\",\n",
    "#     \"CPz\",\n",
    "#     \"CP2\",\n",
    "#     \"P1\",\n",
    "#     \"Pz\",\n",
    "#     \"P2\",\n",
    "# ]\n",
    "\n",
    "red_box = [\n",
    "    \"F3\",\"F1\",\"Fz\", \"F2\", \"F4\",\n",
    "    \"FC3\", \"FC1\", \"FCz\", \"FC2\",\"FC4\",\n",
    "    \"C3\", \"C1\",\"Cz\",\"C2\", \"C4\",\n",
    "    \"CP3\", \"CP1\",\"CPz\",\"CP2\", \"CP4\",\n",
    "    \"P3\",\"P1\", \"Pz\", \"P2\", \"P4\",\n",
    "]\n",
    "\n",
    "significant_channels = [channels_dict[channel] for channel in red_box]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc0044c-fdee-4048-8982-19caa4ea0221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial filters\n",
    "\n",
    "spatial_filters_dict = {\n",
    "    \"ICA\": FastICA(random_state=random_state),\n",
    "    \"PCA\": PCA(random_state=random_state),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858f0948-12b8-42e9-9d9e-c9c7fb579939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # bins width\n",
    "\n",
    "# step_in_ms = 30  # in miliseconds (?)\n",
    "# step_tp = int(signal_frequency * step_in_ms / 1000) # in timepoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff9c2c2-558f-4616-9b88-63631942e80d",
   "metadata": {},
   "source": [
    "---\n",
    "#### Experiment 1\n",
    "\n",
    "- spatial filter\n",
    "- bins\n",
    "- feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d51cf19-bf5e-4c67-aaf6-13be50b4457d",
   "metadata": {},
   "source": [
    "##### Spatial filter & binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e5d755-b1d9-4a03-9e88-95fe9a5a1e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters of pipeline\n",
    "\n",
    "spatial_filter = \"PCA\"\n",
    "\n",
    "min_spatial_filter = 3\n",
    "max_spatial_filter = 6\n",
    "step_spatial_filter = 1\n",
    "\n",
    "min_feature_selection = 2\n",
    "max_feature_selection = 6\n",
    "step_feature_selection = 1\n",
    "\n",
    "\n",
    "# define proper parameters for training. In this case define range of number of feature extraction to search\n",
    "regressor_params = dict(\n",
    "    features__ern_pe_features__ern_features__feature_selection__n_components=np.arange(\n",
    "        min_feature_selection, max_feature_selection, step_feature_selection\n",
    "    ),\n",
    "    features__ern_pe_features__pe_features__feature_selection__n_components=np.arange(\n",
    "        min_feature_selection, max_feature_selection, step_feature_selection\n",
    "        ),\n",
    "    features__ern_pe_features__ern_features__ern_amplitude__step=np.arange(\n",
    "        5, 12, 2\n",
    "    ),\n",
    "    features__ern_pe_features__pe_features__pe_amplitude__step=np.arange(\n",
    "        5, 12, 2\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19073a0-ee3d-4ace-bbfd-177c753cefd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define estimators and their hyperparameters\n",
    "\n",
    "en = (\"en\", ElasticNet(random_state=random_state))\n",
    "en_params = dict(\n",
    "    en__alpha=np.logspace(-7, 3, num=20, base=10),\n",
    "    en__l1_ratio=np.logspace(-8, 0, num=17, base=10),\n",
    ")\n",
    "\n",
    "kr = (\"kr\", KernelRidge(kernel=\"rbf\"))\n",
    "kr_params = dict(\n",
    "    kr__alpha=np.logspace(-5, 3, num=20, base=10),\n",
    "    kr__gamma=np.logspace(-5, 3, num=20, base=10),\n",
    ")\n",
    "\n",
    "\n",
    "svr = (\"svr\", SVR())\n",
    "svr_params = dict(\n",
    "    svr__kernel=[\"linear\", \"rbf\"],\n",
    "    svr__C=[0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
    "    svr__gamma=[\"scale\"],\n",
    "    svr__epsilon=[0.00001, 0.0001, 0.001, 0.01, 0.1, 1],\n",
    ")\n",
    "\n",
    "tested_regressors = [\n",
    "    # (svr, svr_params), \n",
    "    # (kr, kr_params), \n",
    "    (en, en_params)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de81c0ce-bc07-42e2-9dd4-a16eef799b2e",
   "metadata": {},
   "source": [
    "#### Run Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e839c6c-bd10-4873-8763-18f11ad10554",
   "metadata": {},
   "source": [
    "---\n",
    "# Cented Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9db697-300b-4f2e-9856-573239222adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters of pipeline\n",
    "\n",
    "spatial_filter = \"PCA\"\n",
    "\n",
    "min_spatial_filter = 3\n",
    "max_spatial_filter = 6\n",
    "step_spatial_filter = 1\n",
    "\n",
    "min_feature_selection = 2\n",
    "max_feature_selection = 6\n",
    "step_feature_selection = 1\n",
    "\n",
    "\n",
    "# define proper parameters for training. In this case define range of number of feature extraction to search\n",
    "regressor_params = dict(\n",
    "    features__ern_pe_features__ern_features__feature_selection__n_components=np.arange(\n",
    "        min_feature_selection, max_feature_selection, step_feature_selection\n",
    "    ),\n",
    "    features__ern_pe_features__pe_features__feature_selection__n_components=np.arange(\n",
    "        min_feature_selection, max_feature_selection, step_feature_selection\n",
    "        ),\n",
    "    # features__ern_pe_features__ern_features__binning__step=np.arange(\n",
    "    #     5, 13, 2\n",
    "    # ),\n",
    "    # features__ern_pe_features__pe_features__binning__step=np.arange(\n",
    "    #     5, 13, 2\n",
    "    # ),\n",
    "    # features__ern_pe_features__ern_features__ern_extraction__step=np.arange(\n",
    "    #     5, 10, 2\n",
    "    # ),\n",
    "    # features__ern_pe_features__pe_features__pe_extraction__step=np.arange(\n",
    "    #     5, 10, 2\n",
    "    # ),\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf24062e-7ae3-43a2-99d3-8b3d1a372e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_centered_components_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38258981-a4b5-4853-878b-bfc029538029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually test different numbers of spatial filter components\n",
    "\n",
    "timepoints_count = 181\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "    \n",
    "\n",
    "for n_components in range(min_spatial_filter, max_spatial_filter, step_spatial_filter):        \n",
    "    ern_features = Pipeline(steps=[\n",
    "                (\"ern_extraction\", CenteredERN(step=12)),\n",
    "                (\"binning\", BinTransformer(step=12)),\n",
    "                (\"ern_amplitude\", ErnAmplitude2()),\n",
    "                (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                (\"postprocessing\", PostprocessingTransformer()),\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"feature_selection\", FastICA(random_state=random_state))])\n",
    "\n",
    "    pe_features = Pipeline(steps = [\n",
    "                    (\"pe_extraction\", CenteredPe(step=12)),\n",
    "                    (\"binning\", BinTransformer(step=12)),\n",
    "                    (\"pe_amplitude\", PeAmplitude2()),\n",
    "                    (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                    (\"postprocessing\", PostprocessingTransformer()),\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    (\"feature_selection\", FastICA(random_state=random_state))])\n",
    "\n",
    "    ern_pe_features = FeatureUnion([(\"ern_features\", ern_features), (\"pe_features\", pe_features)], n_jobs = 10)\n",
    "\n",
    "    features = Pipeline([\n",
    "        ('ern_pe_features', ern_pe_features)\n",
    "\n",
    "    ])\n",
    "\n",
    "    steps = ('features', features)\n",
    "\n",
    "\n",
    "    pipeline_name = f\"{spatial_filter}_{n_components}_centered_ampl_components\"\n",
    "\n",
    "    preprocessed_pipeline = Pipeline([(\"extract_epochs\", EEGdata(dataset=dataset)),\n",
    "        # (\"narrow_indices\", NarrowIndices(start=76, stop=257)),\n",
    "        (\n",
    "            \"channels_filtering\",\n",
    "            ChannelExtraction(significant_channels)\n",
    "        ),\n",
    "        (\n",
    "            \"average_epochs\",\n",
    "            AveragePerParticipant(),\n",
    "        ),\n",
    "        (\"spatial_filter_preprocessing\", SpatialFilterPreprocessing()),\n",
    "        (\n",
    "            \"spatial_filter\",\n",
    "            PCA(n_components=n_components, random_state=random_state),\n",
    "        ),\n",
    "        (\n",
    "            \"spatial_filter_postprocessing\",\n",
    "            SpatialFilterPostprocessing(\n",
    "                timepoints_count=timepoints_count,\n",
    "            ),\n",
    "        ),\n",
    "        (\"lowpass_filter\", LowpassFilter()),\n",
    "                              ]).fit(X_train)\n",
    "\n",
    "    preprocessed_X = preprocessed_pipeline.transform(X_train)\n",
    "\n",
    "    # this_steps = spatial_filter_centered_components(spatial_filter_n_components=n_components, timepoints_count=timepoints_count)\n",
    "    this_steps = steps\n",
    "\n",
    "    # rate different models\n",
    "    results_static_ICA_bin_union_100_600_centered_components_df = run_experiment(\n",
    "        tested_regressors,\n",
    "        regressor_params,\n",
    "        pipeline_name,\n",
    "        preprocessed_X,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        dataset_name,\n",
    "        this_steps,\n",
    "        preprocessed_pipeline,\n",
    "        X_test_df,\n",
    "        y_rum,\n",
    "        results_static_ICA_bin_union_100_600_centered_components_df,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dcf152-8578-445e-90a5-a19194fe1178",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_centered_components_df.to_pickle(\"../data/regression_union_100-600_centered_components_amplmax_0.3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2195910-161a-4670-99b4-c84102151be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define proper parameters for training. In this case define range of number of feature extraction to search\n",
    "regressor_params = dict(\n",
    "    features__feature_selection__n_components=np.arange(\n",
    "        min_feature_selection, max_feature_selection, step_feature_selection\n",
    "    ),\n",
    "    # features__ern_pe_features__pe_features__feature_selection__n_components=np.arange(\n",
    "    #     min_feature_selection, max_feature_selection, step_feature_selection\n",
    "    #     ),\n",
    "    # features__ern_pe_features__ern_features__binning__step=np.arange(\n",
    "    #     5, 13, 2\n",
    "    # ),\n",
    "    # features__ern_pe_features__pe_features__binning__step=np.arange(\n",
    "    #     5, 13, 2\n",
    "    # ),\n",
    "    # features__ern_pe_features__ern_features__ern_extraction__step=np.arange(\n",
    "    #     5, 10, 2\n",
    "    # ),\n",
    "    # features__ern_pe_features__pe_features__pe_extraction__step=np.arange(\n",
    "    #     5, 10, 2\n",
    "    # ),\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dd6cce-eb1a-4976-b2df-0c21a8e00f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually test different numbers of spatial filter components\n",
    "\n",
    "timepoints_count = 181\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "    \n",
    "\n",
    "for n_components in range(min_spatial_filter, max_spatial_filter, step_spatial_filter):        \n",
    "    ern_features = Pipeline(steps=[\n",
    "                (\"ern_extraction\", CenteredERN(step=12)),\n",
    "                (\"binning\", BinTransformer(step=12)),\n",
    "                # (\"ern_amplitude\", ErnAmplitude2()),\n",
    "                (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                (\"postprocessing\", PostprocessingTransformer()),\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"feature_selection\", FastICA(random_state=random_state))])\n",
    "\n",
    "#     pe_features = Pipeline(steps = [\n",
    "#                     (\"pe_extraction\", CenteredPe(step=12)),\n",
    "#                     (\"binning\", BinTransformer(step=12)),\n",
    "#                     (\"pe_amplitude\", PeAmplitude2()),\n",
    "#                     (\"data_channel_swap\", ChannelDataSwap()),\n",
    "#                     (\"postprocessing\", PostprocessingTransformer()),\n",
    "#                     (\"scaler\", StandardScaler()),\n",
    "#                     (\"feature_selection\", FastICA(random_state=random_state))])\n",
    "\n",
    "#     ern_pe_features = FeatureUnion([(\"ern_features\", ern_features), (\"pe_features\", pe_features)], n_jobs = 10)\n",
    "\n",
    "#     features = Pipeline([\n",
    "#         ('ern_pe_features', ern_pe_features)\n",
    "\n",
    "#     ])\n",
    "\n",
    "    steps = ('features', ern_features)\n",
    "\n",
    "\n",
    "    pipeline_name = f\"{spatial_filter}_{n_components}_centered_ampl_components\"\n",
    "\n",
    "    preprocessed_pipeline = Pipeline([(\"extract_epochs\", EEGdata(dataset=dataset)),\n",
    "        # (\"narrow_indices\", NarrowIndices(start=76, stop=257)),\n",
    "        (\n",
    "            \"channels_filtering\",\n",
    "            ChannelExtraction(significant_channels)\n",
    "        ),\n",
    "        (\n",
    "            \"average_epochs\",\n",
    "            AveragePerParticipant(),\n",
    "        ),\n",
    "        (\"spatial_filter_preprocessing\", SpatialFilterPreprocessing()),\n",
    "        (\n",
    "            \"spatial_filter\",\n",
    "            PCA(n_components=n_components, random_state=random_state),\n",
    "        ),\n",
    "        (\n",
    "            \"spatial_filter_postprocessing\",\n",
    "            SpatialFilterPostprocessing(\n",
    "                timepoints_count=timepoints_count,\n",
    "            ),\n",
    "        ),\n",
    "        (\"lowpass_filter\", LowpassFilter()),\n",
    "                              ]).fit(X_train)\n",
    "\n",
    "    preprocessed_X = preprocessed_pipeline.transform(X_train)\n",
    "\n",
    "    # this_steps = spatial_filter_centered_components(spatial_filter_n_components=n_components, timepoints_count=timepoints_count)\n",
    "    this_steps = steps\n",
    "\n",
    "    # rate different models\n",
    "    results_static_ICA_bin_union_100_600_centered_components_df = run_experiment(\n",
    "        tested_regressors,\n",
    "        regressor_params,\n",
    "        pipeline_name,\n",
    "        preprocessed_X,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        dataset_name,\n",
    "        this_steps,\n",
    "        preprocessed_pipeline,\n",
    "        X_test_df,\n",
    "        y_rum,\n",
    "        results_static_ICA_bin_union_100_600_centered_components_df,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f50255-906c-4ec7-9935-f38498b9c380",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_centered_components_df.to_pickle(\"../data/regression_union_100-600_centered_ern_0.3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a35a11-3af1-41b5-bb14-051e1e74628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define proper parameters for training. In this case define range of number of feature extraction to search\n",
    "regressor_params = dict(\n",
    "    features__feature_selection__n_components=np.arange(\n",
    "        min_feature_selection, max_feature_selection, step_feature_selection\n",
    "    ),\n",
    "    # features__ern_pe_features__pe_features__feature_selection__n_components=np.arange(\n",
    "    #     min_feature_selection, max_feature_selection, step_feature_selection\n",
    "    #     ),\n",
    "    # features__ern_pe_features__ern_features__binning__step=np.arange(\n",
    "    #     5, 13, 2\n",
    "    # ),\n",
    "    # features__ern_pe_features__pe_features__binning__step=np.arange(\n",
    "    #     5, 13, 2\n",
    "    # ),\n",
    "    # features__ern_pe_features__ern_features__ern_extraction__step=np.arange(\n",
    "    #     5, 10, 2\n",
    "    # ),\n",
    "    # features__ern_pe_features__pe_features__pe_extraction__step=np.arange(\n",
    "    #     5, 10, 2\n",
    "    # ),\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64063f9-66a5-445d-a31b-1668b5d700d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually test different numbers of spatial filter components\n",
    "\n",
    "timepoints_count = 181\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "    \n",
    "\n",
    "for n_components in range(min_spatial_filter, max_spatial_filter, step_spatial_filter):        \n",
    "    ern_features = Pipeline(steps=[\n",
    "                (\"ern_extraction\", CenteredERN(step=12)),\n",
    "                (\"binning\", BinTransformer(step=12)),\n",
    "                (\"ern_amplitude\", ErnAmplitude2()),\n",
    "                (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                (\"postprocessing\", PostprocessingTransformer()),\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"feature_selection\", FastICA(random_state=random_state))])\n",
    "\n",
    "#     pe_features = Pipeline(steps = [\n",
    "#                     (\"pe_extraction\", CenteredPe(step=12)),\n",
    "#                     (\"binning\", BinTransformer(step=12)),\n",
    "#                     (\"pe_amplitude\", PeAmplitude2()),\n",
    "#                     (\"data_channel_swap\", ChannelDataSwap()),\n",
    "#                     (\"postprocessing\", PostprocessingTransformer()),\n",
    "#                     (\"scaler\", StandardScaler()),\n",
    "#                     (\"feature_selection\", FastICA(random_state=random_state))])\n",
    "\n",
    "#     ern_pe_features = FeatureUnion([(\"ern_features\", ern_features), (\"pe_features\", pe_features)], n_jobs = 10)\n",
    "\n",
    "#     features = Pipeline([\n",
    "#         ('ern_pe_features', ern_pe_features)\n",
    "\n",
    "#     ])\n",
    "\n",
    "    steps = ('features', ern_features)\n",
    "\n",
    "\n",
    "    pipeline_name = f\"{spatial_filter}_{n_components}_centered_ampl_components\"\n",
    "\n",
    "    preprocessed_pipeline = Pipeline([(\"extract_epochs\", EEGdata(dataset=dataset)),\n",
    "        # (\"narrow_indices\", NarrowIndices(start=76, stop=257)),\n",
    "        (\n",
    "            \"channels_filtering\",\n",
    "            ChannelExtraction(significant_channels)\n",
    "        ),\n",
    "        (\n",
    "            \"average_epochs\",\n",
    "            AveragePerParticipant(),\n",
    "        ),\n",
    "        (\"spatial_filter_preprocessing\", SpatialFilterPreprocessing()),\n",
    "        (\n",
    "            \"spatial_filter\",\n",
    "            PCA(n_components=n_components, random_state=random_state),\n",
    "        ),\n",
    "        (\n",
    "            \"spatial_filter_postprocessing\",\n",
    "            SpatialFilterPostprocessing(\n",
    "                timepoints_count=timepoints_count,\n",
    "            ),\n",
    "        ),\n",
    "        (\"lowpass_filter\", LowpassFilter()),\n",
    "                              ]).fit(X_train)\n",
    "\n",
    "    preprocessed_X = preprocessed_pipeline.transform(X_train)\n",
    "\n",
    "    # this_steps = spatial_filter_centered_components(spatial_filter_n_components=n_components, timepoints_count=timepoints_count)\n",
    "    this_steps = steps\n",
    "\n",
    "    # rate different models\n",
    "    results_static_ICA_bin_union_100_600_centered_components_df = run_experiment(\n",
    "        tested_regressors,\n",
    "        regressor_params,\n",
    "        pipeline_name,\n",
    "        preprocessed_X,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        dataset_name,\n",
    "        this_steps,\n",
    "        preprocessed_pipeline,\n",
    "        X_test_df,\n",
    "        y_rum,\n",
    "        results_static_ICA_bin_union_100_600_centered_components_df,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21850fd-bcae-4982-98fc-d9dd8ea9d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_centered_components_df.to_pickle(\"../data/regression_union_100-600_centered_ern_amplmax_0.3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a7bda0-407a-4cf7-b5f3-534924623bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define proper parameters for training. In this case define range of number of feature extraction to search\n",
    "regressor_params = dict(\n",
    "    features__ern_pe_features__ern_features__feature_selection__n_components=np.arange(\n",
    "        min_feature_selection, max_feature_selection, step_feature_selection\n",
    "    ),\n",
    "    features__ern_pe_features__pe_features__feature_selection__n_components=np.arange(\n",
    "        min_feature_selection, max_feature_selection, step_feature_selection\n",
    "        ),\n",
    "    # features__ern_pe_features__ern_features__binning__step=np.arange(\n",
    "    #     5, 13, 2\n",
    "    # ),\n",
    "    # features__ern_pe_features__pe_features__binning__step=np.arange(\n",
    "    #     5, 13, 2\n",
    "    # ),\n",
    "    # features__ern_pe_features__ern_features__ern_extraction__step=np.arange(\n",
    "    #     5, 10, 2\n",
    "    # ),\n",
    "    # features__ern_pe_features__pe_features__pe_extraction__step=np.arange(\n",
    "    #     5, 10, 2\n",
    "    # ),\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb1476a-5c6d-435a-8374-48d580142fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually test different numbers of spatial filter components centered, max-min + amplitude\n",
    "\n",
    "timepoints_count = 181\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "    \n",
    "\n",
    "for n_components in range(min_spatial_filter, max_spatial_filter, step_spatial_filter):        \n",
    "    ern_features = Pipeline(steps=[\n",
    "                (\"ern_extraction\", CenteredERN(step=12)),\n",
    "                (\"binning\", BinTransformer(step=12)),\n",
    "                (\"ern_amplitude\", ErnAmplitude2()),\n",
    "                (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                (\"postprocessing\", PostprocessingTransformer()),\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"feature_selection\", FastICA(random_state=random_state))])\n",
    "\n",
    "    pe_features = Pipeline(steps = [\n",
    "                    (\"pe_extraction\", CenteredPe(step=12)),\n",
    "                    (\"binning\", BinTransformer(step=12)),\n",
    "                    (\"pe_amplitude\", PeAmplitude2()),\n",
    "                    (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                    (\"postprocessing\", PostprocessingTransformer()),\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    (\"feature_selection\", FastICA(random_state=random_state))])\n",
    "    \n",
    "    ern_amplitude = Pipeline(steps = [\n",
    "        (\"ern_amplitude\", ErnAmplitude()),\n",
    "        (\"data_channel_swap\", ChannelDataSwap()),\n",
    "        (\"postprocessing\", PostprocessingTransformer()),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ])\n",
    "    \n",
    "    \n",
    "    pe_amplitude = Pipeline(steps = [\n",
    "        (\"pe_amplitude\", PeAmplitude()),\n",
    "        (\"data_channel_swap\", ChannelDataSwap()),\n",
    "        (\"postprocessing\", PostprocessingTransformer()),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ])\n",
    "\n",
    "    ern_pe_features = FeatureUnion([(\"ern_features\", ern_features), (\"pe_features\", pe_features), (\"e_ampl\", ern_amplitude), (\"p_ampl\", pe_amplitude)], n_jobs = 10)\n",
    "\n",
    "    features = Pipeline([\n",
    "        ('ern_pe_features', ern_pe_features)\n",
    "\n",
    "    ])\n",
    "\n",
    "    steps = ('features', features)\n",
    "\n",
    "\n",
    "    pipeline_name = f\"{spatial_filter}_{n_components}_centered_ampl_components\"\n",
    "\n",
    "    preprocessed_pipeline = Pipeline([(\"extract_epochs\", EEGdata(dataset=dataset)),\n",
    "        # (\"narrow_indices\", NarrowIndices(start=76, stop=257)),\n",
    "        (\n",
    "            \"channels_filtering\",\n",
    "            ChannelExtraction(significant_channels)\n",
    "        ),\n",
    "        (\n",
    "            \"average_epochs\",\n",
    "            AveragePerParticipant(),\n",
    "        ),\n",
    "        (\"spatial_filter_preprocessing\", SpatialFilterPreprocessing()),\n",
    "        (\n",
    "            \"spatial_filter\",\n",
    "            PCA(n_components=n_components, random_state=random_state),\n",
    "        ),\n",
    "        (\n",
    "            \"spatial_filter_postprocessing\",\n",
    "            SpatialFilterPostprocessing(\n",
    "                timepoints_count=timepoints_count,\n",
    "            ),\n",
    "        ),\n",
    "        (\"lowpass_filter\", LowpassFilter()),\n",
    "                              ]).fit(X_train)\n",
    "\n",
    "    preprocessed_X = preprocessed_pipeline.transform(X_train)\n",
    "\n",
    "    # this_steps = spatial_filter_centered_components(spatial_filter_n_components=n_components, timepoints_count=timepoints_count)\n",
    "    this_steps = steps\n",
    "\n",
    "    # rate different models\n",
    "    results_static_ICA_bin_union_100_600_centered_components_df = run_experiment(\n",
    "        tested_regressors,\n",
    "        regressor_params,\n",
    "        pipeline_name,\n",
    "        preprocessed_X,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        dataset_name,\n",
    "        this_steps,\n",
    "        preprocessed_pipeline,\n",
    "        X_test_df,\n",
    "        y_rum,\n",
    "        results_static_ICA_bin_union_100_600_centered_components_df,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5188ac35-dbbe-4c53-89a8-47cb6f9190b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_centered_components_df.to_pickle(\"../data/regression_union_100-600_centered_components_amplmax_ampl_0.3.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d37f71-8ab9-41e5-9a7e-0fd56fc897ad",
   "metadata": {},
   "source": [
    "# CENTERED SIGNAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45956c8b-cc64-4823-9d72-613c57a1ba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define proper parameters for training. In this case define range of number of feature extraction to search\n",
    "regressor_params = dict(\n",
    "    features__ern_pe_features__ern_features__feature_selection__n_components=np.arange(\n",
    "        min_feature_selection, max_feature_selection, step_feature_selection\n",
    "    ),\n",
    "    features__ern_pe_features__pe_features__feature_selection__n_components=np.arange(\n",
    "        min_feature_selection, max_feature_selection, step_feature_selection\n",
    "        ),   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfc25fa-f645-420d-a1e8-383244984387",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_centered_components_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8658dc82-f376-414f-bcd0-7639f4c1eae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually test different numbers of spatial filter components\n",
    "\n",
    "timepoints_count = 181\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "    \n",
    "\n",
    "for n_components in range(min_spatial_filter, max_spatial_filter, step_spatial_filter):        \n",
    "    \n",
    "    \n",
    "    ern_features = Pipeline(steps=[\n",
    "                    (\"ern_data_extraction\", ErnTransformer()),\n",
    "                    # (\"ern_amplitude\", ErnAmplitude3()),\n",
    "                    (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                    (\"postprocessing\", PostprocessingTransformer()),\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    (\"feature_selection\", FastICA(random_state=random_state))\n",
    "    ])\n",
    "     \n",
    "\n",
    "    pe_features = Pipeline(steps = [\n",
    "                    (\"pe_data_extraction\", PeTransformer()),\n",
    "                    # (\"pe_centered\", CenteredPeAfterBaseline()),\n",
    "                    (\"pe_amplitude\", PeAmplitude2()),\n",
    "                    (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                    (\"postprocessing\", PostprocessingTransformer()),\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    (\"feature_selection\", FastICA(random_state=random_state))\n",
    "    ])\n",
    "    \n",
    "    ern_pe_features = FeatureUnion([(\"ern_features\", ern_features), (\"pe_features\", pe_features)], n_jobs = 10)\n",
    "\n",
    "    features = Pipeline([\n",
    "        ('ern_pe_features', ern_pe_features)\n",
    "\n",
    "    ])\n",
    "\n",
    "    steps = ('features', features)\n",
    "\n",
    "\n",
    "    pipeline_name = f\"{spatial_filter}_{n_components}_centered_ampl_components\"\n",
    "\n",
    "    preprocessed_pipeline = Pipeline([(\"extract_epochs\", EEGdata(dataset=dataset)),\n",
    "        # (\"narrow_indices\", NarrowIndices(start=76, stop=257)),\n",
    "        (\n",
    "            \"channels_filtering\",\n",
    "            ChannelExtraction(significant_channels)\n",
    "        ),\n",
    "        (\n",
    "            \"average_epochs\",\n",
    "            AveragePerParticipant(),\n",
    "        ),\n",
    "        (\"spatial_filter_preprocessing\", SpatialFilterPreprocessing()),\n",
    "        (\n",
    "            \"spatial_filter\",\n",
    "            PCA(n_components=n_components, random_state=random_state),\n",
    "        ),\n",
    "        (\n",
    "            \"spatial_filter_postprocessing\",\n",
    "            SpatialFilterPostprocessing(\n",
    "                timepoints_count=timepoints_count,\n",
    "            ),\n",
    "        ),\n",
    "        (\"lowpass_filter\", LowpassFilter()),\n",
    "        (\"binning\", BinTransformer(step=12)),\n",
    "        (\"baseline\", ErnBaselined()),\n",
    "        (\"centering\", CenteredSignalAfterBaseline())\n",
    "\n",
    "                              ]).fit(X_train)\n",
    "\n",
    "    preprocessed_X = preprocessed_pipeline.transform(X_train)\n",
    "\n",
    "    # this_steps = spatial_filter_centered_components(spatial_filter_n_components=n_components, timepoints_count=timepoints_count)\n",
    "    this_steps = steps\n",
    "\n",
    "    # rate different models\n",
    "    results_static_ICA_bin_union_100_600_centered_components_df = run_experiment(\n",
    "        tested_regressors,\n",
    "        regressor_params,\n",
    "        pipeline_name,\n",
    "        preprocessed_X,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        dataset_name,\n",
    "        this_steps,\n",
    "        preprocessed_pipeline,\n",
    "        X_test_df,\n",
    "        y_rum,\n",
    "        results_static_ICA_bin_union_100_600_centered_components_df,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62254e7-4c9b-4220-b2d4-2ba0756b5749",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_centered_components_df.to_pickle(\"../data/regression_union_100-600_baselined_centered_ampl-2-pe_0.4.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eee08ce-8835-4337-9f89-374e8988e693",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_baselined_peak_to_peak_components_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49f65e6-ab48-4783-b0f6-4ccfb5fff9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_channels = [channels_dict[channel] for channel in red_box]\n",
    "\n",
    "\n",
    "x = Pipeline([(\"extract_epochs\", EEGdata(dataset=dataset)),\n",
    "            (\n",
    "                \"channels_filtering\",\n",
    "                ChannelExtraction(significant_channels)\n",
    "            ),\n",
    "            (\n",
    "                \"average_epochs\",\n",
    "                AveragePerParticipant(),\n",
    "            )]).fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e00eca2-12ef-47ce-bcbd-5a9a7ec8c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44125cb-5db3-4a68-b0ab-1678ba3a16f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels that will be included in the experiment\n",
    "\n",
    "# red_box = [\n",
    "#     \"F1\",\n",
    "#     \"Fz\",\n",
    "#     \"F2\",\n",
    "#     \"FC1\",\n",
    "#     \"FCz\",\n",
    "#     \"FC2\",\n",
    "#     \"C1\",\n",
    "#     \"Cz\",\n",
    "#     \"C2\",\n",
    "#     \"CP1\",\n",
    "#     \"CPz\",\n",
    "#     \"CP2\",\n",
    "#     \"P1\",\n",
    "#     \"Pz\",\n",
    "#     \"P2\",\n",
    "# ]\n",
    "\n",
    "# red_box = [\n",
    "#     \"F3\",\"F1\",\"Fz\", \"F2\", \"F4\",\n",
    "#     \"FC3\", \"FC1\", \"FCz\", \"FC2\",\"FC4\",\n",
    "#     \"C3\", \"C1\",\"Cz\",\"C2\", \"C4\",\n",
    "#     \"CP3\", \"CP1\",\"CPz\",\"CP2\", \"CP4\",\n",
    "#     \"P3\",\"P1\", \"Pz\", \"P2\", \"P4\",\n",
    "# ]\n",
    "\n",
    "red_box = [\n",
    "    \"F3\",\"F2\", \"F4\",\n",
    "    \"C1\",\"Cz\", \"FCz\",\n",
    "    \"C3\",\"C2\",\"C4\",\n",
    "    \"P1\",\"Fpz\", \"P2\",\n",
    "    \"P3\", \"CPz\", \"P4\",\n",
    "]\n",
    "# bez Fpz - no significant\n",
    "red_box2 = [\n",
    "    \"F3\",\"F2\", \"F4\",\n",
    "    \"C1\",\"Cz\", \"FCz\",\n",
    "    \"C3\",\"C2\",\"C4\",\n",
    "    \"P1\", \"P2\",\n",
    "    \"P3\", \"CPz\", \"P4\",\n",
    "]\n",
    "\n",
    "# bez Fpz i z dodanym F1 - no sognificant\n",
    "red_box3 = [\n",
    "    \"F3\",\"F1\",\"F2\", \"F4\",\n",
    "    \"C1\",\"Cz\", \"FCz\",\n",
    "    \"C3\",\"C2\",\"C4\",\n",
    "    \"P1\", \"P2\",\n",
    "    \"P3\", \"CPz\", \"P4\",\n",
    "]\n",
    "\n",
    "red_box4 = [\n",
    "    \"Fpz\",\n",
    "    \"F3\",\"F1\",\"Fz\", \"F2\", \"F4\",\n",
    "    \"FCz\",\n",
    "    \"C3\", \"C1\",\"Cz\",\"C2\",\"C4\",\n",
    "    \"CPz\",\n",
    "    \"P3\", \"P1\", \"P2\", \"P4\",\n",
    "]\n",
    "\n",
    "red_box4_prim = [\n",
    "    \"Fpz\",\n",
    "    \"F1\",\"Fz\", \"F2\",\n",
    "    \"FCz\",\n",
    "    \"C1\",\"Cz\",\"C2\",\n",
    "    \"CPz\",\n",
    "    \"P1\", \"P2\",\n",
    "]\n",
    "\n",
    "#\n",
    "red_box5 = [\n",
    "    \"AFz\", \n",
    "    \"F3\",\"F1\",\"Fz\", \"F2\", \"F4\",\n",
    "    \"C1\",\"Cz\", \"FCz\",\n",
    "    \"C3\",\"C2\",\"C4\",\n",
    "    \"P1\", \"P2\",\n",
    "    \"P3\", \"CPz\", \"P4\",\n",
    "]\n",
    "\n",
    "red_box6 = [\n",
    "    \"Fpz\", \n",
    "    \"AFz\",\n",
    "    \"Fz\",\n",
    "    \"FCz\",\n",
    "    \"Cz\",\n",
    "    \"CPz\",\n",
    "    \"Pz\",\n",
    "]\n",
    "\n",
    "# linia i klaster z tyÅu\n",
    "red_box7 = [\n",
    "    \"Fpz\", \n",
    "    \"AFz\",\n",
    "    \"Fz\",\n",
    "    \"FCz\",\n",
    "    \"Cz\",\n",
    "    \"CPz\",\n",
    "    \"P3\", \"P1\", \"Pz\", \"P2\", \"P4\",\n",
    "]\n",
    "\n",
    "red_box7_prim = [\n",
    "    \"Fpz\", \n",
    "    \"AFz\",\n",
    "    \"Fz\",\n",
    "    \"FCz\",\n",
    "    \"Cz\",\n",
    "    \"CPz\",\n",
    "    \"P1\", \"Pz\", \"P2\",\n",
    "]\n",
    "\n",
    "# linia i klaster z tyÅu i na Årodku\n",
    "red_box8 = [\n",
    "    \"Fpz\", \n",
    "    \"AFz\",\n",
    "    \"Fz\",\n",
    "    \"FCz\",\n",
    "    \"C3\", \"C1\", \"Cz\",\"C2\", \"C4\",\n",
    "    \"CPz\",\n",
    "    \"P3\", \"P1\", \"Pz\", \"P2\", \"P4\"\n",
    "]\n",
    "\n",
    "red_box8_prim = [\n",
    "    \"Fpz\", \n",
    "    \"AFz\",\n",
    "    \"Fz\",\n",
    "    \"FCz\",\n",
    "    \"C1\", \"Cz\",\"C2\",\n",
    "    \"CPz\",\n",
    "    \"P1\", \"Pz\", \"P2\",\n",
    "]\n",
    "\n",
    "# linia i klaster z tyÅu i na Årodku i na poczatku\n",
    "red_box9 = [\n",
    "    \"Fpz\", \n",
    "    \"AFz\",\n",
    "    \"F3\", \"F1\", \"Fz\", \"F2\", \"F4\",\n",
    "    \"FCz\",\n",
    "    \"C3\", \"C1\", \"Cz\",\"C2\", \"C4\",\n",
    "    \"CPz\",\n",
    "    \"P3\", \"P1\", \"Pz\", \"P2\", \"P4\",\n",
    "]\n",
    "\n",
    "red_box9_prim = [\n",
    "    \"Fpz\", \n",
    "    \"AFz\",\n",
    "    \"F1\", \"Fz\", \"F2\",\n",
    "    \"FCz\",\n",
    "    \"C1\", \"Cz\",\"C2\",\n",
    "    \"CPz\",\n",
    "    \"P1\", \"Pz\", \"P2\",\n",
    "]\n",
    "\n",
    "red_box10 = [\n",
    "    \"Fpz\", \n",
    "    \"AFz\",\n",
    "    \"F3\", \"F1\", \"Fz\", \"F2\", \"F4\",\n",
    "    \"FCz\",\n",
    "    \"Cz\",\n",
    "    \"CP3\", \"CP1\", \"CPz\", \"CP2\", \"CP4\",\n",
    "    \"Pz\",\n",
    "]\n",
    "\n",
    "red_box10_prim = [\n",
    "    \"Fpz\", \n",
    "    \"AFz\",\n",
    "    \"F1\", \"Fz\", \"F2\",\n",
    "    \"FCz\",\n",
    "    \"Cz\",\n",
    "    \"CP1\", \"CPz\", \"CP2\",\n",
    "    \"Pz\",\n",
    "]\n",
    "\n",
    "\n",
    "box_list = [red_box6, red_box7, red_box7_prim, red_box8, red_box8_prim, red_box9, red_box9_prim, red_box4, red_box4_prim, red_box10, red_box10_prim]\n",
    "\n",
    "\n",
    "# significant_channels = [channels_dict[channel] for channel in red_box]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9abfb6f-46c8-470c-9689-a4276d3edc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually test different numbers of spatial filter components\n",
    "\n",
    "timepoints_count = 181\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "    \n",
    "for box in box_list:\n",
    "    print(f\"BOX: {box}\")\n",
    "    significant_channels = [channels_dict[channel] for channel in box]\n",
    "    for n_components in range(min_spatial_filter, max_spatial_filter, step_spatial_filter):        \n",
    "\n",
    "\n",
    "        ern_features = Pipeline(steps=[\n",
    "                        (\"ern_data_extraction\", ErnTransformer()),\n",
    "                        (\"ern_amplitude\", ErnAmplitude2()),\n",
    "                        (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                        (\"postprocessing\", PostprocessingTransformer()),\n",
    "                        (\"scaler\", StandardScaler()),\n",
    "                        (\"feature_selection\", FastICA(random_state=random_state))\n",
    "        ])\n",
    "\n",
    "\n",
    "        pe_features = Pipeline(steps = [\n",
    "                        (\"pe_data_extraction\", PeTransformer()),\n",
    "                        (\"pe_amplitude\", PeAmplitude2()),\n",
    "                        (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                        (\"postprocessing\", PostprocessingTransformer()),\n",
    "                        (\"scaler\", StandardScaler()),\n",
    "                        (\"feature_selection\", FastICA(random_state=random_state))\n",
    "        ])\n",
    "\n",
    "        ern_pe_features = FeatureUnion([(\"ern_features\", ern_features), (\"pe_features\", pe_features)], n_jobs = 10)\n",
    "\n",
    "        features = Pipeline([\n",
    "            ('ern_pe_features', ern_pe_features)\n",
    "\n",
    "        ])\n",
    "\n",
    "        steps = ('features', features)\n",
    "\n",
    "\n",
    "        pipeline_name = f\"{spatial_filter}_{n_components}_centered_ampl_components\"\n",
    "\n",
    "        preprocessed_pipeline = Pipeline([(\"extract_epochs\", EEGdata(dataset=dataset)),\n",
    "            (\n",
    "                \"channels_filtering\",\n",
    "                ChannelExtraction(significant_channels)\n",
    "            ),\n",
    "            (\n",
    "                \"average_epochs\",\n",
    "                AveragePerParticipant(),\n",
    "            ),\n",
    "            (\"spatial_filter_preprocessing\", SpatialFilterPreprocessing()),\n",
    "            (\n",
    "                \"spatial_filter\",\n",
    "                PCA(n_components=n_components, random_state=random_state),\n",
    "            ),\n",
    "            (\n",
    "                \"spatial_filter_postprocessing\",\n",
    "                SpatialFilterPostprocessing(\n",
    "                    timepoints_count=timepoints_count,\n",
    "                ),\n",
    "            ),\n",
    "            (\"lowpass_filter\", LowpassFilter()),\n",
    "            (\"binning\", BinTransformer(step=12)),\n",
    "            (\"baseline\", ErnBaselined()),\n",
    "            (\"centering\", CenteredSignalAfterBaseline())\n",
    "            # ('features', features)\n",
    "\n",
    "                                  ]).fit(X_train)\n",
    "\n",
    "        preprocessed_X = preprocessed_pipeline.transform(X_train)\n",
    "\n",
    "        # this_steps = spatial_filter_centered_components(spatial_filter_n_components=n_components, timepoints_count=timepoints_count)\n",
    "        this_steps = steps\n",
    "\n",
    "        # rate different models\n",
    "        results_static_ICA_bin_union_100_600_baselined_peak_to_peak_components_df = run_experiment(\n",
    "            tested_regressors,\n",
    "            regressor_params,\n",
    "            pipeline_name,\n",
    "            preprocessed_X,\n",
    "            X_test,\n",
    "            y_train,\n",
    "            y_test,\n",
    "            dataset_name,\n",
    "            this_steps,\n",
    "            preprocessed_pipeline,\n",
    "            X_test_df,\n",
    "            y_rum,\n",
    "            results_static_ICA_bin_union_100_600_baselined_peak_to_peak_components_df,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711c9efe-7aa4-42f5-96b7-c0a613cc3d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56c993f-9c52-461f-ba44-4163d6096fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_baselined_peak_to_peak_components_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8dc160-5cd6-45fc-9fb7-1a120cae923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_baselined_peak_to_peak_components_df.to_pickle(\"../data/regression_union_100-600_baselined_centered_diff_boxes.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c0272c-e11a-4f27-894d-7f22b9faf425",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77073a2-3770-4ae1-a532-f5bd05287201",
   "metadata": {},
   "outputs": [],
   "source": [
    "    ern_features = Pipeline(steps=[\n",
    "                    (\"ern_data_extraction\", ExtractErnBins()),\n",
    "                    (\"ern_amplitude\", ErnAmplitudeInBins()),\n",
    "                    (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                    (\"postprocessing\", PostprocessingTransformer()),\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    (\"feature_selection\", FastICA(random_state=random_state))\n",
    "    ])\n",
    "     \n",
    "\n",
    "    pe_features = Pipeline(steps = [\n",
    "                    (\"pe_data_extraction\", ExtractPeBins()),\n",
    "                    # (\"pe_min_max_features\", PeMinMaxFeatures()),\n",
    "                    # (\"pe_amplitude\", PeAmplitude2()),\n",
    "                    # (\"pe_centered\", CenteredPeAfterBaseline()),\n",
    "                    (\"pe_amplitude\", PeAmplitudeInBins()),\n",
    "                    (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                    (\"postprocessing\", PostprocessingTransformer()),\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    (\"feature_selection\", FastICA(random_state=random_state))\n",
    "    ])\n",
    "    \n",
    "    ern_pe_features = FeatureUnion([(\"ern_features\", ern_features), (\"pe_features\", pe_features)], n_jobs = 10)\n",
    "\n",
    "#     features = Pipeline([\n",
    "#         ('ern_pe_features', ern_pe_features)\n",
    "\n",
    "#     ])\n",
    "\n",
    "# steps = ('features', features)\n",
    "preprocessed_pipeline = Pipeline([(\"extract_epochs\", EEGdata(dataset=dataset)),\n",
    "            (\"narrow_indices\", NarrowIndices(start=76, stop=257)),\n",
    "            (\n",
    "                \"channels_filtering\",\n",
    "                ChannelExtraction(significant_channels)\n",
    "            ),\n",
    "            (\n",
    "                \"average_epochs\",\n",
    "                AveragePerParticipant(),\n",
    "            ),\n",
    "            (\"spatial_filter_preprocessing\", SpatialFilterPreprocessing()),\n",
    "            (\n",
    "                \"spatial_filter\",\n",
    "                PCA(n_components=3, random_state=random_state),\n",
    "            ),\n",
    "            (\n",
    "                \"spatial_filter_postprocessing\",\n",
    "                SpatialFilterPostprocessing(\n",
    "                    timepoints_count=181,\n",
    "                ),\n",
    "            ),\n",
    "            (\"lowpass_filter\", LowpassFilter()),\n",
    "            # (\"binning\", BinTransformer(step=12)),\n",
    "            # (\"baseline\", BaselineToFirstPositivityPeak()),\n",
    "            # (\"centering\", CenterSignalToErn()),\n",
    "            # ('ern_pe_features', ern_pe_features)\n",
    "                                  ]).fit(X_train)\n",
    "\n",
    "preprocessed_X = preprocessed_pipeline.transform(X_train)\n",
    "pre_processed_test_X = preprocessed_pipeline.transform(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaff9ca6-b4d1-454f-9752-ed8fbfb3d2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import estimator_html_repr\n",
    "\n",
    "with open(\"my_estimator.html\", \"w\") as f:\n",
    "    f.write(estimator_html_repr(preprocessed_pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fcb2ec-e33f-43b3-9db0-a3eb764e3d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_pipeline = Pipeline([(\"extract_epochs\", EEGdata(dataset=dataset)),\n",
    "        # (\"narrow_indices\", NarrowIndices(start=76, stop=257)),\n",
    "        (\n",
    "            \"channels_filtering\",\n",
    "            ChannelExtraction(significant_channels)\n",
    "        ),\n",
    "        # (\n",
    "        #     \"average_epochs\",\n",
    "        #     AveragePerParticipant(),\n",
    "        # ),\n",
    "        # (\"spatial_filter_preprocessing\", SpatialFilterPreprocessing()),\n",
    "        # (\n",
    "        #     \"spatial_filter\",\n",
    "        #     PCA(n_components=3, random_state=random_state),\n",
    "        # ),\n",
    "        # (\n",
    "        #     \"spatial_filter_postprocessing\",\n",
    "        #     SpatialFilterPostprocessing(\n",
    "        #         timepoints_count=181,\n",
    "        #     ),\n",
    "        # ),\n",
    "        # (\"lowpass_filter\", LowpassFilter()),\n",
    "        # (\"binning\", BinTransformer(step=12)),\n",
    "        # (\"baseline\", ErnBaselined()),\n",
    "        # (\"centering\", CenteredSignalAfterBaseline())\n",
    "\n",
    "                              ]).fit(X_train)\n",
    "\n",
    "preprocessed_X = preprocessed_pipeline.transform(X_train)\n",
    "pre_processed_test_X = preprocessed_pipeline.transform(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207591c0-5b87-4022-af0c-d4329da62f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_X[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464279bf-7633-43df-9209-7e47a0ab1a14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba3b787-acca-4b56-8307-335b1803506e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d226a5-bdd2-45ef-8ab3-68324e5090a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b771fdde-0f9e-4912-8990-70daa2d7bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_X = np.mean(preprocessed_X, axis=0)\n",
    "mean_X_test = np.mean(pre_processed_test_X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9323ca9c-bb35-42bb-88fc-a9bc3cac6cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(0,3):\n",
    "    plt.plot(mean_X_test[i])\n",
    "# plt.axvline(x=12, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "# plt.axvline(x=24, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "# plt.axvline(x=36, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "# plt.axvline(x=48, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "# plt.axvline(x=60, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "# plt.axvline(x=72, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "# plt.axvline(x=84, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "# plt.axvline(x=96, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "# plt.axvline(x=108, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431db940-0746-461d-bc4e-c0650ec97d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(preprocessed_X[6][0])\n",
    "plt.plot(preprocessed_X[14][0])\n",
    "plt.plot(preprocessed_X[2][0])\n",
    "plt.axvline(x=1, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=2, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=3, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=4, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=5, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=6, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=7, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=8, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=9, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef7b04-cf4e-4066-8662-f8e96020aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(preprocessed_X[6][1])\n",
    "plt.plot(preprocessed_X[14][1])\n",
    "plt.plot(preprocessed_X[2][1])\n",
    "plt.axvline(x=1, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=2, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=3, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=4, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=5, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=6, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=7, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=8, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=9, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795ce700-02c7-40eb-b24d-53c28e0cf72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(-preprocessed_X[6][0])\n",
    "plt.plot(-preprocessed_X[14][0])\n",
    "plt.plot(-preprocessed_X[2][0])\n",
    "plt.axvline(x=5, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=12, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=24, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=36, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=48, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=60, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=72, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=84, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=96, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=108, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.savefig(f\"train_component_0.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746ed88e-f9cd-4475-ac07-d957250bb0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(preprocessed_X[6][0])\n",
    "plt.plot(preprocessed_X[14][0])\n",
    "plt.plot(preprocessed_X[2][0])\n",
    "plt.axvline(x=1, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=2, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=3, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=4, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=5, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=6, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=7, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=8, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=9, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec16c3b-382f-4cf0-b8d4-7be61638427d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7433d6-b898-4708-b346-17bd4c03b478",
   "metadata": {},
   "outputs": [],
   "source": [
    "ern_features = Pipeline(steps=[\n",
    "                    (\"ern_extraction\", CenteredERN(step=12)),\n",
    "                    (\"binning\", BinTransformer(step=12)),\n",
    "#                     (\"data_channel_swap\", ChannelDataSwap()),\n",
    "#                     (\"postprocessing\", PostprocessingTransformer()),\n",
    "#                     (\"scaler\", StandardScaler()),\n",
    "#                     (\"feature_selection\", FastICA(random_state=random_state))\n",
    "# \n",
    "])\n",
    "\n",
    "#         pe_features = Pipeline(steps = [\n",
    "#                         (\"pe_extraction\", CenteredPe(step=12)),\n",
    "#                         # (\"binning\", BinTransformer(step=12)),\n",
    "#                         # (\"data_channel_swap\", ChannelDataSwap()),\n",
    "#                         # (\"postprocessing\", PostprocessingTransformer()),\n",
    "#                         # (\"scaler\", StandardScaler()),\n",
    "#                         # (\"feature_selection\", FastICA(random_state=random_state))\n",
    "#         ])\n",
    "    \n",
    "#         ern_pe_features = FeatureUnion([(\"ern_features\", ern_features), (\"pe_features\", pe_features)], n_jobs = 10)\n",
    "\n",
    "#         features = Pipeline([\n",
    "#             ('ern_pe_features', ern_pe_features)\n",
    "\n",
    "#         ])\n",
    "\n",
    "#         steps = ('features', features)\n",
    "\n",
    "ern_fitted = ern_features.fit_transform(preprocessed_X)\n",
    "ern_test_fitted = ern_features.transform(pre_processed_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0628fa9-1ac6-465c-91ed-44fc39a915ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ern_fitted.shape\n",
    "ern_test_fitted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806fb21d-991b-44eb-98cc-65d5de6ac39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ern_fitted_mean = np.mean(ern_fitted, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130b4d44-eeb4-4106-a67c-db24433550f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ern_fitted_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8f5dc5-9c18-4a3f-a38f-643f8c3fd4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(0, 10):\n",
    "    plt.plot(ern_fitted[i][0])\n",
    "\n",
    "# plt.plot(ern_fitted_mean[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8120cc-dcaf-4cee-9392-2937f98438a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_static_ICA_bin_union_100_600_centered_components_df[\"ex_score\"] = 0\n",
    "\n",
    "\n",
    "# for i in range(0,3):\n",
    "#     pre_processed_test_X = results_static_ICA_bin_union_100_600_centered_components_df.pre_processed_pipeline[i].transform(X_test_df)\n",
    "#     # print(pre_processed_test_X.shape)\n",
    "#     estimator = results_static_ICA_bin_union_100_600_centered_components_df.best_estimator[i]\n",
    "#     score = estimator.score(pre_processed_test_X, y_rum)\n",
    "#     # results_static_ICA_bin_union_100_600_better_ampl_bins30_df[\"ex_score\"] = score\n",
    "#     # print(score)\n",
    "#     results_static_ICA_bin_union_100_600_centered_components_df[\"ex_score\"][i] = score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f2b309-490f-47b5-8b07-4ca3eeb6ef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_centered_components_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27174088-10c1-4974-883a-d7e4c970103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_centered_components_df.to_pickle(\"../data/regression_union_100-600_centered_components_0.3.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b73a393-26c0-4b48-8921-39b3e4bd3c8c",
   "metadata": {},
   "source": [
    "----\n",
    "# Better Amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42edd269-69b8-4820-8f8a-56b97c53f2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters of pipeline\n",
    "\n",
    "spatial_filter = \"PCA\"\n",
    "\n",
    "min_spatial_filter = 3\n",
    "max_spatial_filter = 6\n",
    "step_spatial_filter = 1\n",
    "\n",
    "min_feature_selection = 2\n",
    "max_feature_selection = 6\n",
    "step_feature_selection = 1\n",
    "\n",
    "\n",
    "# define proper parameters for training. In this case define range of number of feature extraction to search\n",
    "regressor_params = dict(\n",
    "    features__ern_pe_features__ern_features__feature_selection__n_components=np.arange(\n",
    "        min_feature_selection, max_feature_selection, step_feature_selection\n",
    "    ),\n",
    "    features__ern_pe_features__pe_features__feature_selection__n_components=np.arange(\n",
    "        min_feature_selection, max_feature_selection, step_feature_selection\n",
    "        ),\n",
    "    features__ern_pe_features__ern_features__ern_amplitude__step=np.arange(\n",
    "        5, 12, 2\n",
    "    ),\n",
    "    features__ern_pe_features__pe_features__pe_amplitude__step=np.arange(\n",
    "        5, 12, 2\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095aa9c4-5ebb-48ac-b01e-9949dff3c608",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_better_ampl_bins_train_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca79cb30-c273-47c3-9528-bb13a2624574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually test different numbers of spatial filter components\n",
    "\n",
    "timepoints_count = 181\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "    \n",
    "\n",
    "for n_components in range(min_spatial_filter, max_spatial_filter, step_spatial_filter):\n",
    "\n",
    "    pipeline_name = f\"{spatial_filter}_{n_components}_bins_union_100_600_ampl\"\n",
    "    \n",
    "    preprocessed_pipeline = Pipeline([(\"extract_epochs\", EEGdata(dataset=dataset)),\n",
    "        # (\"narrow_indices\", NarrowIndices(start=76, stop=257)),\n",
    "        (\n",
    "            \"channels_filtering\",\n",
    "            ChannelExtraction(significant_channels)\n",
    "        ),\n",
    "        (\n",
    "            \"average_epochs\",\n",
    "            AveragePerParticipant(),\n",
    "        ),\n",
    "        (\"spatial_filter_preprocessing\", SpatialFilterPreprocessing()),\n",
    "        (\n",
    "            \"spatial_filter\",\n",
    "            PCA(n_components=n_components, random_state=random_state),\n",
    "        ),\n",
    "        (\n",
    "            \"spatial_filter_postprocessing\",\n",
    "            SpatialFilterPostprocessing(\n",
    "                timepoints_count=timepoints_count,\n",
    "            ),\n",
    "        ),\n",
    "        (\"lowpass_filter\", LowpassFilter()),\n",
    "                              ]).fit(X_train)\n",
    "    \n",
    "    preprocessed_X = preprocessed_pipeline.transform(X_train)\n",
    "    \n",
    "    this_steps = spatial_filter_bins_union_amplitude(spatial_filter_n_components=n_components, timepoints_count=timepoints_count)   \n",
    "   \n",
    "    # rate different models\n",
    "    results_static_ICA_bin_union_100_600_better_ampl_bins_train_df = run_experiment(\n",
    "        tested_regressors,\n",
    "        regressor_params,\n",
    "        pipeline_name,\n",
    "        preprocessed_X,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        dataset_name,\n",
    "        this_steps,\n",
    "        preprocessed_pipeline,\n",
    "        X_test_df,\n",
    "        y_rum,\n",
    "        results_static_ICA_bin_union_100_600_better_ampl_bins_train_df,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3486c16-7c49-4e10-8478-a2cf965e31ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_static_ICA_bin_union_100_600_better_ampl_bins_train_df[\"ex_score\"] = 0\n",
    "\n",
    "\n",
    "# for i in range(0,3):\n",
    "#     pre_processed_test_X = results_static_ICA_bin_union_100_600_better_ampl_bins_train_df.pre_processed_pipeline[i].transform(X_test_df)\n",
    "#     # print(pre_processed_test_X.shape)\n",
    "#     estimator = results_static_ICA_bin_union_100_600_better_ampl_bins_train_df.best_estimator[i]\n",
    "#     score = estimator.score(pre_processed_test_X, y_rum)\n",
    "#     # results_static_ICA_bin_union_100_600_better_ampl_bins30_df[\"ex_score\"] = score\n",
    "#     # results_static_ICA_bin_union_100_600_better_ampl_bins_train_df[\"ex_score\"][i] = score\n",
    "\n",
    "#     print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca84f0d-bcda-4ad3-bb36-2d88b03c4b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_better_ampl_bins_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88a0b30-db2f-4d79-a388-3d669ce25439",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_better_ampl_bins_train_df.to_pickle(\"../data/regression_union_100-600_better_ampl_trained_first_component_0.3.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbd2dd5-0c88-41d2-864b-78a81c9c5506",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec869ac-4509-4ce0-91d6-726a334f62a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eb6377-da93-4bbd-bdda-aec19f639d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins width\n",
    "\n",
    "step_in_ms = 30  # in miliseconds (?)\n",
    "step_tp = int(signal_frequency * step_in_ms / 1000) # in timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d726e3-0844-4360-86a8-5b09b8fba6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_ampl_bins30_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4ee8c7-d8dd-4223-a935-9e86a0f17ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually test different numbers of spatial filter components\n",
    "\n",
    "timepoints_count = 181\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "    \n",
    "\n",
    "for n_components in range(min_spatial_filter, max_spatial_filter, step_spatial_filter):\n",
    "\n",
    "    pipeline_name = f\"{spatial_filter}_{n_components}_bins_union_100_600_ampl\"\n",
    "    \n",
    "    preprocessed_pipeline = Pipeline([(\"extract_epochs\", EEGdata(dataset=dataset)),\n",
    "        # (\"narrow_indices\", NarrowIndices(start=76, stop=257)),\n",
    "        (\n",
    "            \"channels_filtering\",\n",
    "            ChannelExtraction(significant_channels)\n",
    "        ),\n",
    "        (\n",
    "            \"average_epochs\",\n",
    "            AveragePerParticipant(),\n",
    "        ),\n",
    "        (\"spatial_filter_preprocessing\", SpatialFilterPreprocessing()),\n",
    "        (\n",
    "            \"spatial_filter\",\n",
    "            PCA(n_components=n_components, random_state=random_state),\n",
    "        ),\n",
    "        (\n",
    "            \"spatial_filter_postprocessing\",\n",
    "            SpatialFilterPostprocessing(\n",
    "                timepoints_count=timepoints_count,\n",
    "            ),\n",
    "        ),\n",
    "        (\"lowpass_filter\", LowpassFilter()),\n",
    "        (\"binning\", BinTransformer(step=step_tp)),\n",
    "                              ]).fit(X_train)\n",
    "    \n",
    "    preprocessed_X = preprocessed_pipeline.transform(X_train)\n",
    "    \n",
    "    this_steps = spatial_filter_bins_union_features(spatial_filter_n_components=n_components, timepoints_count=timepoints_count)\n",
    "    \n",
    "    # this_steps = spatial_filter_bins_steps(spatial_filter_n_components=n_components, timepoints_count=181)\n",
    "    # pre_processing_pipeline = Pipeline(steps=this_steps)\n",
    "    # pre_processed_X = pre_processing_pipeline.fit_transform(X_train)\n",
    "    \n",
    "   \n",
    "    # rate different models\n",
    "    results_static_ICA_bin_union_100_600_ampl_bins30_df = run_experiment(\n",
    "        tested_regressors,\n",
    "        regressor_params,\n",
    "        pipeline_name,\n",
    "        preprocessed_X,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        dataset_name,\n",
    "        this_steps,\n",
    "        preprocessed_pipeline,\n",
    "        results_static_ICA_bin_union_100_600_ampl_bins30_df,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fde5401-3922-4ef5-8b01-ec1b8bc682b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,3):\n",
    "    pre_processed_test_X = results_static_ICA_bin_union_100_600_ampl_bins30_df.pre_processed_pipeline[i].transform(X_test_df)\n",
    "    # print(pre_processed_test_X.shape)\n",
    "    estimator = results_static_ICA_bin_union_100_600_ampl_bins30_df.best_estimator[i]\n",
    "    score = estimator.score(pre_processed_test_X, y_rum)\n",
    "    # print(score)\n",
    "    # results_static_ICA_bin_union_100_600_ampl_bins30_df[\"ex_score\"] = score\n",
    "    results_static_ICA_bin_union_100_600_ampl_bins30_df[\"ex_score\"][i] = score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a5e3b4-9df8-45f1-8965-bd168db7e5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_ampl_bins30_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a365475-7af7-4fd9-8ac5-7897604e1f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_ampl_bins30_df.to_pickle(\"../data/regression_union_100-600_ampl_bins30_0.3.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3d3627-96d6-4250-aaf0-fe1956accf80",
   "metadata": {},
   "source": [
    "---\n",
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81d9753-e510-4f30-b022-74147ffceee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins width\n",
    "\n",
    "step_in_ms = 30  # in miliseconds (?)\n",
    "step_tp = int(signal_frequency * step_in_ms / 1000) # in timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483651c0-84c5-4537-8ffa-08a685e9192d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_max_bins30_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328a148e-70ad-4b35-81ae-719b0b56850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually test different numbers of spatial filter components\n",
    "\n",
    "timepoints_count = 181\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "    \n",
    "\n",
    "for n_components in range(min_spatial_filter, max_spatial_filter, step_spatial_filter):\n",
    "\n",
    "    pipeline_name = f\"{spatial_filter}_{n_components}_bins_union_100_600_ampl\"\n",
    "    \n",
    "    preprocessed_pipeline = Pipeline([(\"extract_epochs\", EEGdata(dataset=dataset)),\n",
    "        # (\"narrow_indices\", NarrowIndices(start=76, stop=257)),\n",
    "        (\n",
    "            \"channels_filtering\",\n",
    "            ChannelExtraction(significant_channels)\n",
    "        ),\n",
    "        (\n",
    "            \"average_epochs\",\n",
    "            AveragePerParticipant(),\n",
    "        ),\n",
    "        (\"spatial_filter_preprocessing\", SpatialFilterPreprocessing()),\n",
    "        (\n",
    "            \"spatial_filter\",\n",
    "            PCA(n_components=n_components, random_state=random_state),\n",
    "        ),\n",
    "        (\n",
    "            \"spatial_filter_postprocessing\",\n",
    "            SpatialFilterPostprocessing(\n",
    "                timepoints_count=timepoints_count,\n",
    "            ),\n",
    "        ),\n",
    "        (\"lowpass_filter\", LowpassFilter()),\n",
    "        (\"binning\", BinTransformer(step=step_tp)),\n",
    "                              ]).fit(X_train)\n",
    "    \n",
    "    preprocessed_X = preprocessed_pipeline.transform(X_train)\n",
    "    \n",
    "    this_steps = spatial_filter_bins_union_min_max_features(spatial_filter_n_components=n_components, timepoints_count=timepoints_count)\n",
    "    \n",
    "    # this_steps = spatial_filter_bins_steps(spatial_filter_n_components=n_components, timepoints_count=181)\n",
    "    # pre_processing_pipeline = Pipeline(steps=this_steps)\n",
    "    # pre_processed_X = pre_processing_pipeline.fit_transform(X_train)\n",
    "    \n",
    "   \n",
    "    # rate different models\n",
    "    results_static_ICA_bin_union_100_600_max_bins30_df = run_experiment(\n",
    "        tested_regressors,\n",
    "        regressor_params,\n",
    "        pipeline_name,\n",
    "        preprocessed_X,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        dataset_name,\n",
    "        this_steps,\n",
    "        preprocessed_pipeline,\n",
    "        results_static_ICA_bin_union_100_600_max_bins30_df,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f89192-9039-4858-bb1f-c864d37751bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,3):\n",
    "    pre_processed_test_X = results_static_ICA_bin_union_100_600_max_bins30_df.pre_processed_pipeline[i].transform(X_test_df)\n",
    "    # print(pre_processed_test_X.shape)\n",
    "    estimator = results_static_ICA_bin_union_100_600_max_bins30_df.best_estimator[i]\n",
    "    score = estimator.score(pre_processed_test_X, y_rum)\n",
    "    # results_static_ICA_bin_union_100_600_max_bins30_df[\"ex_score\"] = score\n",
    "    results_static_ICA_bin_union_100_600_max_bins30_df[\"ex_score\"][i] = score\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da13e9c-d4d3-4c27-a0e6-0f68a64e0e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_max_bins30_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e0a3ae-1402-4cbe-9f07-899470c34e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_max_bins30_df.to_pickle(\"../data/regression_union_100-600_max_bins30_0.3.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d52fb5-9c08-4c77-8af0-fa6d69ed19fb",
   "metadata": {},
   "source": [
    "---\n",
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccb053c-3546-4169-a471-7d5eb86acfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins width\n",
    "\n",
    "step_in_ms = 50  # in miliseconds (?)\n",
    "step_tp = int(signal_frequency * step_in_ms / 1000) # in timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3eb489-ea4e-4536-a675-c8f02524df9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters of pipeline\n",
    "\n",
    "spatial_filter = \"PCA\"\n",
    "\n",
    "min_spatial_filter = 3\n",
    "max_spatial_filter = 6\n",
    "step_spatial_filter = 1\n",
    "\n",
    "min_feature_selection = 2\n",
    "max_feature_selection = 6\n",
    "step_feature_selection = 1\n",
    "\n",
    "\n",
    "# define proper parameters for training. In this case define range of number of feature extraction to search\n",
    "regressor_params = dict(\n",
    "    features__ern_pe_features__ern_features__feature_selection__n_components=np.arange(\n",
    "        2, 3, step_feature_selection\n",
    "    ),\n",
    "    features__ern_pe_features__pe_features__feature_selection__n_components=np.arange(\n",
    "        4, 5, step_feature_selection\n",
    "        ),\n",
    "    # features__ern_pe_features__ern_features__ern_amplitude__step=np.arange(\n",
    "    #     5, 12, 2\n",
    "    # ),\n",
    "    # features__ern_pe_features__pe_features__pe_amplitude__step=np.arange(\n",
    "    #     5, 12, 2\n",
    "    # ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d098de-a380-4515-b63a-d8a8f662b890",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_ampl_bins50_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b697f653-6f6e-485b-84e6-0adaf6532daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually test different numbers of spatial filter components\n",
    "\n",
    "timepoints_count = 181\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "    \n",
    "\n",
    "for n_components in range(min_spatial_filter, max_spatial_filter, step_spatial_filter):\n",
    "\n",
    "    pipeline_name = f\"{spatial_filter}_{n_components}_bins_union_100_600_ampl\"\n",
    "    \n",
    "    preprocessed_pipeline = Pipeline([(\"extract_epochs\", EEGdata(dataset=dataset)),\n",
    "        # (\"narrow_indices\", NarrowIndices(start=76, stop=257)),\n",
    "        (\n",
    "            \"channels_filtering\",\n",
    "            ChannelExtraction(significant_channels)\n",
    "        ),\n",
    "        (\n",
    "            \"average_epochs\",\n",
    "            AveragePerParticipant(),\n",
    "        ),\n",
    "        (\"spatial_filter_preprocessing\", SpatialFilterPreprocessing()),\n",
    "        (\n",
    "            \"spatial_filter\",\n",
    "            PCA(n_components=n_components, random_state=random_state),\n",
    "        ),\n",
    "        (\n",
    "            \"spatial_filter_postprocessing\",\n",
    "            SpatialFilterPostprocessing(\n",
    "                timepoints_count=timepoints_count,\n",
    "            ),\n",
    "        ),\n",
    "        (\"lowpass_filter\", LowpassFilter()),\n",
    "        (\"binning\", BinTransformer(step=step_tp)),\n",
    "                              ]).fit(X_train)\n",
    "    \n",
    "    preprocessed_X = preprocessed_pipeline.transform(X_train)\n",
    "    \n",
    "    this_steps = spatial_filter_bins_union_features(spatial_filter_n_components=n_components, timepoints_count=timepoints_count)\n",
    "    \n",
    "    # this_steps = spatial_filter_bins_steps(spatial_filter_n_components=n_components, timepoints_count=181)\n",
    "    # pre_processing_pipeline = Pipeline(steps=this_steps)\n",
    "    # pre_processed_X = pre_processing_pipeline.fit_transform(X_train)\n",
    "    \n",
    "   \n",
    "    # rate different models\n",
    "    results_static_ICA_bin_union_100_600_ampl_bins50_df = run_experiment(\n",
    "        tested_regressors,\n",
    "        regressor_params,\n",
    "        pipeline_name,\n",
    "        preprocessed_X,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        dataset_name,\n",
    "        this_steps,\n",
    "        preprocessed_pipeline,\n",
    "        X_test_df,\n",
    "        y_rum,\n",
    "        results_static_ICA_bin_union_100_600_ampl_bins50_df,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9819199b-d5ba-4392-9bc5-018a1f09773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_ampl_bins50_df.to_pickle(\"../data/regression_union_100-600_ampl_bins50_0.4.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9548dbd6-bce1-458f-8d8a-2a6d7f2e0b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_pickle(\n",
    "    \"../data/split0.3/regression_union_100-600_ampl_bins50_0.3_significant.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a61e3b-58b6-4dcb-9ba3-bbb0c119916b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5869b28f-e935-4a2f-83d3-8dde8271db52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_static_ICA_bin_union_100_600_ampl_bins50_df[\"ex_score\"] = 0\n",
    "\n",
    "for i in range(0,3):\n",
    "    pre_processed_test_X = results_df.pre_processed_pipeline[i].transform(X_test_df)\n",
    "    # print(pre_processed_test_X.shape)\n",
    "    estimator = results_df.best_estimator[i]\n",
    "    score = estimator.score(pre_processed_test_X, y_rum)\n",
    "    # print(score)\n",
    "    # results_static_ICA_bin_union_100_600_ampl_bins50_df[\"ex_score\"] = score\n",
    "    # results_df[\"ex_score\"][i] = score\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e0129-a205-49a4-8f40-b4da59f3d3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_ampl_bins50_df.to_pickle(\"../data/regression_union_100-600_ampl_bins50_0.3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee060e9-da0b-477a-a1b9-ea604b3acfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_ampl_bins50_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e57ce7-4f3e-41b1-a296-5fce0b982360",
   "metadata": {},
   "source": [
    "---\n",
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8206261-467c-4070-9901-cbea95a81d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins width\n",
    "\n",
    "step_in_ms = 50  # in miliseconds (?)\n",
    "step_tp = int(signal_frequency * step_in_ms / 1000) # in timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417d660c-6d59-4965-a96f-ee87b7ac6d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_max_bins50_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed62393-6121-4e05-8bc7-25133ffafd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually test different numbers of spatial filter components\n",
    "\n",
    "timepoints_count = 181\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "    \n",
    "\n",
    "for n_components in range(min_spatial_filter, max_spatial_filter, step_spatial_filter):\n",
    "\n",
    "    pipeline_name = f\"{spatial_filter}_{n_components}_bins_union_100_600_ampl\"\n",
    "    \n",
    "    preprocessed_pipeline = Pipeline([(\"extract_epochs\", EEGdata(dataset=dataset)),\n",
    "        # (\"narrow_indices\", NarrowIndices(start=76, stop=257)),\n",
    "        (\n",
    "            \"channels_filtering\",\n",
    "            ChannelExtraction(significant_channels)\n",
    "        ),\n",
    "        (\n",
    "            \"average_epochs\",\n",
    "            AveragePerParticipant(),\n",
    "        ),\n",
    "        (\"spatial_filter_preprocessing\", SpatialFilterPreprocessing()),\n",
    "        (\n",
    "            \"spatial_filter\",\n",
    "            PCA(n_components=n_components, random_state=random_state),\n",
    "        ),\n",
    "        (\n",
    "            \"spatial_filter_postprocessing\",\n",
    "            SpatialFilterPostprocessing(\n",
    "                timepoints_count=timepoints_count,\n",
    "            ),\n",
    "        ),\n",
    "        (\"lowpass_filter\", LowpassFilter()),\n",
    "        (\"binning\", BinTransformer(step=step_tp)),\n",
    "                              ]).fit(X_train)\n",
    "    \n",
    "    preprocessed_X = preprocessed_pipeline.transform(X_train)\n",
    "    \n",
    "    this_steps = spatial_filter_bins_union_min_max_features(spatial_filter_n_components=n_components, timepoints_count=timepoints_count)\n",
    "    \n",
    "    # this_steps = spatial_filter_bins_steps(spatial_filter_n_components=n_components, timepoints_count=181)\n",
    "    # pre_processing_pipeline = Pipeline(steps=this_steps)\n",
    "    # pre_processed_X = pre_processing_pipeline.fit_transform(X_train)\n",
    "    \n",
    "   \n",
    "    # rate different models\n",
    "    results_static_ICA_bin_union_100_600_max_bins50_df = run_experiment(\n",
    "        tested_regressors,\n",
    "        regressor_params,\n",
    "        pipeline_name,\n",
    "        preprocessed_X,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        dataset_name,\n",
    "        this_steps,\n",
    "        preprocessed_pipeline,\n",
    "        results_static_ICA_bin_union_100_600_max_bins50_df,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef72ea9-e451-4409-a16f-d43a3626f4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_static_ICA_bin_union_100_600_max_bins50_df[\"ex_score\"] = 0\n",
    "\n",
    "\n",
    "for i in range(0,3):\n",
    "    pre_processed_test_X = results_static_ICA_bin_union_100_600_max_bins50_df.pre_processed_pipeline[i].transform(X_test_df)\n",
    "    # print(pre_processed_test_X.shape)\n",
    "    estimator = results_static_ICA_bin_union_100_600_max_bins50_df.best_estimator[i]\n",
    "    score = estimator.score(pre_processed_test_X, y_rum)\n",
    "    # print(score)\n",
    "    # results_static_ICA_bin_union_100_600_max_bins50_df[\"ex_score\"] = score\n",
    "    results_static_ICA_bin_union_100_600_max_bins50_df[\"ex_score\"][i] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c948d939-b1cf-4c8a-9c72-bb058d98b4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_max_bins50_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2061b56f-f336-4c74-99cd-af9ce84783bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_max_bins50_df.to_pickle(\"../data/regression_union_100-600_max_bins50_0.3.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb3b5ae-2486-4ea1-aa8b-652159ef4831",
   "metadata": {},
   "source": [
    "---\n",
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df600a0-7285-409c-ab24-e3e80ec808f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bins width\n",
    "\n",
    "step_in_ms = 50  # in miliseconds (?)\n",
    "step_tp = int(signal_frequency * step_in_ms / 1000) # in timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6914f239-5f52-4023-949b-b724cba5921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_plain_bins50_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245efbd2-2be4-4237-9fd2-80477bc9ef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually test different numbers of spatial filter components\n",
    "\n",
    "timepoints_count = 181\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    os.environ[\"PYTHONWARNINGS\"] = \"ignore\" # Also affect subprocesses\n",
    "    \n",
    "\n",
    "for n_components in range(min_spatial_filter, max_spatial_filter, step_spatial_filter):\n",
    "\n",
    "    pipeline_name = f\"{spatial_filter}_{n_components}_bins_union_100_600_ampl\"\n",
    "    \n",
    "    preprocessed_pipeline = Pipeline([(\"extract_epochs\", EEGdata(dataset=dataset)),\n",
    "        # (\"narrow_indices\", NarrowIndices(start=76, stop=257)),\n",
    "        (\n",
    "            \"channels_filtering\",\n",
    "            ChannelExtraction(significant_channels)\n",
    "        ),\n",
    "        (\n",
    "            \"average_epochs\",\n",
    "            AveragePerParticipant(),\n",
    "        ),\n",
    "        (\"spatial_filter_preprocessing\", SpatialFilterPreprocessing()),\n",
    "        (\n",
    "            \"spatial_filter\",\n",
    "            PCA(n_components=n_components, random_state=random_state),\n",
    "        ),\n",
    "        (\n",
    "            \"spatial_filter_postprocessing\",\n",
    "            SpatialFilterPostprocessing(\n",
    "                timepoints_count=timepoints_count,\n",
    "            ),\n",
    "        ),\n",
    "        (\"lowpass_filter\", LowpassFilter()),\n",
    "        (\"binning\", BinTransformer(step=step_tp)),\n",
    "                              ]).fit(X_train)\n",
    "    \n",
    "    preprocessed_X = preprocessed_pipeline.transform(X_train)\n",
    "    \n",
    "    this_steps = spatial_filter_bins_union_plain_features(spatial_filter_n_components=n_components, timepoints_count=timepoints_count)\n",
    "    \n",
    "    # this_steps = spatial_filter_bins_steps(spatial_filter_n_components=n_components, timepoints_count=181)\n",
    "    # pre_processing_pipeline = Pipeline(steps=this_steps)\n",
    "    # pre_processed_X = pre_processing_pipeline.fit_transform(X_train)\n",
    "    \n",
    "   \n",
    "    # rate different models\n",
    "    results_static_ICA_bin_union_100_600_plain_bins50_df = run_experiment(\n",
    "        tested_regressors,\n",
    "        regressor_params,\n",
    "        pipeline_name,\n",
    "        preprocessed_X,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        dataset_name,\n",
    "        this_steps,\n",
    "        preprocessed_pipeline,\n",
    "        \n",
    "        results_static_ICA_bin_union_100_600_plain_bins50_df,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9112388-240a-445f-8abb-28f3f98bb339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_static_ICA_bin_union_100_600_plain_bins50_df[\"ex_score\"] = 0\n",
    "\n",
    "for i in range(0,3):\n",
    "    pre_processed_test_X = results_static_ICA_bin_union_100_600_plain_bins50_df.pre_processed_pipeline[i].transform(X_test_df)\n",
    "    # print(pre_processed_test_X.shape)\n",
    "    estimator = results_static_ICA_bin_union_100_600_plain_bins50_df.best_estimator[i]\n",
    "    score = estimator.score(pre_processed_test_X, y_rum)\n",
    "    # print(score)\n",
    "    # results_static_ICA_bin_union_100_600_plain_bins50_df[\"ex_score\"] = score\n",
    "    results_static_ICA_bin_union_100_600_plain_bins50_df[\"ex_score\"][i] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499ec140-3474-48d7-9b57-942c5045dddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_plain_bins50_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbb6057-1010-4b26-a886-916e3cbf1da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_plain_bins50_df.to_pickle(\"../data/regression_union_100-600_plain_bins50_0.3.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466713cd-b0d6-488c-b4b9-4995c26cf81b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78db25e-4328-44d9-aedf-b1e9a3949dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_ampl2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c162f349-0a1c-4501-85bf-c669f6f9970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_max_min_without_sx_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4d8525-7f37-407f-9490-afcac857e534",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_static_ICA_bin_union_100_600_max_min_without_sx_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593e1c8f-2fb5-4612-9017-f9a629ace9f0",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4cbb6b-8259-44a6-8ff6-949fe9d7e64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df = pd.read_pickle(\n",
    "#     \"../data/split0.3/regression_union_100-600_baselined_centered_ampl-2-pe-ern_0.3-5_significant.pkl\"\n",
    "# )\n",
    "data_df = results_static_ICA_bin_union_100_600_baselined_peak_to_peak_components_df\n",
    "data_df.name = \"union_100_600_baselined_centered_no_scaler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90458d7d-3a55-479c-9c82-bba82801046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fdc3c7-5692-47ba-8626-fe94ec398b0c",
   "metadata": {},
   "source": [
    "#### Extract coefficients of ERN and PE features extraction (ICA) and coefficient od estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42575b1-e957-4341-94bd-b2efb0604898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ern_features = data_df.best_estimator[1][\"features\"].transformer_list[0][1][\"feature_selection\"].components_\n",
    "# pe_features = data_df.best_estimator[1][\"features\"].transformer_list[1][1][\"feature_selection\"].components_\n",
    "\n",
    "# without additional metric as feature\n",
    "ern_features = data_df.best_estimator[0][\"features\"][\"ern_pe_features\"].transformer_list[0][1][\"feature_selection\"].components_\n",
    "pe_features = data_df.best_estimator[0][\"features\"][\"ern_pe_features\"].transformer_list[1][1][\"feature_selection\"].components_\n",
    "\n",
    "coeffs = data_df.best_estimator[0][\"en\"].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45fc2ed-1541-4b69-88c2-3e1f3fa9333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ern_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089ca93e-e420-401b-b38f-e356ec42a0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ea39cb-334d-4a4f-8312-e722e0b4bc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da26fe94-2a8e-4acb-8cda-9b6e0fc5e8c6",
   "metadata": {},
   "source": [
    "#### Weigh components with coeffs from estimator and sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591889e2-aa90-447e-afde-2385b2bee260",
   "metadata": {},
   "outputs": [],
   "source": [
    "ern_components_weighed = np.array([ern_features[i] * coeffs[i] for i in range(0,ern_features.shape[0])])\n",
    "pe_components_weighed = np.array([pe_features[i-ern_features.shape[0]] * coeffs[i] for i in range(ern_features.shape[0], ern_features.shape[0] + pe_features.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aefe62-2e54-405f-9b33-74523fd6fbe7",
   "metadata": {},
   "source": [
    "#### Sum all feature extraction components to extract direct weigh of given bin at given spatial filter component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2279af91-4d5b-49ec-b4bf-44cf202bdca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "components_weighed_ern_sum = sum(ern_components_weighed)\n",
    "components_weighed_pe_sum = sum(pe_components_weighed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13104848-45d7-45f9-90d0-999642cbaabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "components_weighed_ern_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3905a32-13c0-465f-af63-e7c7f8af4484",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rum_ern = components_weighed_ern_sum * ern_ampl_mean\n",
    "mean_rum_ern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcc551b-646b-4155-bc5b-75f891cc378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_rum_pe = components_weighed_pe_sum * pe_ampl_mean\n",
    "mean_rum_pe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe975747-5514-4b6d-a7d0-5b7c9249c822",
   "metadata": {},
   "source": [
    "#### Extract components of spatial filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e552573-ab6f-457c-a172-2cba7f5a6435",
   "metadata": {},
   "outputs": [],
   "source": [
    "ern_features = Pipeline(steps=[\n",
    "                (\"ern_data_extraction\", ErnTransformer()),\n",
    "                (\"ern_amplitude\", ErnAmplitude2()),\n",
    "                (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                (\"postprocessing\", PostprocessingTransformer()),\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                # (\"feature_selection\", FastICA(random_state=random_state))\n",
    "])\n",
    "\n",
    "\n",
    "pe_features = Pipeline(steps = [\n",
    "                (\"pe_data_extraction\", PeTransformer()),\n",
    "                # (\"pe_centered\", CenteredPeAfterBaseline()),\n",
    "                (\"pe_amplitude\", PeAmplitude2()),\n",
    "                (\"data_channel_swap\", ChannelDataSwap()),\n",
    "                (\"postprocessing\", PostprocessingTransformer()),\n",
    "                # (\"scaler\", StandardScaler()),\n",
    "                # (\"feature_selection\", FastICA(random_state=random_state))\n",
    "])\n",
    "\n",
    "ern_pe_features = FeatureUnion([(\"ern_features\", ern_features), (\"pe_features\", pe_features)], n_jobs = 10)\n",
    "\n",
    "features = Pipeline([\n",
    "    ('ern_pe_features', ern_pe_features)\n",
    "\n",
    "])\n",
    "\n",
    "# steps = ('features', features)\n",
    "\n",
    "preprocessed_pipeline = Pipeline([(\"extract_epochs\", EEGdata(dataset=dataset)),\n",
    "    # (\"narrow_indices\", NarrowIndices(start=76, stop=257)),\n",
    "    (\n",
    "        \"channels_filtering\",\n",
    "        ChannelExtraction(significant_channels)\n",
    "    ),\n",
    "    (\n",
    "        \"average_epochs\",\n",
    "        AveragePerParticipant(),\n",
    "    ),\n",
    "    (\"spatial_filter_preprocessing\", SpatialFilterPreprocessing()),\n",
    "    (\n",
    "        \"spatial_filter\",\n",
    "        PCA(n_components=3, random_state=random_state),\n",
    "    ),\n",
    "    (\n",
    "        \"spatial_filter_postprocessing\",\n",
    "        SpatialFilterPostprocessing(\n",
    "            timepoints_count=181,\n",
    "        ),\n",
    "    ),\n",
    "    (\"lowpass_filter\", LowpassFilter()),\n",
    "    (\"binning\", BinTransformer(step=12)),\n",
    "    (\"baseline\", ErnBaselined()),\n",
    "    (\"centering\", CenteredSignalAfterBaseline()),\n",
    "    # ('features', features)\n",
    "\n",
    "                          ]).fit(X_train)\n",
    "preprocessed_X_test = preprocessed_pipeline.transform(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d0176e-1f92-4939-8aaa-3883ea50c032",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_X = preprocessed_pipeline.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8784737-7a9a-45a8-a1b2-4a4281f31a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f394cf0f-a7b8-4192-91b3-093be1d95197",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe_ampl = preprocessed_X[:,3:6]\n",
    "pe_ampl_mean = np.mean(pe_ampl, axis=0)\n",
    "pe_ampl_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f6736c-5c08-437d-8e09-f93c907a4c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "ern_ampl = preprocessed_X[:,0:3]\n",
    "ern_ampl_mean = np.mean(ern_ampl, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06a14b5-650c-46b2-89cc-07f49ac1b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ern_ampl_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4dd765-9269-410d-831a-cf7e85e71010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps = ('features', features)\n",
    "preprocessed_pipeline = Pipeline([(\"extract_epochs\", EEGdata(dataset=dataset)),\n",
    "            # (\"narrow_indices\", NarrowIndices(start=76, stop=257)),\n",
    "            (\n",
    "                \"channels_filtering\",\n",
    "                ChannelExtraction(significant_channels)\n",
    "            ),\n",
    "            (\n",
    "                \"average_epochs\",\n",
    "                AveragePerParticipant(),\n",
    "            ),\n",
    "            (\"spatial_filter_preprocessing\", SpatialFilterPreprocessing()),\n",
    "            (\n",
    "                \"spatial_filter\",\n",
    "                PCA(n_components=3, random_state=random_state),\n",
    "            ),\n",
    "            (\n",
    "                \"spatial_filter_postprocessing\",\n",
    "                SpatialFilterPostprocessing(\n",
    "                    timepoints_count=181,\n",
    "                ),\n",
    "            ),\n",
    "            (\"lowpass_filter\", LowpassFilter()),\n",
    "            (\"binning\", BinTransformer(step=12)),\n",
    "            (\"baseline\", ErnBaselined()),\n",
    "            (\"centering\", CenteredSignalAfterBaseline()),\n",
    "            ('ern_pe_features', ern_pe_features)\n",
    "                                  ]).fit(X_train)\n",
    "\n",
    "preprocessed_X = preprocessed_pipeline.transform(X_train)\n",
    "pre_processed_test_X = preprocessed_pipeline.transform(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d7e58b-f842-489e-863e-1e2f78d3ed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ern_features = Pipeline(steps=[\n",
    "#                     (\"ern_extraction\", CenteredERN(step=16)),\n",
    "#                     (\"binning\", BinTransformer(step=16)),\n",
    "# #                     (\"data_channel_swap\", ChannelDataSwap()),\n",
    "# #                     (\"postprocessing\", PostprocessingTransformer()),\n",
    "# #                     (\"scaler\", StandardScaler()),\n",
    "# #                     (\"feature_selection\", FastICA(random_state=random_state))\n",
    "# # \n",
    "# ])\n",
    "\n",
    "# pe_features = Pipeline(steps = [\n",
    "#                         (\"pe_extraction\", CenteredPe(step=16)),\n",
    "#                         (\"binning\", BinTransformer(step=16)),\n",
    "# #                         # (\"data_channel_swap\", ChannelDataSwap()),\n",
    "# #                         # (\"postprocessing\", PostprocessingTransformer()),\n",
    "# #                         # (\"scaler\", StandardScaler()),\n",
    "# #                         # (\"feature_selection\", FastICA(random_state=random_state))\n",
    "#         ])\n",
    "    \n",
    "# #         ern_pe_features = FeatureUnion([(\"ern_features\", ern_features), (\"pe_features\", pe_features)], n_jobs = 10)\n",
    "\n",
    "# #         features = Pipeline([\n",
    "# #             ('ern_pe_features', ern_pe_features)\n",
    "\n",
    "# #         ])\n",
    "\n",
    "# #         steps = ('features', features)\n",
    "\n",
    "# ern_fitted = ern_features.fit_transform(preprocessed_X)\n",
    "# ern_test_fitted = ern_features.transform(pre_processed_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f195f5-64d8-4087-893e-1224bcba013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ern_fitted_mean = np.mean(ern_fitted, axis=0)\n",
    "ern_test_fitted_mean = np.mean(ern_test_fitted, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca03f64-94fd-465a-aa8d-45eea6d64eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ern_test_fitted_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8a1499-e289-4e78-835d-e6f5fcfe56f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(ern_fitted_mean[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac3ce80-9136-4bea-9680-193356081190",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eb0ee3-7b85-4ee4-9afb-65aefd48565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_filter_n_components = 3\n",
    "\n",
    "this_steps = spatial_filter_bins_steps(spatial_filter_n_components=spatial_filter_n_components, timepoints_count=181)\n",
    "pre_processed_X = Pipeline(steps=this_steps).fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5b02a2-044a-4553-b3b5-69d0841d228d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_test_X = preprocessed_pipeline.transform(X_test_df)\n",
    "pre_processed_X = preprocessed_pipeline.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3486f6-a736-48c1-b8ce-a1c0d99cfb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaged signal within components through all participants\n",
    "mean_X_1 = np.mean(pre_processed_X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f9cb59-d7a8-4d1d-b5cd-462943105f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ern_fitted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c8a68d-95f0-4c5b-8ada-7b021f8b823f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd337e5-ad95-41be-aecb-f3906b10f22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6757d7-cbc7-42a1-abec-a3cbde22dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaged signal within components through all participants\n",
    "mean_X = np.mean(preprocessed_X, axis=0)\n",
    "mean_2_X = np.mean(pre_processed_test_X, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6573c8-792b-4eba-a2ea-474177d202e7",
   "metadata": {},
   "source": [
    "-----\n",
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd22a81b-c033-4672-93a7-f7003ed1dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices in bins\n",
    "\n",
    "tmin, tmax = -0.1, 0.6  # Start and end of the segments\n",
    "signal_frequency = 256\n",
    "\n",
    "step_in_ms = 50  # in miliseconds (?)\n",
    "step_tp = int(signal_frequency * step_in_ms / 1000) # in timepoints\n",
    "\n",
    "# indices for slicing epoch into ERN part and Pe part (in sec)\n",
    "start_ern = 0\n",
    "stop_ern = 0.15\n",
    "start_pe = 0.15\n",
    "stop_pe = 0.35\n",
    "\n",
    "start_ern_bin = int((signal_frequency * (start_ern - tmin)) / step_tp) + 1\n",
    "stop_ern_bin = int(signal_frequency * (stop_ern - tmin) / step_tp) + 1\n",
    "start_pe_bin = int(signal_frequency * (start_pe - tmin) / step_tp) + 1\n",
    "stop_pe_bin = int(signal_frequency * (stop_pe - tmin) / step_tp) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430dbc2b-8302-4624-a55b-67bde67f741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ern_bin = 0\n",
    "stop_ern_bin = 3\n",
    "start_pe_bin = 3\n",
    "stop_pe_bin = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13efc2d-cf0c-4314-9917-19144e6cf4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_filter_n_components = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88488c65-4b2a-4c04-a963-506505712f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0, 1 or 2\n",
    "this_component = 2\n",
    "\n",
    "# pe_step = int(pe_features.shape[1]/ spatial_filter_n_components)\n",
    "# ern_step = int(ern_features.shape[1]/ spatial_filter_n_components)\n",
    "# spatial_filter_step = int(pre_processed_X.shape[1]/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f7c0a8-e843-4a1b-924e-ad9618f1b9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_filter_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1310d788-67e6-4bd0-aac2-74dc87d23f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "ern_components_weighed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a781ecdb-0d91-4437-9969-2d380b8df101",
   "metadata": {},
   "outputs": [],
   "source": [
    "-ern_fitted_mean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c3a287-972a-4976-b72c-8857c162ec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ern_components_weighed[0][0:3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86258f07-0dde-46c7-8ed2-c6822dd21f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0,4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e938b9f5-af49-4100-93f6-e15de0582164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# ax1 = plt.twinx()\n",
    "ax1.set(ylim=(np.min(ern_components_weighed)-0.1, np.max(pe_components_weighed)+0.05))\n",
    "ax1.tick_params(axis='y', color=\"magenta\", width=3, length=10)\n",
    "\n",
    "plt.axhline(y=0, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=2, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=6, color=\"grey\", linewidth = 2, linestyle='--', alpha=0.5)\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(0,5):\n",
    "#     sns.lineplot(np.arange(0,3), ern_components_weighed[i][this_component:3], ax=ax1)\n",
    "\n",
    "# for i in range(0,pe_features.shape[0]):\n",
    "#     sns.scatterplot(np.arange(5,6), pe_components_weighed[i][this_component], ax=ax1)\n",
    "    \n",
    "\n",
    "ax2 = plt.twinx()\n",
    "ax2.set(ylim=(-1e-5,2.5e-5))\n",
    "ax2.tick_params(axis='y', color=\"black\")\n",
    "\n",
    "# ax3 = plt.twinx()\n",
    "# ax3.set(ylim=(min(components_weighed_ern_sum), max(components_weighed_ern_sum)))\n",
    "# ax3.tick_params(axis='y', color=\"magenta\")\n",
    "\n",
    "sns.scatterplot(x=[4], y= components_weighed_pe_sum[this_component], ax=ax1, color=\"magenta\")\n",
    "sns.scatterplot(x=[1], y= components_weighed_ern_sum[this_component], ax=ax1, color=\"magenta\")\n",
    "# sns_plot = sns.scatterplot(np.arange(5,6), components_weighed_pe_sum[this_component*pe_step:(this_component+1)*pe_step], ax=ax1, color=\"magenta\")\n",
    "# plt.axhline(y=0, color=\"magenta\", linewidth = 2)\n",
    "\n",
    "sns_plot = sns.lineplot(np.arange(0,10), -mean_X[this_component], ax=ax2, color=\"black\", linewidth = 3)\n",
    "\n",
    "\n",
    "sns_plot.figure.savefig(f\"{data_df.name}_output_{this_component}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a547dfae-7072-4983-9462-d97eacf968bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902ccd1e-bb51-4402-983e-ee5e909984a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_rum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e73ff6-3d71-4b09-818d-5c883636c881",
   "metadata": {},
   "source": [
    "# CURRENT BEST RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed55ab31-ce10-4b62-95c7-6a252a3586b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_pickle(\n",
    "    \"../data/split0.3/regression_union_100-600_ampl_bins50_0.3_significant.pkl\"\n",
    ")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7552610c-11bb-4836-8abd-a1bf40f70ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_pickle(\n",
    "    \"../data/split0.3/regression_union_100-600_centered_signal_ampl_0.3-5_significant.pkl\"\n",
    ")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93acf9d8-6d12-4b97-80dc-41e7515501a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_pickle(\n",
    "    \"../data/split0.3/regression_union_100-600_centered_signal_baselined-to-0-bin_signal_0.3-5.pkl\"\n",
    ")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d60ee-ad10-4611-9fd2-3b5123682bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_pickle(\n",
    "    \"../data/split0.3/regression_union_100-600_baselined_centered_ampl-2-pe-ern_0.3-5_significant.pkl\"\n",
    ")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05c76ff-bede-43d8-8755-f9870d928bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erpinator",
   "language": "python",
   "name": "erpinator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
