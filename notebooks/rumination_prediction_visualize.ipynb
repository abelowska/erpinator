{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import os\n",
    "import pickle\n",
    "from time import time\n",
    "import pywt\n",
    "import mne\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import cesium.featurize\n",
    "from time import sleep\n",
    "from random import shuffle\n",
    "from plotly.subplots import make_subplots\n",
    "from ipywidgets import Dropdown, FloatRangeSlider, IntSlider, FloatSlider, interact\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "from utils import *\n",
    "from architecture import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore np.corrcoef RuntimeWarnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import HTML\n",
    "\n",
    "# display(HTML('<span style=\"color: #ff0000\">red</span>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dummy regressor for baseline\n",
    "# dummy_regr = DummyRegressor(strategy=\"mean\")\n",
    "\n",
    "# scores = []\n",
    "# kf = KFold(n_splits=5)\n",
    "# for train_index, test_index in kf.split(X, y):\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "#     dummy_regr.fit(X_train, y_train)\n",
    "#     y_pred = dummy_regr.predict(X_test)\n",
    "\n",
    "#     corr = np.corrcoef(y_test, y_pred)[0][1]\n",
    "#     r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "#     scores.append([corr, r2])\n",
    "\n",
    "# # print scores\n",
    "# means = np.mean(scores, axis=0)\n",
    "# sems = scipy.stats.sem(scores, axis=0)\n",
    "# for mean, sem in zip(means, sems):\n",
    "#     print(f\"{mean:5.2f}±{sem:4.2f}\", end=\"   \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# grid_search = GridSearchCV(\n",
    "#     pipeline,\n",
    "#     regressor_params,\n",
    "#     cv=5,\n",
    "#     scoring={\"r2\": \"r2\"},\n",
    "#     refit=False,\n",
    "#     n_jobs=1,\n",
    "#     verbose=3,\n",
    "# )\n",
    "# grid_search.fit(X, y)\n",
    "\n",
    "# # predictions = grid_search.predict(X_test)\n",
    "# # r2 = grid_search.score(X_test, y_test)\n",
    "# None\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=0, shuffle=False\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "false"
   },
   "source": [
    "Loading EEG data and data from rumination questionnaire. By default create_df_data loads all info from given file but one can specify it by passing a list of desired labels from csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_name = \"go_nogo_df_non_personal\"\n",
    "pickled_data_filename = \"../data/\" + df_name + \".pkl\"\n",
    "info_filename = \"../data/Demographic_Questionnaires_Behavioral_Results_N=163.csv\"\n",
    "\n",
    "# Check if data is already loaded\n",
    "if os.path.isfile(pickled_data_filename):\n",
    "    print(\"Pickled file found. Loading pickled data...\")\n",
    "    epochs_df = pd.read_pickle(pickled_data_filename)\n",
    "    print(\"Done\")\n",
    "else:\n",
    "    print(\"Pickled file not found. Loading data...\")\n",
    "    epochs_df = create_df_data(info_filename=info_filename, personal=False)\n",
    "    epochs_df.name = df_name\n",
    "    # save loaded data into a pickle file\n",
    "    epochs_df.to_pickle(\"../data/\" + epochs_df.name + \".pkl\")\n",
    "    print(\"Done. Pickle file created\")\n",
    "\n",
    "# Data is now read into dataframe and each epoch is a single record.\n",
    "# Sorting participants by the number of errors, descending. This way the best participants are first.\n",
    "\n",
    "# add new columns with info about error/correct responses amount\n",
    "grouped_df = epochs_df.groupby(\"id\")\n",
    "epochs_df[\"error_sum\"] = grouped_df[[\"marker\"]].transform(\n",
    "    lambda x: (x.values == ERROR).sum()\n",
    ")\n",
    "epochs_df[\"correct_sum\"] = grouped_df[[\"marker\"]].transform(\n",
    "    lambda x: (x.values == CORRECT).sum()\n",
    ")\n",
    "\n",
    "# mergesort for stable sorting\n",
    "epochs_df = epochs_df.sort_values(\"error_sum\", ascending=False, kind=\"mergesort\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test, y_test = X_train, y_train\n",
    "def custom_gridsearch(steps, cv, regressor_params, memory):\n",
    "    pipeline = Pipeline(steps, memory=memory)\n",
    "    print(\" \" * 133 + \"corr           r2\")\n",
    "\n",
    "    # get params randomly\n",
    "    all_params = list(ParameterGrid(regressor_params))\n",
    "    # shuffle(all_params)\n",
    "\n",
    "    for params in all_params:\n",
    "        pipeline.set_params(**params)\n",
    "\n",
    "        scores = []\n",
    "        kf = KFold(n_splits=cv)\n",
    "        for train_index, test_index in kf.split(X, y):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "            corr = np.corrcoef(y_test, y_pred)[0][1]\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "            scores.append([corr, r2])\n",
    "\n",
    "        # print scores\n",
    "        print(f\"{str(params):126}\", end=\" \")\n",
    "        means = np.mean(scores, axis=0)\n",
    "        sems = scipy.stats.sem(scores, axis=0)\n",
    "        for mean, sem in zip(means, sems):\n",
    "            print(f\"{mean:5.2f}±{sem:4.2f}\", end=\"   \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(epochs_df[epochs_df[\"marker\"] == ERROR][\"epoch\"].to_list())\n",
    "y = np.array(epochs_df[epochs_df[\"marker\"] == ERROR][\"Rumination Full Scale\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedir = \"/home/filip/.erpinator_cache\"\n",
    "\n",
    "steps = steps_peaks_and_power_and_shape\n",
    "# steps = steps[:-1] + [(\"knr\", KNeighborsRegressor())]\n",
    "\n",
    "regressor_params = dict(\n",
    "    spatial_filter__n_components=[6],\n",
    "    #     cwt__mwt=[\"mexh\"],\n",
    "    #     pca__n_components=[3],\n",
    "    featurize__power__cwt__mwt=[\"cmor0.5-1\"],\n",
    "    featurize__power__pca__n_components=[3],\n",
    "    featurize__shape__pca__n_components=[3],\n",
    "    svr__C=[0.05],\n",
    "#     knr__n_neighbors=[25],\n",
    ")\n",
    "print(regressor_params)\n",
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# custom_gridsearch(steps, cv=5, regressor_params=regressor_params, memory=cachedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model on splitted participants, and then predict rumination for each or their epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_epochs = epochs_df[epochs_df[\"marker\"] == CORRECT]\n",
    "\n",
    "grouped = error_epochs.groupby([\"id\"])\n",
    "participant_ids = error_epochs[\"id\"].unique()\n",
    "\n",
    "personal_scores = []\n",
    "# kf = KFold(n_splits=len(participant_ids))\n",
    "kf = KFold(n_splits=5)\n",
    "for train_index, test_index in kf.split(participant_ids):\n",
    "    p_train, p_test = participant_ids[train_index], participant_ids[test_index]\n",
    "\n",
    "    train_epochs = error_epochs[[e_id in p_train for e_id in error_epochs[\"id\"]]]\n",
    "    test_epochs = error_epochs[[e_id in p_test for e_id in error_epochs[\"id\"]]]\n",
    "\n",
    "    X_train = np.array(train_epochs[\"epoch\"].to_list())\n",
    "    y_train = np.array(train_epochs[\"Rumination Full Scale\"].to_list())\n",
    "\n",
    "    pipeline = Pipeline(steps, memory=cachedir)\n",
    "    pipeline.set_params(**ParameterGrid(regressor_params)[0])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    for participant_id in p_test:\n",
    "        participant_df = grouped.get_group(participant_id)\n",
    "        X_test = np.array(participant_df[\"epoch\"].to_list())\n",
    "        y_test = np.array(participant_df[\"Rumination Full Scale\"].to_list())\n",
    "\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        print(y_pred.mean(), np.median(y_pred), y_test[0])\n",
    "        personal_scores.append([y_pred, y_test[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = [preds.mean() for preds, true in personal_scores]\n",
    "medians = [np.median(preds) for preds, true in personal_scores]\n",
    "trues = [true for preds, true in personal_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "all_trues = []\n",
    "for preds, true in personal_scores:\n",
    "    for pred in preds:\n",
    "        all_preds.append(pred)\n",
    "        all_trues.append(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(all_preds, all_trues)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(means, trues)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(medians, trues)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(all_trues, all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(trues, means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(trues, medians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.FigureWidget(layout=base_layout)\n",
    "fig.update_layout(height=600, width=600)\n",
    "fig.add_scatter(x=trues, y=medians, mode=\"markers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = go.FigureWidget(layout=base_layout)\n",
    "# fig.update_layout(height=600, width=600)\n",
    "# fig.add_scatter(x=all_trues, y=all_preds, mode=\"markers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_scores = sorted(personal_scores, key=lambda pair: pair[1])\n",
    "preds_sorted = []\n",
    "trues_sorted = []\n",
    "for i, pair in enumerate(sorted_scores):\n",
    "    preds, true = pair\n",
    "    for pred in preds:\n",
    "        preds_sorted.append(pred)\n",
    "        trues_sorted.append(i)\n",
    "\n",
    "fig = go.FigureWidget(layout=base_layout)\n",
    "fig.update_layout(height=600, width=600)\n",
    "fig.add_scatter(x=trues_sorted, y=preds_sorted, mode=\"markers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erpinator",
   "language": "python",
   "name": "erpinator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
