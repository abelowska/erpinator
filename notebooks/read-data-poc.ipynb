{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG classification\n",
    "\n",
    "Link to working-documentation. Please, **update** when have an idea, plan or when sth important was done.\n",
    "\n",
    "\n",
    "https://docs.google.com/document/d/1i7tLHpXD-uXY5BopIGGcu-KWAR1DZvSlxQbYRi4fvBI/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext lab_black\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "import numpy as np\n",
    "import pywt\n",
    "from utils import tmax, tmin\n",
    "\n",
    "# plt.style.use(\"dark_background\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_bads(epochs, bads, replacement=0):\n",
    "    \"\"\"Clear specified channels in epochs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    epochs : mne Epochs\n",
    "        epochs for clearing.\n",
    "    bads: array[(epoch, channel)]\n",
    "        list of tuples (epoch, channel) for clearing.\n",
    "    replacement: int\n",
    "        sign for replacing.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    epochs : mne Epochs\n",
    "        cleared epochs.\n",
    "    \"\"\"\n",
    "\n",
    "    eeg_data = epochs.get_data()\n",
    "    overlapped_epochs_set = set()\n",
    "\n",
    "    #     print(\"Cleared channels: \")\n",
    "    for epoch_index, channel_index in bads:\n",
    "        overlapped_epochs_set.add(epoch_index)\n",
    "        #         print(\"channel: {} , epoch_index: {}\".format(channel_index, epoch_index))\n",
    "\n",
    "        eeg_data[epoch_index][channel_index] = [replacement]\n",
    "\n",
    "    print(\"Amount of overlapped epochs: {}\".format(len(overlapped_epochs_set)))\n",
    "    print(\"Overlapped epochs: {}\".format(overlapped_epochs_set))\n",
    "\n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_to_peak_amplitude(signal):\n",
    "    n_samples = len(signal)\n",
    "\n",
    "    signal_fft = np.fft.fft(signal)\n",
    "    amplitudes = 2 / n_samples * np.abs(signal_fft)\n",
    "    peak_to_peak_amplitude = max(amplitudes) - min(amplitudes)\n",
    "\n",
    "    #     print('peak to peak amplitude {}, max amplitude: {}'.format(peak_to_peak_amplitude, max(amplitudes)))\n",
    "\n",
    "    return peak_to_peak_amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bad_epochs_channel_index(annotation, current_segment_index):\n",
    "    \"\"\"Gets epochs and channels indices where annotation given as parameter occures.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    annotation: OrderDict\n",
    "    current_segment_index: int\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bad_epoch_channel_index: array[(epoch, channel)]\n",
    "\n",
    "    \"\"\"\n",
    "    onset = annotation[\"onset\"]  # as position in datapoint\n",
    "    duration = annotation[\"duration\"]  # as ticks\n",
    "    channel_num = annotation[\"channel_num\"]\n",
    "    channel_index = channel_num - 1\n",
    "\n",
    "    bad_epoch_channel_index = []\n",
    "\n",
    "    bad_interval_start_index = current_segment_index\n",
    "    bad_interval_end_index = get_epoch_index(onset_in_ticks=onset + duration)\n",
    "\n",
    "    for i in range(bad_interval_start_index, bad_interval_end_index + 1):\n",
    "        bad_epoch_channel_index.append((i, channel_index))\n",
    "\n",
    "    return bad_epoch_channel_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epoch_index(onset_in_ticks):\n",
    "    \"\"\"\n",
    "    onset_in_ticks: int\n",
    "        Time elapsed since tick number 0 in ticks.\n",
    "    \"\"\"\n",
    "    #     freq = raw.info['sfreq']\n",
    "    freq = 256\n",
    "    segment_duration = int((tmax - tmin) * freq)\n",
    "    epoch_index = int(onset_in_ticks // segment_duration)\n",
    "\n",
    "    return epoch_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bads_by_peak_to_peak_amplitude(epochs, amplitude=4e-5):\n",
    "    \"\"\"Finds bad epochs and channels, based on signal amplitude thresholds.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    epochs : mne Epochs\n",
    "        epochs for clearing.\n",
    "    amplitude: float\n",
    "        maximum acceptable peak-to-peak amplitude.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bads : array[(epoch, channel)]\n",
    "    \"\"\"\n",
    "    epoch_data = epochs.get_data()\n",
    "    bads = []\n",
    "\n",
    "    for epoch_index in range(len(epoch_data)):\n",
    "        epoch = epoch_data[epoch_index]\n",
    "        for channel_index in range(len(epoch)):\n",
    "            channel_data = epoch[channel_index]\n",
    "            this_amplitude = peak_to_peak_amplitude(channel_data)\n",
    "\n",
    "            if this_amplitude > amplitude:\n",
    "                #                 print('Epoch: {}, Channel: {}, Amplitude: {}'.format(epoch_index, channel_index, this_amplitude))\n",
    "                bads.append((epoch_index, channel_index))\n",
    "\n",
    "    return bads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bads_by_annotation(\n",
    "    annotations, rejected_description=\"Bad Interval/Bad Amplitude\"\n",
    "):\n",
    "    \"\"\"Finds bad epochs and channels, based on annotation file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    epochs : mne Epochs\n",
    "        epochs for clearing.\n",
    "    annotations: array[OrderDict]\n",
    "        list of all annotations from .vmrk file\n",
    "    rejected_description: String\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bads : array[(epoch, channel)]\n",
    "    \"\"\"\n",
    "\n",
    "    bads = []\n",
    "    current_segment_index = -1\n",
    "\n",
    "    for annot in annotations:\n",
    "        if annot[\"description\"] == \"New Segment/\":\n",
    "            current_segment_index += 1\n",
    "\n",
    "        if annot[\"description\"] == rejected_description:\n",
    "            this_bad = get_bad_epochs_channel_index(annot, current_segment_index)\n",
    "            bads = bads + this_bad\n",
    "\n",
    "    return bads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def get_epoch_channels_dict(bads):\n",
    "    \"\"\"Create default dictionary from array of tuples\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    bads: array\n",
    "        array consisting of tuples (epoch_index, channel_index) which are concernd as bad.\n",
    "    Returns\n",
    "    -------\n",
    "    epoch_channel_dict: dict\n",
    "    \"\"\"\n",
    "\n",
    "    epoch_channels_dict = defaultdict(list)\n",
    "\n",
    "    for epoch_index, channel_index in bads:\n",
    "        epoch_channels_dict[epoch_index].append(channel_index)\n",
    "\n",
    "    return epoch_channels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject_with_mask(epochs, mask, bads):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    epochs: mne Epochs\n",
    "    mask: array\n",
    "        array consisting of 0s and 1s determinig which channels are off and on.\n",
    "        Length of mask must be equal to amount of eeg channels.\n",
    "    bads: array\n",
    "        array consisting of tuples (epoch_index, channel_index) which are concernd as bad.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    epochs: mne Epochs\n",
    "    \"\"\"\n",
    "    bads_dict = get_epoch_channels_dict(bads)\n",
    "    epoch_drop_indices = []\n",
    "    print(bads_dict)\n",
    "\n",
    "    for epoch_index in bads_dict:\n",
    "        channels = bads_dict.get(epoch_index)\n",
    "        filtered_channels = list(filter(lambda item: mask[item] == 0, channels))\n",
    "\n",
    "        if len(channels) != len(filtered_channels):\n",
    "            epoch_drop_indices.append(epoch_index)\n",
    "\n",
    "    epochs.drop(indices=epoch_drop_indices)\n",
    "\n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import os.path as op\n",
    "\n",
    "\n",
    "def _read_vmrk(fname):\n",
    "    \"\"\"Read annotations from a vmrk file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fname : str\n",
    "        vmrk file to be read.\n",
    "    Returns\n",
    "    -------\n",
    "    onset : array, shape (n_annots,)\n",
    "        The onsets in ticks.\n",
    "    duration : array, shape (n_annots,)\n",
    "        The duration in ticks.\n",
    "    description : array, shape (n_annots,)\n",
    "        The description of each annotation.\n",
    "    channel_num : array, shape (n_annots,)\n",
    "        The channel number.\n",
    "    \"\"\"\n",
    "    # read vmrk file\n",
    "    with open(fname, \"rb\") as fid:\n",
    "        txt = fid.read()\n",
    "\n",
    "    # we don't actually need to know the coding for the header line.\n",
    "    # the characters in it all belong to ASCII and are thus the\n",
    "    # same in Latin-1 and UTF-8\n",
    "    header = txt.decode(\"ascii\", \"ignore\").split(\"\\n\")[0].strip()\n",
    "    #     _check_bv_version(header, 'marker')\n",
    "\n",
    "    # although the markers themselves are guaranteed to be ASCII (they\n",
    "    # consist of numbers and a few reserved words), we should still\n",
    "    # decode the file properly here because other (currently unused)\n",
    "    # blocks, such as that the filename are specifying are not\n",
    "    # guaranteed to be ASCII.\n",
    "\n",
    "    try:\n",
    "        # if there is an explicit codepage set, use it\n",
    "        # we pretend like it's ascii when searching for the codepage\n",
    "        cp_setting = re.search(\n",
    "            \"Codepage=(.+)\", txt.decode(\"ascii\", \"ignore\"), re.IGNORECASE & re.MULTILINE\n",
    "        )\n",
    "        codepage = \"utf-8\"\n",
    "        if cp_setting:\n",
    "            codepage = cp_setting.group(1).strip()\n",
    "        # BrainAmp Recorder also uses ANSI codepage\n",
    "        # an ANSI codepage raises a LookupError exception\n",
    "        # python recognize ANSI decoding as cp1252\n",
    "        if codepage == \"ANSI\":\n",
    "            codepage = \"cp1252\"\n",
    "        txt = txt.decode(codepage)\n",
    "    except UnicodeDecodeError:\n",
    "        # if UTF-8 (new standard) or explicit codepage setting fails,\n",
    "        # fallback to Latin-1, which is Windows default and implicit\n",
    "        # standard in older recordings\n",
    "        txt = txt.decode(\"latin-1\")\n",
    "\n",
    "    # extract Marker Infos block\n",
    "    m = re.search(r\"\\[Marker Infos\\]\", txt, re.IGNORECASE)\n",
    "    if not m:\n",
    "        return np.array(list()), np.array(list()), np.array(list()), \"\"\n",
    "\n",
    "    mk_txt = txt[m.end() :]\n",
    "    m = re.search(r\"^\\[.*\\]$\", mk_txt)\n",
    "    if m:\n",
    "        mk_txt = mk_txt[: m.start()]\n",
    "\n",
    "    # extract event information\n",
    "    items = re.findall(r\"^Mk\\d+=(.*)\", mk_txt, re.MULTILINE)\n",
    "    onset, duration, description, channel_num = list(), list(), list(), list()\n",
    "    date_str = \"\"\n",
    "    for info in items:\n",
    "        info_data = info.split(\",\")\n",
    "        mtype, mdesc, this_onset, this_duration, this_channel_num = info_data[:5]\n",
    "        # commas in mtype and mdesc are handled as \"\\1\". convert back to comma\n",
    "        mtype = mtype.replace(r\"\\1\", \",\")\n",
    "        mdesc = mdesc.replace(r\"\\1\", \",\")\n",
    "        if date_str == \"\" and len(info_data) == 5 and mtype == \"New Segment\":\n",
    "            # to handle the origin of time and handle the presence of multiple\n",
    "            # New Segment annotations. We only keep the first one that is\n",
    "            # different from an empty string for date_str.\n",
    "            date_str = info_data[-1]\n",
    "\n",
    "        this_duration = int(this_duration) if this_duration.isdigit() else 0\n",
    "        duration.append(this_duration)\n",
    "        onset.append(int(this_onset) - 1)  # BV is 1-indexed, not 0-indexed\n",
    "        description.append(mtype + \"/\" + mdesc)\n",
    "        channel_num.append(int(this_channel_num))\n",
    "\n",
    "    return (\n",
    "        np.array(onset),\n",
    "        np.array(duration),\n",
    "        np.array(description),\n",
    "        np.array(channel_num),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations(fname):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    -------\n",
    "    annotations: array[OrderDict]\n",
    "\n",
    "    \"\"\"\n",
    "    annotations_attributes = [\"onset\", \"duration\", \"description\", \"channel_num\"]\n",
    "\n",
    "    onset, duration, description, channel_num = _read_vmrk(\"../data/\" + fname)\n",
    "    annotations_list = list(zip(onset, duration, description, channel_num))\n",
    "\n",
    "    annotations = []\n",
    "\n",
    "    for item in annotations_list:\n",
    "        #         annot = CustomAnnotations(*item)\n",
    "        annot = dict(zip(annotations_attributes, list(item)))\n",
    "        annotations.append(annot)\n",
    "\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_epochs_from_file(file, reject_bad_segments=\"auto\", mask=None):\n",
    "    \"\"\"Load epochs from a header file.\n",
    "\n",
    "    Args:\n",
    "        file: path to a header file (.vhdr)\n",
    "        reject_bad_segments: 'auto' | 'annot' | 'peak-to-peak'\n",
    "\n",
    "        Whether the epochs with overlapping bad segments are rejected by default.\n",
    "\n",
    "        'auto' means that bad segments are rejected automatically.\n",
    "        'annot' rejection based on annotations and reject only channels annotated in .vmrk file as\n",
    "        'bad'.\n",
    "        'amplitude' rejection based on peak-to-peak amplitude of channels.\n",
    "\n",
    "        Rejected with 'annot' and 'amplitude' channels are zeroed.\n",
    "\n",
    "    Returns:\n",
    "        mne Epochs\n",
    "\n",
    "    \"\"\"\n",
    "    # Import the BrainVision data into an MNE Raw object\n",
    "    raw = mne.io.read_raw_brainvision(\"../data/\" + file)\n",
    "\n",
    "    # Construct annotation filename\n",
    "    annot_file = file[:-4] + \"vmrk\"\n",
    "\n",
    "    # Read in the event information as MNE annotations\n",
    "    annotations = mne.read_annotations(\"../data/\" + annot_file)\n",
    "\n",
    "    # Add the annotations to our raw object so we can use them with the data\n",
    "    raw.set_annotations(annotations)\n",
    "\n",
    "    # Map with response markers only\n",
    "    event_dict = {\n",
    "        \"Stimulus/RE*ex*1_n*1_c_1*R*FB\": 10004,\n",
    "        \"Stimulus/RE*ex*1_n*1_c_1*R*FG\": 10005,\n",
    "        \"Stimulus/RE*ex*1_n*1_c_2*R\": 10006,\n",
    "        \"Stimulus/RE*ex*1_n*2_c_1*R\": 10007,\n",
    "        \"Stimulus/RE*ex*2_n*1_c_1*R\": 10008,\n",
    "        \"Stimulus/RE*ex*2_n*2_c_1*R*FB\": 10009,\n",
    "        \"Stimulus/RE*ex*2_n*2_c_1*R*FG\": 10010,\n",
    "        \"Stimulus/RE*ex*2_n*2_c_2*R\": 10011,\n",
    "    }\n",
    "\n",
    "    # Map for merged correct/error response markers\n",
    "    merged_event_dict = {\"correct_response\": 0, \"error_response\": 1}\n",
    "\n",
    "    # Reconstruct the original events from Raw object\n",
    "    events, event_ids = mne.events_from_annotations(raw, event_id=event_dict)\n",
    "\n",
    "    # Merge correct/error response events\n",
    "    merged_events = mne.merge_events(\n",
    "        events,\n",
    "        [10004, 10005, 10009, 10010],\n",
    "        merged_event_dict[\"correct_response\"],\n",
    "        replace_events=True,\n",
    "    )\n",
    "    merged_events = mne.merge_events(\n",
    "        merged_events,\n",
    "        [10006, 10007, 10008, 10011],\n",
    "        merged_event_dict[\"error_response\"],\n",
    "        replace_events=True,\n",
    "    )\n",
    "\n",
    "    epochs = []\n",
    "    bads = []\n",
    "    this_reject_by_annotation = True\n",
    "\n",
    "    if reject_bad_segments != \"auto\":\n",
    "        this_reject_by_annotation = False\n",
    "\n",
    "    # Read epochs\n",
    "    temp_epochs = mne.Epochs(\n",
    "        raw=raw,\n",
    "        events=merged_events,\n",
    "        event_id=merged_event_dict,\n",
    "        tmin=tmin,\n",
    "        tmax=tmax,\n",
    "        baseline=None,\n",
    "        reject_by_annotation=this_reject_by_annotation,\n",
    "        preload=True,\n",
    "    )\n",
    "\n",
    "    if reject_bad_segments == \"annot\":\n",
    "        custom_annotations = get_annotations(annot_file)\n",
    "        bads = get_bads_by_annotation(custom_annotations)\n",
    "    elif reject_bad_segments == \"peak-to-peak\":\n",
    "        bads = get_bads_by_peak_to_peak_amplitude(temp_epochs)\n",
    "    else:\n",
    "        epochs = temp_epochs\n",
    "        return epochs\n",
    "\n",
    "    if mask is None:\n",
    "        epochs = clear_bads(temp_epochs, bads)\n",
    "    elif len(mask) == 64:\n",
    "        epochs = reject_with_mask(temp_epochs, mask, bads)\n",
    "    else:\n",
    "        print(\n",
    "            \"Given mask has wrong shape. Expected len of 64 but got {}\".format(\n",
    "                len(mask)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"GNG_BK0504-64 el.vhdr\"\n",
    "\n",
    "data_bad_annot = load_epochs_from_file(file=file, reject_bad_segments=\"annot\")\n",
    "data_bad_amplitude = load_epochs_from_file(\n",
    "    file=file, reject_bad_segments=\"peak-to-peak\"\n",
    ")\n",
    "data_clear = load_epochs_from_file(file=file, reject_bad_segments=\"auto\")\n",
    "data_bad_mask = load_epochs_from_file(\n",
    "    file=file, reject_bad_segments=\"peak-to-peak\", mask=np.zeros((64,), dtype=int)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_epoch = 100\n",
    "this_channel = 0\n",
    "data_temp = data_bad_mask[this_epoch]._data[0][this_channel]\n",
    "\n",
    "amplitude = peak_to_peak_amplitude(data_temp)\n",
    "print(\"amp: {}\".format(amplitude))\n",
    "\n",
    "\n",
    "data_bad_mask[this_epoch].plot(n_epochs=2, event_colors={0: \"g\", 1: \"m\"})\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bad_amplitude.plot(n_epochs=1, event_colors={0: \"g\", 1: \"m\"})\n",
    "None  # prevents doubled output\n",
    "\n",
    "epochs = data_bad_amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_response_epochs = epochs[\"correct_response\"]\n",
    "error_response_epochs = epochs[\"error_response\"]\n",
    "\n",
    "\n",
    "# Calculate averages of events sets\n",
    "correct_response_evoked = correct_response_epochs.average()\n",
    "error_response_evoked = error_response_epochs.average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averages of two event sets\n",
    "\n",
    "mne.viz.plot_compare_evokeds(\n",
    "    dict(\n",
    "        correct_response=correct_response_evoked, error_response=error_response_evoked\n",
    "    ),\n",
    "    legend=\"upper left\",\n",
    "    show_sensors=\"upper right\",\n",
    "    ylim=dict(eeg=[-10, 10]),\n",
    "    invert_y=True,\n",
    "    combine=\"mean\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averages of error response events per channel\n",
    "\n",
    "error_response_evoked.plot_joint(picks=\"eeg\")\n",
    "error_response_evoked.plot_topomap(times=[0.0, 0.08, 0.1, 0.12, 0.2], ch_type=\"eeg\")\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averages of merged event sets (diff between error and correct) per channel\n",
    "\n",
    "evoked_diff = mne.combine_evoked(\n",
    "    [correct_response_evoked, error_response_evoked], weights=[1, -1]\n",
    ")\n",
    "evoked_diff.plot_joint()\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-processing done with Brain Vision Software:**\n",
    "\n",
    "- Notch filter  0.05-25\n",
    "- Baseline Correction //what baseline?\n",
    "- Ocular Correction\n",
    "- Artifact Rejection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extraction recommended for eeg data is **Wavelet Transform** (especially **Discrite Wavelet Transform**). Better that FFT for biomedical signals because of its localization characteristics of non-stationary signals in time and frequency domains. DWT decompositing signal into five frequency bands.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Discrete_wavelet_transform\n",
    "\n",
    "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0173138&type=printable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for feature extraction: create X-data array and Y-labels array\n",
    "\n",
    "X = epochs._data\n",
    "Y = []\n",
    "\n",
    "for i in range(len(epochs)):\n",
    "    event_id = list(epochs[i].event_id.values())[0]\n",
    "    Y.append(event_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Wavelet Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mother wavelets list for continuous WT\n",
    "\n",
    "MWT_list = pywt.wavelist(kind=\"continuous\")\n",
    "\n",
    "# Remove cmor, fbsp, shan wavelets because of need of special specification\n",
    "# of this wavelet with bandpass and center - do not want to handle with it NOW.\n",
    "MWT_list.remove(\"cmor\")\n",
    "MWT_list.remove(\"fbsp\")\n",
    "MWT_list.remove(\"shan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct list of scales corresponding to pseudo-frequencies [128Hz-1Hz] for each wavelet\n",
    "# Could help understand: https://www.researchgate.net/publication/267491844_Continuous_Wavelet_Transform_EEG_Features_of_Alzheimer%27s_Disease\n",
    "\n",
    "# TODO: refactor\n",
    "\n",
    "signal_frequency = 256\n",
    "\n",
    "\n",
    "# compute coeffs of wavelets listed in MWT_list for an given epoch (one channel)\n",
    "def compute_coeffs(epoch):\n",
    "\n",
    "    wavelets = {}\n",
    "\n",
    "    for MWT in MWT_list:\n",
    "        center_wavelet_frequency = pywt.scale2frequency(MWT, [1])[0]\n",
    "        const = center_wavelet_frequency * signal_frequency\n",
    "\n",
    "        # construct scales\n",
    "        scales = np.arange(const / 128, const / 1, 0.1).tolist()\n",
    "\n",
    "        # compute coeffs\n",
    "        coef, freqs = pywt.cwt(\n",
    "            data=epoch, scales=scales, wavelet=MWT, sampling_period=1 / signal_frequency\n",
    "        )\n",
    "\n",
    "        # Save coeffs from the MWT\n",
    "        wavelets[MWT] = coef\n",
    "\n",
    "    return wavelets\n",
    "\n",
    "\n",
    "epoch = X[0][0]\n",
    "\n",
    "coeffs_dict = compute_coeffs(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erpinator",
   "language": "python",
   "name": "erpinator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
