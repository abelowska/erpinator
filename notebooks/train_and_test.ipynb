{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import os\n",
    "import pickle\n",
    "from time import time\n",
    "\n",
    "import pywt\n",
    "import mne\n",
    "import scipy\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from ipywidgets import Dropdown, FloatRangeSlider, IntSlider, FloatSlider, interact\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Load stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# load epochs (only a train set)\n",
    "# epochs is a 5D structure:\n",
    "# PARTICIPANTS x [ERROR, CORRECT] x EPOCH X CHANNEL x TIMEPOINT\n",
    "\n",
    "pickled_data = \"../data/train_epochs.p\"\n",
    "if os.path.isfile(pickled_data):\n",
    "    epochs = pickle.load(open(pickled_data, \"rb\"))\n",
    "else:\n",
    "    epochs = load_all_epochs()\n",
    "    # pickle data loaded by MNE to save on loading times later\n",
    "    pickle.dump(epochs, open(pickled_data, \"wb\"))\n",
    "\n",
    "# sort participants by the number of errors, descending\n",
    "# this way the best participants are first\n",
    "epochs.sort(reverse=True, key=lambda e: len(e[ERROR]))\n",
    "\n",
    "print(\"participants\\t\", len(epochs))\n",
    "print(\"p0 error\\t\", epochs[0][ERROR].shape)\n",
    "print(\"p0 correct\\t\", epochs[0][CORRECT].shape)\n",
    "\n",
    "\n",
    "# get metadata\n",
    "_mne_epochs = load_epochs_from_file(\"../data/responses/GNG_AA0303-64 el.vhdr\")\n",
    "times = _mne_epochs.times\n",
    "\n",
    "_channel_info = _mne_epochs.info[\"chs\"]\n",
    "channel_locations = np.array([ch[\"loc\"][:3] for ch in _channel_info])\n",
    "channel_names = [ch[\"ch_name\"] for ch in _channel_info]\n",
    "\n",
    "channel_colors = channel_locations - channel_locations.min(axis=0)\n",
    "channel_colors /= channel_colors.max(axis=0)\n",
    "channel_colors = channel_colors * 255 // 1\n",
    "channel_colors = [f\"rgb({c[0]:.0f},{c[1]:.0f},{c[2]:.0f})\" for c in channel_colors]\n",
    "\n",
    "log_freq = np.log2(get_frequencies())  # for plotting CWT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def train(X, y, mwt=\"mexh\", cwt_density=2, ica_n_components=4, wavelet_choice=\"single\"):\n",
    "    # X has a shape EPOCHS x CHANNELS x TIMEPOINTS\n",
    "    # y has a shape EPOCHS\n",
    "\n",
    "    # compute ICA\n",
    "    concat = np.concatenate(X, axis=1)\n",
    "    # concat.shape == (num_of_channels, timepoints)\n",
    "    ica = FastICA(n_components=ica_n_components)\n",
    "    ica.fit_transform(concat.T)\n",
    "    # ica.components_.shape == (n_components, num_of_channels)\n",
    "\n",
    "    features = []\n",
    "    for spatial_filter in ica.components_:\n",
    "        # apply ICA\n",
    "        X_filtered = filter_(X, spatial_filter)\n",
    "        # they have shape EPOCHS x TIMEPOINTS\n",
    "\n",
    "        # apply cwt\n",
    "        X_cwts = np.array([cwt(epoch, mwt, cwt_density) for epoch in X_filtered])\n",
    "        # it has a shape EPOCH x FREQUENCY x TIMEPOINT\n",
    "\n",
    "        if wavelet_choice == \"single\":\n",
    "            # find bets separating wavelet\n",
    "            separations = get_separations(X_cwts[y == ERROR], X_cwts[y == CORRECT])\n",
    "            # separations are shaped FREQUENCY x TIMEPOINT\n",
    "            index = np.unravel_index(separations.argmax(), separations.shape)\n",
    "            wavelet_weights = np.zeros_like(separations)\n",
    "            wavelet_weights[index] = 1\n",
    "        elif wavelet_choice == \"LDA\":\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\"wrong wavelet_choice argument\")\n",
    "\n",
    "        X_end = np.tensordot(X_cwts, wavelet_weights, axes=([1, 2], [0, 1]))\n",
    "\n",
    "        # fit normal distributions to error and correct final feature\n",
    "        err_end = X_end[y == ERROR]\n",
    "        cor_end = X_end[y == CORRECT]\n",
    "        _params = scipy.stats.norm.fit(err_end)\n",
    "        err_distr = scipy.stats.norm(*_params).pdf\n",
    "        _params = scipy.stats.norm.fit(cor_end)\n",
    "        cor_distr = scipy.stats.norm(*_params).pdf\n",
    "\n",
    "        separation = separations[index]\n",
    "        features.append(\n",
    "            (separation, spatial_filter, wavelet_weights, err_distr, cor_distr)\n",
    "        )\n",
    "\n",
    "    # find which spatial_filters separate best, and sort them by separation, descending\n",
    "    features.sort(reverse=True)\n",
    "    return features\n",
    "\n",
    "\n",
    "def predict(epochs, features, mwt=\"mexh\", cwt_density=2):\n",
    "    feature = features[0]\n",
    "    _, spatial_filter, wavelet_weights, err_distr, cor_distr = feature\n",
    "\n",
    "    filtered = filter_(epochs, spatial_filter)\n",
    "\n",
    "    cwts = np.array([cwt(epoch, mwt, cwt_density) for epoch in filtered])\n",
    "    # EPOCH x FREQUENCY x TIMEPOINT\n",
    "\n",
    "    end = np.tensordot(cwts, wavelet_weights, axes=([1, 2], [0, 1]))\n",
    "\n",
    "    # assume equal priors\n",
    "    predictions = cor_distr(end) / (cor_distr(end) + err_distr(end))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "print(\"participant            AUROC   err/corr\")\n",
    "aurocs = []\n",
    "auroc_sems = []\n",
    "for participant, err_cor in enumerate(epochs[:3]):\n",
    "    err, cor = err_cor\n",
    "    X = np.concatenate((err, cor))\n",
    "    y = np.concatenate((np.zeros(len(err)), np.ones(len(cor))))\n",
    "\n",
    "    mwt = \"mexh\"\n",
    "    # bandwidth = 0.5\n",
    "    # mwt = f\"cmor{bandwidth}-1\"\n",
    "\n",
    "    aurocs_personal = []\n",
    "    # KFold cross-validation\n",
    "    skf = StratifiedKFold(n_splits=4)\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        #         print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # train\n",
    "        features = train(X_train, y_train, mwt, wavelet_choice=\"single\")\n",
    "\n",
    "        # test\n",
    "        y_pred = predict(X_test, features, mwt)\n",
    "\n",
    "        auroc = roc_auc_score(y_test, y_pred)\n",
    "        aurocs_personal.append(auroc)\n",
    "\n",
    "    aurocs.append(np.mean(aurocs_personal))\n",
    "    auroc_sems.append(scipy.stats.sem(aurocs_personal))\n",
    "\n",
    "    print(\n",
    "        f\"{participant:11}    \"\n",
    "        f\"{aurocs[-1]:.3f} ± {auroc_sems[-1]:.3f}    \"\n",
    "        f\"{len(err):3}/{len(cor):3}\"\n",
    "    )\n",
    "\n",
    "print(f\"\\ntraining time: {(time() - start) / 60:.0f} min\")\n",
    "total_sem = sum(np.array(auroc_sems) ** 2) ** (1 / 2) / len(auroc_sems)\n",
    "print(f\"mean AUROC: {np.mean(aurocs):.3f} ± {total_sem:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# px.scatter(y=aurocs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erpinator",
   "language": "python",
   "name": "erpinator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
