{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import os\n",
    "import pickle\n",
    "from time import time\n",
    "\n",
    "import pywt\n",
    "import mne\n",
    "import scipy\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from ipywidgets import Dropdown, FloatRangeSlider, IntSlider, FloatSlider, interact\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Load stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# load epochs (only a train set)\n",
    "# epochs is a 5D structure:\n",
    "# PARTICIPANTS x [ERROR, CORRECT] x EPOCH X CHANNEL x TIMEPOINT\n",
    "\n",
    "pickled_data = \"../data/train_epochs.p\"\n",
    "if os.path.isfile(pickled_data):\n",
    "    epochs = pickle.load(open(pickled_data, \"rb\"))\n",
    "else:\n",
    "    epochs = load_all_epochs()\n",
    "    # pickle data loaded by MNE to save on loading times later\n",
    "    pickle.dump(epochs, open(pickled_data, \"wb\"))\n",
    "\n",
    "# sort participants by the number of errors, descending\n",
    "# this way the best participants are first\n",
    "epochs.sort(reverse=True, key=lambda e: len(e[ERROR]))\n",
    "\n",
    "print(\"participants\\t\", len(epochs))\n",
    "print(\"p0 error\\t\", epochs[0][ERROR].shape)\n",
    "print(\"p0 correct\\t\", epochs[0][CORRECT].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# get metadata\n",
    "_mne_epochs = load_epochs_from_file(\"../data/responses/GNG_AA0303-64 el.vhdr\")\n",
    "times = _mne_epochs.times\n",
    "\n",
    "_channel_info = _mne_epochs.info[\"chs\"]\n",
    "channel_locations = np.array([ch[\"loc\"][:3] for ch in _channel_info])\n",
    "channel_names = [ch[\"ch_name\"] for ch in _channel_info]\n",
    "\n",
    "channel_colors = channel_locations - channel_locations.min(axis=0)\n",
    "channel_colors /= channel_colors.max(axis=0)\n",
    "channel_colors = channel_colors * 255 // 1\n",
    "channel_colors = [f\"rgb({c[0]:.0f},{c[1]:.0f},{c[2]:.0f})\" for c in channel_colors]\n",
    "\n",
    "log_freq = np.log2(get_frequencies())  # for plotting CWT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def train(err, cor, mwt=\"mexh\", cwt_density=2, ica_n_components=4):\n",
    "    # compute ICA\n",
    "    joined_epochs = np.concatenate((err, cor))\n",
    "    concat = np.concatenate(joined_epochs, axis=1)\n",
    "    # concat.shape == (num_of_channels, timepoints)\n",
    "    ica = FastICA(n_components=ica_n_components)\n",
    "    ica.fit_transform(concat.T)\n",
    "    # ica.components_.shape == (n_components, num_of_channels)\n",
    "\n",
    "    features = []\n",
    "    for spatial_filter in ica.components_:\n",
    "        # apply ICA\n",
    "        err_filtered = filter_(err, spatial_filter)\n",
    "        cor_filtered = filter_(cor, spatial_filter)\n",
    "        # they have shape EPOCHS x TIMEPOINTS\n",
    "\n",
    "        # apply cwt\n",
    "        err_cwts = np.array([cwt(epoch, mwt, cwt_density) for epoch in err_filtered])\n",
    "        cor_cwts = np.array([cwt(epoch, mwt, cwt_density) for epoch in cor_filtered])\n",
    "        # they have shape EPOCH x FREQUENCY x TIMEPOINT\n",
    "\n",
    "        # find bets separating wavelet\n",
    "        separations = get_separations(err_cwts, cor_cwts)\n",
    "        # separations are shaped FREQUENCY x TIMEPOINT\n",
    "        index = np.unravel_index(separations.argmax(), separations.shape)\n",
    "        err_end = err_cwts[:, index[0], index[1]]\n",
    "        cor_end = cor_cwts[:, index[0], index[1]]\n",
    "\n",
    "        # fit normal distributions to error and correct final feature\n",
    "        _params = scipy.stats.norm.fit(err_end)\n",
    "        err_distr = scipy.stats.norm(*_params).pdf\n",
    "        _params = scipy.stats.norm.fit(cor_end)\n",
    "        cor_distr = scipy.stats.norm(*_params).pdf\n",
    "\n",
    "        separation = separations[index]\n",
    "        features.append((separation, spatial_filter, index, err_distr, cor_distr))\n",
    "\n",
    "    # find which ICA components separate best, and sort them by separation, descending\n",
    "    features.sort(reverse=True)\n",
    "    return features\n",
    "\n",
    "\n",
    "def predict(epochs, features, mwt=\"mexh\", cwt_density=2):\n",
    "    feature = features[0]\n",
    "    _, spatial_filter, index, err_distr, cor_distr = feature\n",
    "\n",
    "    filtered = filter_(epochs, spatial_filter)\n",
    "\n",
    "    cwts = np.array([cwt(epoch, mwt, cwt_density) for epoch in filtered])\n",
    "    # EPOCH x FREQUENCY x TIMEPOINT\n",
    "\n",
    "    end = cwts[:, index[0], index[1]]\n",
    "\n",
    "    # assume equal priors\n",
    "    predictions = cor_distr(end) / (cor_distr(end) + err_distr(end))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "aurocs = []\n",
    "for participant, err_cor in enumerate(epochs[:10]):\n",
    "    err, cor = err_cor\n",
    "\n",
    "    mwt = \"mexh\"\n",
    "    # bandwidth = 0.5\n",
    "    # mwt = f\"cmor{bandwidth}-1\"\n",
    "\n",
    "    # split out test sets\n",
    "    err_train, err_test = train_test_split(err, test_size=0.4, random_state=0)\n",
    "    cor_train, cor_test = train_test_split(cor, test_size=0.4, random_state=0)\n",
    "\n",
    "    # train\n",
    "    features = train(err_train, cor_train, mwt)\n",
    "\n",
    "    # test\n",
    "    y_true = np.concatenate((np.zeros(len(err_test)), np.ones(len(cor_test))))\n",
    "    test_data = np.concatenate((err_test, cor_test))\n",
    "    y_pred = predict(test_data, features, mwt)\n",
    "\n",
    "    auroc = roc_auc_score(y_true, y_pred)\n",
    "    aurocs.append(auroc)\n",
    "\n",
    "    print(\n",
    "        f\"participant: {participant:3}    errors/corrects: {len(err):3}/{len(cor):3}    AUROC: {auroc:.3f}\"\n",
    "    )\n",
    "\n",
    "print(time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "np.mean(aurocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# px.scatter(y=aurocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "list(kf.split([1, 2, 3, 4, 5, 6]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erpinator",
   "language": "python",
   "name": "erpinator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
