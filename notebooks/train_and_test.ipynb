{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pywt\n",
    "import mne\n",
    "import scipy\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from ipywidgets import Dropdown, FloatRangeSlider, IntSlider, FloatSlider, interact\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Load stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# load epochs (only a train set)\n",
    "# epochs is a 5D structure:\n",
    "# PARTICIPANTS x [ERROR, CORRECT] x EPOCH X CHANNEL x TIMEPOINT\n",
    "\n",
    "pickled_data = \"../data/train_epochs.p\"\n",
    "if os.path.isfile(pickled_data):\n",
    "    epochs = pickle.load(open(pickled_data, \"rb\"))\n",
    "else:\n",
    "    epochs = load_all_epochs()\n",
    "    # pickle data loaded by MNE to save on loading times later\n",
    "    pickle.dump(epochs, open(pickled_data, \"wb\"))\n",
    "\n",
    "# sort participants by the number of errors, descending\n",
    "# this way the best participants are first\n",
    "epochs.sort(reverse=True, key=lambda e: len(e[ERROR]))\n",
    "\n",
    "print(\"participants\\t\", len(epochs))\n",
    "print(\"p0 error\\t\", epochs[0][ERROR].shape)\n",
    "print(\"p0 correct\\t\", epochs[0][CORRECT].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# get metadata\n",
    "_mne_epochs = load_epochs_from_file(\"../data/responses/GNG_AA0303-64 el.vhdr\")\n",
    "times = _mne_epochs.times\n",
    "\n",
    "_channel_info = _mne_epochs.info[\"chs\"]\n",
    "channel_locations = np.array([ch[\"loc\"][:3] for ch in _channel_info])\n",
    "channel_names = [ch[\"ch_name\"] for ch in _channel_info]\n",
    "\n",
    "channel_colors = channel_locations - channel_locations.min(axis=0)\n",
    "channel_colors /= channel_colors.max(axis=0)\n",
    "channel_colors = channel_colors * 255 // 1\n",
    "channel_colors = [f\"rgb({c[0]:.0f},{c[1]:.0f},{c[2]:.0f})\" for c in channel_colors]\n",
    "\n",
    "log_freq = np.log2(get_frequencies())  # for plotting CWT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def train(err, cor, mwt, cwt_density=2, ica_n_components=4):\n",
    "    # apply cwt\n",
    "    err_cwts = np.array(\n",
    "        [[cwt(ch_signal, mwt, cwt_density) for ch_signal in epoch] for epoch in err]\n",
    "    )\n",
    "    cor_cwts = np.array(\n",
    "        [[cwt(ch_signal, mwt, cwt_density) for ch_signal in epoch] for epoch in cor]\n",
    "    )\n",
    "    # they are 4D numpy arrays:\n",
    "    # EPOCH x CHANNEL x FREQUENCY x TIMEPOINT\n",
    "\n",
    "    # compute ICA\n",
    "    joined_epochs = np.concatenate((err, cor))\n",
    "    concat = np.concatenate(joined_epochs, axis=1)\n",
    "    # concat.shape == (num_of_channels, timepoints)\n",
    "    ica = FastICA(n_components=ica_n_components)\n",
    "    ica.fit_transform(concat.T)\n",
    "    # ica.components_.shape == (n_components, num_of_channels)\n",
    "\n",
    "    # find which ICA components separate best, and sort them by separation, descending\n",
    "    _components = []\n",
    "    for i, comp in enumerate(ica.components_):\n",
    "        _, separations = get_best_separation(err_cwts, cor_cwts, comp)\n",
    "        _components.append((separations.max(), comp))\n",
    "    _components.sort(reverse=True)\n",
    "    ica_components = [comp for separation, comp in _components]\n",
    "\n",
    "    # find bets separating wavelet\n",
    "    spatial_filter = ica_components[0]\n",
    "    index, _ = get_best_separation(err_cwts, cor_cwts, spatial_filter)\n",
    "    err_end = filter_(err_cwts, spatial_filter)[:, index[0], index[1]]\n",
    "    cor_end = filter_(cor_cwts, spatial_filter)[:, index[0], index[1]]\n",
    "\n",
    "    # fit normal distributions to error and correct final features\n",
    "    _params = scipy.stats.norm.fit(err_end)\n",
    "    err_distr = scipy.stats.norm(*_params).pdf\n",
    "    _params = scipy.stats.norm.fit(cor_end)\n",
    "    cor_distr = scipy.stats.norm(*_params).pdf\n",
    "\n",
    "    return ica_components, index, err_distr, cor_distr\n",
    "\n",
    "\n",
    "def predict(epochs, mwt, ica_component, index, err_distr, cor_distr):\n",
    "    cwts = np.array([[cwt(ch_signal, mwt) for ch_signal in epoch] for epoch in epochs])\n",
    "    # they are 4D numpy arrays:\n",
    "    # EPOCH x CHANNEL x FREQUENCY x TIMEPOINT\n",
    "\n",
    "    spatial_filter = ica_components[0]\n",
    "    end = filter_(cwts, spatial_filter)[:, index[0], index[1]]\n",
    "\n",
    "    # assume equal priors\n",
    "    predictions = cor_distr(end) / (cor_distr(end) + err_distr(end))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "aurocs = []\n",
    "for participant, err_cor in enumerate(epochs[:10]):\n",
    "    err, cor = err_cor\n",
    "\n",
    "    mwt = \"mexh\"\n",
    "    # bandwidth = 0.5\n",
    "    # mwt = f\"cmor{bandwidth}-1\"\n",
    "\n",
    "    # split out test sets\n",
    "    err_train, err_test = train_test_split(err, test_size=0.4, random_state=0)\n",
    "    cor_train, cor_test = train_test_split(cor, test_size=0.4, random_state=0)\n",
    "\n",
    "    # train\n",
    "    ica_components, index, err_distr, cor_distr = train(err_train, cor_train, mwt)\n",
    "\n",
    "    # test\n",
    "    y_true = np.concatenate((np.zeros(len(err_test)), np.ones(len(cor_test))))\n",
    "    test_data = np.concatenate((err_test, cor_test))\n",
    "    y_pred = predict(test_data, mwt, ica_components, index, err_distr, cor_distr)\n",
    "\n",
    "    auroc = roc_auc_score(y_true, y_pred)\n",
    "    aurocs.append(auroc)\n",
    "\n",
    "    print(\n",
    "        f\"participant: {participant:3}    errors/corrects: {len(err):3}/{len(cor):3}    AUROC: {auroc:.3f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erpinator",
   "language": "python",
   "name": "erpinator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
