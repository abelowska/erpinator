{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import inspect\n",
    "import itertools\n",
    "from time import time\n",
    "from copy import deepcopy\n",
    "\n",
    "import pywt\n",
    "import mne\n",
    "import scipy\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import xxhash\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "from cachier import cachier\n",
    "from plotly.subplots import make_subplots\n",
    "from ipywidgets import Dropdown, FloatRangeSlider, IntSlider, FloatSlider, interact\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from ipywidgets import HBox, VBox\n",
    "from ipywidgets import Dropdown, FloatRangeSlider, IntSlider, FloatSlider, interact\n",
    "\n",
    "from utils import *\n",
    "from architecture import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "# ignore FastICA did not converge warnings\n",
    "# TODO investigate why doesn't it converge\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "false"
   },
   "source": [
    "#### Data read into dataframe structure. Each epoch is a single record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_name = \"go_nogo_df_personal\"\n",
    "pickled_data_filename = \"../data/\" + df_name + \".pkl\"\n",
    "info_filename = \"../data/Demographic_Questionnaires_Behavioral_Results_N=163.csv\"\n",
    "\n",
    "# Check if data is already loaded\n",
    "if os.path.isfile(pickled_data_filename):\n",
    "    print(\"Pickled file found. Loading pickled data...\")\n",
    "    epochs = pd.read_pickle(pickled_data_filename)\n",
    "else:\n",
    "    print(\"Pickled file not found. Loading data...\")\n",
    "    epochs = create_df_data(info_filename=info_filename, personal=True)\n",
    "    epochs.name = df_name\n",
    "    # save loaded data into a pickle file\n",
    "    epochs.to_pickle(\"../data/\" + epochs.name + \".pkl\")\n",
    "\n",
    "# epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "false"
   },
   "source": [
    "#### Sort participants by the number of errors, descending. This way the best participants are first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# add new columns with info about error/correct responses amount\n",
    "grouped = epochs.groupby(\"id\")\n",
    "epochs[\"error_sum\"] = grouped[[\"marker\"]].transform(lambda x: (x.values == ERROR).sum())\n",
    "epochs[\"correct_sum\"] = grouped[[\"marker\"]].transform(\n",
    "    lambda x: (x.values == CORRECT).sum()\n",
    ")\n",
    "\n",
    "# mergesort for stable sorting\n",
    "epochs = epochs.sort_values(\"error_sum\", ascending=False, kind=\"mergesort\")\n",
    "# epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "false"
   },
   "source": [
    "#### Get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "_mne_epochs = load_epochs_from_file(\"../data/responses/GNG_AA0303-64 el.vhdr\")\n",
    "times = _mne_epochs.times\n",
    "\n",
    "_channel_info = _mne_epochs.info[\"chs\"]\n",
    "channel_locations = np.array([ch[\"loc\"][:3] for ch in _channel_info])\n",
    "channel_names = [ch[\"ch_name\"] for ch in _channel_info]\n",
    "\n",
    "channel_colors = channel_locations - channel_locations.min(axis=0)\n",
    "channel_colors /= channel_colors.max(axis=0)\n",
    "channel_colors = channel_colors * 255 // 1\n",
    "channel_colors = [f\"rgb({c[0]:.0f},{c[1]:.0f},{c[2]:.0f})\" for c in channel_colors]\n",
    "\n",
    "log_freq = np.log2(get_frequencies())  # for plotting CWT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedir = \"/home/filip/.erpinator_cache\"\n",
    "\n",
    "steps = steps_simple  # one PCA for all\n",
    "\n",
    "# steps = steps_parallel_pca\n",
    "# steps.pop(3)  # remove CWT\n",
    "\n",
    "# StandardScaler doesn't seem to change anything for LDA\n",
    "# steps = steps[:-2] + [(\"lasso\", Lasso())]\n",
    "# steps = steps[:-2] + [(\"lda\", LinearDiscriminantAnalysis())]\n",
    "# steps = steps[:-1] + [(\"knr\", KNeighborsRegressor())]\n",
    "steps = steps[:-1] + [(\"lasso\", Lasso())]\n",
    "\n",
    "steps[1] = (\"spatial_filter\", PCA(random_state=0))  # replace ICA with PCA\n",
    "\n",
    "regressor_params = dict(\n",
    "    spatial_filter__n_components=[4],\n",
    "    #     cwt__mwt=[\"morl\"],\n",
    "    #     cwt__octaves=[4],\n",
    "    pca__n_components=[8],\n",
    "    # featurize__power__cwt__mwt=[\"cmor0.5-1\"],\n",
    "    # featurize__power__pca__n_components=[3],\n",
    "    # featurize__shape__cwt__mwt=[\"mexh\"],\n",
    "    # featurize__shape__pca__n_components=[3],\n",
    "    #     svr__C=[0.1],\n",
    "    #     knr__n_neighbors=[11],\n",
    "    lasso__alpha=[0.0000003],\n",
    "    # lda__solver=[\"lsqr\"],  # to turn off scaling, to simplify visualizing\n",
    ")\n",
    "steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate model for each person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "print(\"participant            AUROC   err/corr\")\n",
    "aurocs = []\n",
    "auroc_sems = []\n",
    "pipelines = []\n",
    "\n",
    "# group data by participants' ids\n",
    "grouped = epochs.groupby([\"id\"])\n",
    "for participant_id in epochs[\"id\"].unique():\n",
    "    participant_df = grouped.get_group(participant_id)\n",
    "\n",
    "    X = np.array(participant_df[\"epoch\"].to_list())\n",
    "    y = np.array(participant_df[\"marker\"].to_list())\n",
    "\n",
    "    pipeline = Pipeline(deepcopy(steps), memory=cachedir)\n",
    "    pipeline.set_params(**ParameterGrid(regressor_params)[0])\n",
    "\n",
    "    aurocs_personal = []\n",
    "    pipelines_personal = []\n",
    "    skf = StratifiedKFold(n_splits=2)\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        if type(steps[-1][1]) == LinearDiscriminantAnalysis:\n",
    "            y_pred = pipeline.predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "        # corr = np.corrcoef(y_test, y_pred)[0][1]\n",
    "        # r2 = r2_score(y_test, y_pred)\n",
    "        auroc = roc_auc_score(y_test, y_pred)\n",
    "        aurocs_personal.append(auroc)\n",
    "        pipelines_personal.append(pipeline)\n",
    "\n",
    "    aurocs.append(np.mean(aurocs_personal))\n",
    "    auroc_sems.append(scipy.stats.sem(aurocs_personal))\n",
    "    pipelines.append(pipelines_personal)\n",
    "\n",
    "    error_size = participant_df[\"error_sum\"].iloc[0]\n",
    "    correct_size = participant_df[\"correct_sum\"].iloc[0]\n",
    "    print(\n",
    "        f\"{participant_id:11}    \"\n",
    "        f\"{aurocs[-1]:.3f} ± {auroc_sems[-1]:.3f}    \"\n",
    "        f\"{error_size:3}/{correct_size:3}\"\n",
    "    )\n",
    "\n",
    "total_sem = sum(np.array(auroc_sems) ** 2) ** (1 / 2) / len(auroc_sems)\n",
    "mean_auroc = f\"{np.mean(aurocs):.3f} ± {total_sem:.3f}\"\n",
    "print(\"mean AUROC: \" + mean_auroc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erpinator",
   "language": "python",
   "name": "erpinator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
