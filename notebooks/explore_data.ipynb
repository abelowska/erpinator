{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import pywt\n",
    "import mne\n",
    "import scipy\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from ipywidgets import Dropdown, FloatRangeSlider, IntSlider, FloatSlider, interact\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# ignore FastICA did not converge warnings\n",
    "# TODO investigate why doesn't it converge\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "false"
   },
   "source": [
    "#### Data read into dataframe structure. Each epoch is a single record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_name = \"go_nogo_df\"\n",
    "pickled_data_filename = \"../data/\" + df_name + \".pkl\"\n",
    "info_filename = \"../data/Demographic_Questionnaires_Behavioral_Results_N=163.csv\"\n",
    "\n",
    "# Check if data is already loaded\n",
    "if os.path.isfile(pickled_data_filename):\n",
    "    print(\"Pickled file found. Loading pickled data...\")\n",
    "    epochs = pd.read_pickle(pickled_data_filename)\n",
    "else:\n",
    "    print(\"Pickled file not found. Loading data...\")\n",
    "    epochs = create_df_data(info_filename=info_filename)\n",
    "    epochs.name = df_name\n",
    "    # save loaded data into a pickle file\n",
    "    epochs.to_pickle(\"../data/\" + epochs.name + \".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "false"
   },
   "source": [
    "#### Sort participants by the number of errors, descending. This way the best participants are first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# add new columns with info about error/correct responses amount\n",
    "grouped = epochs.groupby(\"id\")\n",
    "epochs[\"error_sum\"] = grouped[[\"marker\"]].transform(lambda x: (x.values == ERROR).sum())\n",
    "epochs[\"correct_sum\"] = grouped[[\"marker\"]].transform(\n",
    "    lambda x: (x.values == CORRECT).sum()\n",
    ")\n",
    "\n",
    "# mergesort for stable sorting\n",
    "epochs = epochs.sort_values(\"error_sum\", ascending=False, kind=\"mergesort\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": "false"
   },
   "source": [
    "#### Get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "_mne_epochs = load_epochs_from_file(\"../data/responses/GNG_AA0303-64 el.vhdr\")\n",
    "times = _mne_epochs.times\n",
    "\n",
    "_channel_info = _mne_epochs.info[\"chs\"]\n",
    "channel_locations = np.array([ch[\"loc\"][:3] for ch in _channel_info])\n",
    "channel_names = [ch[\"ch_name\"] for ch in _channel_info]\n",
    "\n",
    "channel_colors = channel_locations - channel_locations.min(axis=0)\n",
    "channel_colors /= channel_colors.max(axis=0)\n",
    "channel_colors = channel_colors * 255 // 1\n",
    "channel_colors = [f\"rgb({c[0]:.0f},{c[1]:.0f},{c[2]:.0f})\" for c in channel_colors]\n",
    "\n",
    "log_freq = np.log2(get_frequencies())  # for plotting CWT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# # display electrode locations\n",
    "# x, y, z = channel_locations.T\n",
    "# scalp3d = go.FigureWidget(layout=base_layout)\n",
    "# scalp3d.update_layout(width=700, height=700)\n",
    "# scalp3d.add_scatter3d(\n",
    "#     x=x,\n",
    "#     y=y,\n",
    "#     z=z,\n",
    "#     mode=\"markers+text\",\n",
    "#     text=channel_names,\n",
    "#     marker_size=3,\n",
    "#     marker_color=channel_colors,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# # those sliders are shared across plots\n",
    "# participant_slider = Dropdown(options=epochs[\"id\"].unique())\n",
    "# channel_slider = Dropdown(value=\"Cz\", options=channel_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(\"plot all channels for a given epoch, and CWT for a chosen channel of this epoch\")\n",
    "max_amp = 0.00005\n",
    "\n",
    "fig = go.FigureWidget(\n",
    "    make_subplots(\n",
    "        rows=3,\n",
    "        vertical_spacing=0.1,\n",
    "        subplot_titles=(\"all channels, single epoch\", \"complex CWT\", \"real CWT\"),\n",
    "    )\n",
    ")\n",
    "fig.update_layout(**base_layout)\n",
    "fig.update_layout(\n",
    "    xaxis_range=[times[0], times[-1]],\n",
    "    yaxis_range=[-max_amp, max_amp],\n",
    "    #     height=840,\n",
    ")\n",
    "for i in range(len(channel_names)):\n",
    "    fig.add_scatter(x=times, row=1, col=1)\n",
    "fig.add_heatmap(x=times, row=2, col=1, zmin=0, zmax=40e-6, y=log_freq, colorscale=\"ice\")\n",
    "fig.add_heatmap(\n",
    "    x=times, row=3, col=1, zmin=-100e-6, zmax=100e-6, y=log_freq, colorbar_x=1.1\n",
    ")\n",
    "\n",
    "grouped = epochs.groupby([\"id\"])\n",
    "\n",
    "\n",
    "@interact(\n",
    "    participant=Dropdown(options=epochs[\"id\"].unique()),\n",
    "    channel=Dropdown(value=\"Cz\", options=channel_names),\n",
    "    condition=Dropdown(options=[(\"error\", ERROR), (\"correct\", CORRECT)]),\n",
    "    epoch_num=IntSlider(min=0, max=7),\n",
    ")\n",
    "def update_plots(participant, channel, condition, epoch_num):\n",
    "    channel = channel_names.index(channel)\n",
    "    with fig.batch_update():\n",
    "        df = grouped.get_group(participant)\n",
    "        epoch = df.loc[df[\"marker\"] == condition].iloc[epoch_num][\"epoch\"]\n",
    "        for ch in range(len(channel_names)):\n",
    "            fig.data[ch].y = epoch[ch]\n",
    "            if ch == channel:\n",
    "                fig.data[ch].line = {\"width\": 3, \"color\": channel_colors[ch]}\n",
    "            else:\n",
    "                fig.data[ch].line = {\"width\": 0.3, \"color\": channel_colors[ch]}\n",
    "        fig.data[-2].z = cwt(epoch[channel], \"cmor0.5-1\")\n",
    "        fig.data[-1].z = cwt(epoch[channel], \"mexh\")\n",
    "        print(channel_names[channel])\n",
    "\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(\"plot average ERP difference between conditions, and its CWT\")\n",
    "fig2 = go.FigureWidget(make_subplots(rows=2))\n",
    "fig2.update_layout(**base_layout)\n",
    "fig2.update_layout(\n",
    "    xaxis_range=[times[0], times[-1]],\n",
    "    yaxis_range=[-max_amp / 2, max_amp / 2],\n",
    ")\n",
    "for i in range(len(channel_names)):\n",
    "    fig2.add_scatter(x=times, row=1, col=1)\n",
    "fig2.add_heatmap(x=times, row=2, col=1, zmin=-50e-6, zmax=50e-6)\n",
    "\n",
    "\n",
    "grouped = epochs.groupby([\"id\"])\n",
    "\n",
    "\n",
    "@interact(\n",
    "    participant=Dropdown(options=epochs[\"id\"].unique()),\n",
    "    channel=Dropdown(value=\"Cz\", options=channel_names),\n",
    ")\n",
    "def update_plots(participant, channel):\n",
    "    channel = channel_names.index(channel)\n",
    "    with fig2.batch_update():\n",
    "\n",
    "        df = grouped.get_group(participant)\n",
    "        err = np.stack(df.loc[df[\"marker\"] == ERROR][\"epoch\"].values)\n",
    "        cor = np.stack(df.loc[df[\"marker\"] == CORRECT][\"epoch\"].values)\n",
    "\n",
    "        ERP_diff = cor.mean(axis=0) - err.mean(axis=0)\n",
    "        for ch in range(len(channel_names)):\n",
    "            fig2.data[ch].y = ERP_diff[ch]\n",
    "            if ch == channel:\n",
    "                fig2.data[ch].line = {\"width\": 3, \"color\": channel_colors[ch]}\n",
    "            else:\n",
    "                fig2.data[ch].line = {\"width\": 0.3, \"color\": channel_colors[ch]}\n",
    "        fig2.data[-1].z = cwt(ERP_diff[channel])\n",
    "        print(channel_names[channel])\n",
    "\n",
    "\n",
    "fig2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    \"all epochs, for a chosen participant and channel, green are correct, red are errors\"\n",
    ")\n",
    "fig3 = go.FigureWidget()\n",
    "fig3.update_layout(**base_layout)\n",
    "fig3.update_layout(\n",
    "    xaxis_range=[times[0], times[-1]],\n",
    "    yaxis_range=[-max_amp, max_amp],\n",
    "    height=300,\n",
    ")\n",
    "for i in range(400):  # must be more than epochs for any participant\n",
    "    fig3.add_scatter(x=times)\n",
    "\n",
    "grouped = epochs.groupby([\"id\"])\n",
    "\n",
    "\n",
    "@interact(\n",
    "    participant=Dropdown(options=epochs[\"id\"].unique()),\n",
    "    channel=Dropdown(value=\"Cz\", options=channel_names),\n",
    ")\n",
    "def update_plots(participant, channel):\n",
    "    channel = channel_names.index(channel)\n",
    "    df = grouped.get_group(participant)\n",
    "    err = np.stack(df.loc[df[\"marker\"] == ERROR][\"epoch\"].values)\n",
    "    cor = np.stack(df.loc[df[\"marker\"] == CORRECT][\"epoch\"].values)\n",
    "    ERP_diff = cor.mean(axis=0) - err.mean(axis=0)\n",
    "    with fig3.batch_update():\n",
    "        fig3.update_traces(visible=False)\n",
    "    with fig3.batch_update():\n",
    "        for i, epoch in enumerate(cor):\n",
    "            fig3.data[-i].y = epoch[channel]\n",
    "            fig3.data[-i].line = {\"color\": \"green\", \"width\": 0.2}\n",
    "            fig3.data[-i].visible = True\n",
    "        for i, epoch in enumerate(err):\n",
    "            fig3.data[i].y = epoch[channel]\n",
    "            fig3.data[i].line = {\"color\": \"red\", \"width\": 0.2}\n",
    "            fig3.data[i].visible = True\n",
    "        print(channel_names[channel])\n",
    "\n",
    "\n",
    "fig3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features - this section is bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# compute CWT for a chosen participant\n",
    "participant = participant_slider.value\n",
    "print(f\"participant: {participant}\")\n",
    "\n",
    "mwt = \"mexh\"\n",
    "# bandwidth = 0.5\n",
    "# mwt = f\"cmor{bandwidth}-1\"\n",
    "\n",
    "err, cor = epochs[participant]\n",
    "# split out test sets\n",
    "err_train, err_test = train_test_split(err, test_size=0.4, random_state=0)\n",
    "cor_train, cor_test = train_test_split(cor, test_size=0.4, random_state=0)\n",
    "\n",
    "density = 2\n",
    "err_cwts = np.array(\n",
    "    [[cwt(ch_signal, mwt, density) for ch_signal in epoch] for epoch in err_train]\n",
    ")\n",
    "cor_cwts = np.array(\n",
    "    [[cwt(ch_signal, mwt, density) for ch_signal in epoch] for epoch in cor_train]\n",
    ")\n",
    "\n",
    "err_cwts_test = np.array(\n",
    "    [[cwt(ch_signal, mwt, density) for ch_signal in epoch] for epoch in err_test]\n",
    ")\n",
    "cor_cwts_test = np.array(\n",
    "    [[cwt(ch_signal, mwt, density) for ch_signal in epoch] for epoch in cor_test]\n",
    ")\n",
    "\n",
    "# they are 4D numpy arrays:\n",
    "# EPOCH x CHANNEL x FREQUENCY x TIMEPOINT\n",
    "print(err_cwts.shape)\n",
    "print(cor_cwts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# def reduce_over_timeslices(data, slice_size=30, ufunc=np.maximum):\n",
    "#     indexes = np.arange(len(times) - slice_size)\n",
    "#     slice_indexes = np.stack((indexes, indexes + slice_size), axis=-1).flatten()\n",
    "#     return ufunc.reduceat(data, slice_indexes, axis=-1)[:, :, :, ::2]\n",
    "\n",
    "\n",
    "# cor_cwts = reduce_over_timeslices(cor_cwts)\n",
    "# err_cwts = reduce_over_timeslices(err_cwts)\n",
    "# cor_cwts_test = reduce_over_timeslices(cor_cwts_test)\n",
    "# err_cwts_test = reduce_over_timeslices(err_cwts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# TODO delete\n",
    "def get_best_separation(cond1, cond2, spatial_filter):\n",
    "    cond1_filtered = np.tensordot(cond1, spatial_filter, axes=([1], [0]))\n",
    "    cond2_filtered = np.tensordot(cond2, spatial_filter, axes=([1], [0]))\n",
    "    separations = get_separations(cond1_filtered, cond2_filtered)\n",
    "\n",
    "    best_index = np.unravel_index(separations.argmax(), separations.shape)\n",
    "    return best_index, separations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# for each channel, check how well its CWT separates conditions\n",
    "best_separation = 1\n",
    "sep_for_channels = []\n",
    "for i in range(len(channel_names)):\n",
    "    spatial_filter = np.zeros(len(channel_names))\n",
    "    spatial_filter[i] = 1\n",
    "\n",
    "    _, separations = get_best_separation(err_cwts, cor_cwts, spatial_filter)\n",
    "    best_separation = separations.max()\n",
    "    sep_for_channels.append(best_separation)\n",
    "\n",
    "x = channel_locations.T[0]\n",
    "y = channel_locations.T[1]\n",
    "mne.viz.plot_topomap(sep_for_channels, np.stack((x, y), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# show separation for a chosen spatial filter\n",
    "cz_spatial_filter = np.zeros(len(channel_names))\n",
    "for ch_name in [\"Cz\"]:\n",
    "    # for ch_name in [\"Cz\", \"CPz\", \"FCz\", \"C1\", \"CP1\", \"FC1\", \"CP3\", \"C3\", \"FC3\"]:\n",
    "    # for ch_name in [\"Cz\", \"FCz\", \"C1\", \"FC1\"]:\n",
    "    ch_index = channel_names.index(ch_name)\n",
    "    cz_spatial_filter[ch_index] = 1\n",
    "\n",
    "#########################################\n",
    "# spatial_filter = cz_spatial_filter\n",
    "spatial_filter = ica_components[0]\n",
    "\n",
    "index, separations_train = get_best_separation(err_cwts, cor_cwts, spatial_filter)\n",
    "print(\"best index found\", index)\n",
    "print(\"separation on train set\\t\", separations_train.max())\n",
    "\n",
    "# test using Cz electrode\n",
    "_, separations_test = get_best_separation(err_cwts_test, cor_cwts_test, spatial_filter)\n",
    "print(\"separation on test set\\t\", separations_test[index])\n",
    "\n",
    "fig4 = go.FigureWidget(make_subplots(rows=2))\n",
    "fig4.update_layout(**base_layout)\n",
    "fig4.add_heatmap(z=separations_train, x=times, row=1, col=1, zmin=1, zmax=2, y=log_freq)\n",
    "fig4.add_heatmap(z=separations_test, x=times, row=2, col=1, zmin=1, zmax=2, y=log_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# apply spatial filter and get wavelet value at the given index\n",
    "err_end = np.tensordot(err_cwts, spatial_filter, axes=([1], [0]))[:, index[0], index[1]]\n",
    "cor_end = np.tensordot(cor_cwts, spatial_filter, axes=([1], [0]))[:, index[0], index[1]]\n",
    "\n",
    "threshold = (err_end.mean() + cor_end.mean()) / 2\n",
    "err_end -= threshold\n",
    "cor_end -= threshold\n",
    "fig5 = go.FigureWidget(layout=base_layout)\n",
    "fig5.update_layout(height=150)\n",
    "fig5.add_scatter(\n",
    "    x=err_end, y=np.linspace(0, 1, len(err_end)), mode=\"markers\", marker_color=\"red\"\n",
    ")\n",
    "fig5.add_scatter(\n",
    "    x=cor_end, y=np.linspace(0, 1, len(cor_end)), mode=\"markers\", marker_color=\"green\"\n",
    ")\n",
    "fig5\n",
    "\n",
    "# TODO use raincloud plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# final test\n",
    "err_end = np.tensordot(err_cwts_test, spatial_filter, axes=([1], [0]))[\n",
    "    :, index[0], index[1]\n",
    "]\n",
    "cor_end = np.tensordot(cor_cwts_test, spatial_filter, axes=([1], [0]))[\n",
    "    :, index[0], index[1]\n",
    "]\n",
    "err_end -= threshold\n",
    "cor_end -= threshold\n",
    "\n",
    "fig6 = go.FigureWidget(layout=base_layout)\n",
    "fig6.update_layout(height=150)\n",
    "fig6.add_scatter(\n",
    "    x=err_end, y=np.linspace(0, 1, len(err_end)), mode=\"markers\", marker_color=\"red\"\n",
    ")\n",
    "fig6.add_scatter(\n",
    "    x=cor_end, y=np.linspace(0, 1, len(cor_end)), mode=\"markers\", marker_color=\"green\"\n",
    ")\n",
    "fig6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# t_params = scipy.stats.t.fit(err_end, fdf=len(err_end) - 1)\n",
    "# distr = scipy.stats.t(*t_params).pdf\n",
    "\n",
    "# t_params = scipy.stats.t.fit(cor_end, fdf=len(cor_end) - 1)\n",
    "# distr2 = scipy.stats.t(*t_params).pdf\n",
    "\n",
    "params = scipy.stats.norm.fit(err_end)\n",
    "distr = scipy.stats.norm(*params).pdf\n",
    "print(params)\n",
    "\n",
    "params = scipy.stats.norm.fit(cor_end)\n",
    "distr2 = scipy.stats.norm(*params).pdf\n",
    "print(params)\n",
    "\n",
    "# distr = scipy.stats.norm(0, 1).pdf\n",
    "# distr2 = scipy.stats.t(10, 0, 1).pdf\n",
    "\n",
    "# xs = np.linspace(-2, 2, 100)\n",
    "xs = np.linspace(-0.08, 0.1, 100)\n",
    "fig7 = go.FigureWidget(layout=base_layout)\n",
    "fig7.update_layout(height=300)\n",
    "fig7.add_scatter(x=xs, y=distr(xs))\n",
    "fig7.add_scatter(x=xs, y=distr2(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erpinator",
   "language": "python",
   "name": "erpinator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
